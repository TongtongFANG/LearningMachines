{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "# import librosa\n",
    "# from librosa import display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from matplotlib.pyplot import specgram\n",
    "from random import shuffle\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "# import pydot\n",
    "# import graphviz\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "plt.rcParams['font.serif'] = 'Ubuntu'\n",
    "plt.rcParams['font.monospace'] = 'Ubuntu Mono'\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.rcParams['axes.labelsize'] = 11\n",
    "plt.rcParams['axes.labelweight'] = 'bold'\n",
    "plt.rcParams['axes.titlesize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 10\n",
    "plt.rcParams['ytick.labelsize'] = 10\n",
    "plt.rcParams['legend.fontsize'] = 11\n",
    "plt.rcParams['figure.titlesize'] = 13\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "\n",
    "dataset_path_prefix = 'dataset'\n",
    "model_path_prefix = 'trained_models'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Leapmotion dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "leap_features = np.loadtxt(os.path.join(dataset_path_prefix, 'leap_merge_features.csv'), delimiter=',')\n",
    "leap_labels = np.array(np.loadtxt(os.path.join(dataset_path_prefix, 'leap_merge_labels.csv'), delimiter=','), dtype=np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hitmann/.local/lib/python3.5/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(887, 8700)\n",
      "(296, 8700)\n",
      "(887, 6)\n",
      "(296, 6)\n",
      "After reshaping\n",
      "(887, 100, 87)\n",
      "(296, 100, 87)\n",
      "(887, 6)\n",
      "(296, 6)\n"
     ]
    }
   ],
   "source": [
    "X_leap_train, X_leap_test, y_leap_train, y_leap_test = train_test_split(\n",
    "        leap_features, leap_labels, stratify=leap_labels, train_size=.75, random_state=round(time.time()))\n",
    "\n",
    "print(X_leap_train.shape)\n",
    "print(X_leap_test.shape)\n",
    "print(y_leap_train.shape)\n",
    "print(y_leap_test.shape)\n",
    "\n",
    "num_rows, num_cols = 100, 87\n",
    "\n",
    "X_leap_train = X_leap_train.reshape(X_leap_train.shape[0], num_rows, num_cols)\n",
    "X_leap_test = X_leap_test.reshape(X_leap_test.shape[0], num_rows, num_cols)\n",
    "\n",
    "print(\"After reshaping\")\n",
    "print(X_leap_train.shape)\n",
    "print(X_leap_test.shape)\n",
    "print(y_leap_train.shape)\n",
    "print(y_leap_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Voice dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "features = np.loadtxt(os.path.join(dataset_path_prefix, 'voice_merge_features.csv'), delimiter=',')\n",
    "labels = np.array(np.loadtxt(os.path.join(dataset_path_prefix, 'voice_merge_labels.csv'), delimiter=','), dtype=np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hitmann/.local/lib/python3.5/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "X_all, _, y_all, _ = train_test_split(\n",
    "        features, labels, stratify=labels, train_size=.1, random_state=round(time.time()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "enc = OneHotEncoder(sparse=False)\n",
    "y_all = enc.fit_transform(y_all.reshape((-1, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1133, 1280)\n",
      "(284, 1280)\n",
      "(1133, 6)\n",
      "(284, 6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hitmann/.local/lib/python3.5/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "X_voice_train, X_voice_test, y_voice_train, y_voice_test = train_test_split(\n",
    "        X_all, y_all, stratify=y_all, train_size=.8, random_state=round(time.time()))\n",
    "\n",
    "# X_voice_train, X_voice_val, y_voice_train, y_voice_val = train_test_split(\n",
    "#         X_voice_train, y_voice_train, stratify=y_voice_train, train_size=.8, random_state=round(time.time()))\n",
    "\n",
    "print(X_voice_train.shape)\n",
    "print(X_voice_test.shape)\n",
    "# print(X_voice_val.shape)\n",
    "print(y_voice_train.shape)\n",
    "print(y_voice_test.shape)\n",
    "# print(y_voice_val.shape)\n",
    "# num_rows, num_cols = 40, 32\n",
    "\n",
    "# X_leap_train = X_leap_train.reshape(X_leap_train.shape[0], num_rows, num_cols)\n",
    "# X_leap_test = X_leap_test.reshape(X_leap_test.shape[0], num_rows, num_cols)\n",
    "\n",
    "# print(\"After reshaping\")\n",
    "# print(X_voice_train.shape)\n",
    "# print(X_voice_test.shape)\n",
    "# print(y_voice_train.shape)\n",
    "# print(y_voice_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Video dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_features = np.loadtxt(os.path.join(dataset_path_prefix, 'video_merge_features.csv'), delimiter=',')\n",
    "video_labels = np.array(np.loadtxt(os.path.join(dataset_path_prefix, 'video_merge_labels.csv'), delimiter=','), dtype=np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1373, 81920)\n",
      "(1373, 6)\n"
     ]
    }
   ],
   "source": [
    "print(video_features.shape)\n",
    "print(video_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hitmann/.local/lib/python3.5/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1098, 81920)\n",
      "(275, 81920)\n",
      "(1098, 6)\n",
      "(275, 6)\n"
     ]
    }
   ],
   "source": [
    "X_video_train, X_video_test, y_video_train, y_video_test = train_test_split(\n",
    "        video_features, video_labels, stratify=video_labels, train_size=.8, random_state=round(time.time()))\n",
    "\n",
    "# X_video_train, X_video_val, y_video_train, y_video_val = train_test_split(\n",
    "#         X_video_train, y_video_train, stratify=y_video_train, train_size=.9, random_state=round(time.time()))\n",
    "\n",
    "print(X_video_train.shape)\n",
    "print(X_video_test.shape)\n",
    "# print(X_video_val.shape)\n",
    "print(y_video_train.shape)\n",
    "print(y_video_test.shape)\n",
    "# print(y_video_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "del video_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Leapmotion Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LSTM\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "data_dim = 87\n",
    "timesteps = 100\n",
    "num_classes = 6\n",
    "leap_batch_size = 55"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imports\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "from keras.utils import print_summary, plot_model\n",
    "from keras import regularizers\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_representation_layer(model_name, trainable=False, new_model=False):\n",
    "    \n",
    "    model = load_model(os.path.join(model_path_prefix, model_name))\n",
    "    if new_model:\n",
    "        model = Sequential.from_config(model.get_config())\n",
    "    else:\n",
    "        model.trainable = trainable\n",
    "    \n",
    "    return model, model.layers[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "leap_model, leapmotion_representation_output = extract_representation_layer(\"leap_model.h5\", trainable=True, new_model=False)\n",
    "voice_model, voice_representation_output = extract_representation_layer(\"voice_model.h5\", trainable=True, new_model=False)\n",
    "video_model, video_representation_output = extract_representation_layer(\"video_model.h5\", trainable=True, new_model=False)\n",
    "# leap_model = load_model(\"leap_model.h5\")\n",
    "# voice_model = load_model(\"voice_model.h5\")\n",
    "# video_model = ResearchModels(len(data.classes), model_name, seq_length, saved_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "284/284 [==============================] - 5s 16ms/step\n",
      "\n",
      "Test loss: 0.463952642931\n",
      "Test accuracy: 0.855633802817\n"
     ]
    }
   ],
   "source": [
    "score = voice_model.evaluate(X_voice_test, y_voice_test, verbose=1)\n",
    "print()\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Merge, concatenate\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hitmann/.local/lib/python3.5/site-packages/ipykernel_launcher.py:9: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "# merge_layer = concatenate([leapmotion_representation_output, voice_representation_output])\n",
    "# dense_layer = Dense(64, activation='relu', name=\"merge_dense\")(merge_layer)\n",
    "# dense_layer = Dropout(0.5, name=\"merge_dropout\")(dense_layer)\n",
    "# output_layer = Dense(num_classes, activation='softmax', name=\"merge_output\")(dense_layer)\n",
    "\n",
    "# merge_model = Model(inputs=[leap_model.input, voice_model.input], outputs=output_layer)\n",
    "\n",
    "merge_model = Sequential()\n",
    "merge_model.add(Merge([video_representation_output, leapmotion_representation_output, voice_representation_output], mode='concat', concat_axis=-1))\n",
    "\n",
    "merge_model.add(Dense(256, activation='relu', name=\"merge_dense_1\"))\n",
    "merge_model.add(Dropout(0.5, name=\"merge_dropout_1\"))\n",
    "merge_model.add(Dense(256, activation='relu', name=\"merge_dense_2\"))\n",
    "merge_model.add(Dropout(0.5, name=\"merge_dropout_2\"))\n",
    "merge_model.add(Dense(num_classes, activation='softmax', name=\"merge_output\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = RMSprop(lr=5e-5)\n",
    "\n",
    "merge_model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4435 samples, validate on 887 samples\n",
      "Epoch 1/5\n",
      "4435/4435 [==============================] - 76s 17ms/step - loss: 0.1938 - acc: 0.9522 - val_loss: 0.0747 - val_acc: 0.9921\n",
      "Epoch 2/5\n",
      "4435/4435 [==============================] - 76s 17ms/step - loss: 0.1659 - acc: 0.9626 - val_loss: 0.0766 - val_acc: 0.9910\n",
      "Epoch 3/5\n",
      "4435/4435 [==============================] - 78s 18ms/step - loss: 0.1548 - acc: 0.9671 - val_loss: 0.0606 - val_acc: 0.9932\n",
      "Epoch 4/5\n",
      "4435/4435 [==============================] - 79s 18ms/step - loss: 0.1367 - acc: 0.9763 - val_loss: 0.0541 - val_acc: 0.9944\n",
      "Epoch 5/5\n",
      "4435/4435 [==============================] - 77s 17ms/step - loss: 0.1188 - acc: 0.9756 - val_loss: 0.0511 - val_acc: 0.9921\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7f944bacf8>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge_model.fit([X_merge_video_train, X_merge_leap_train, X_merge_voice_train],\\\n",
    "          y_merge_train,\n",
    "          batch_size=64, shuffle=False,\n",
    "          epochs=5,\n",
    "          verbose=1,\n",
    "          validation_data=([X_merge_video_val, X_merge_leap_val, X_merge_voice_val], y_merge_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1260/1260 [==============================] - 7s 5ms/step\n",
      "\n",
      "Test loss: 0.188800419798\n",
      "Test accuracy: 0.964285714475\n"
     ]
    }
   ],
   "source": [
    "score = merge_model.evaluate([X_merge_video_test, X_merge_leap_test, X_merge_voice_test], y_merge_test, verbose=1)\n",
    "print()\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/engine/topology.py:1271: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  return cls(**config)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The layer has never been called and thus has no defined output shape.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-50f5ec36dc93>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmerge_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"merge_model.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/models.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'No model found in config file.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0mmodel_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_from_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0;31m# set weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/models.py\u001b[0m in \u001b[0;36mmodel_from_config\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m    315\u001b[0m                         \u001b[0;34m'Maybe you meant to use '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m                         '`Sequential.from_config(config)`?')\n\u001b[0;32m--> 317\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mlayer_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/layers/__init__.py\u001b[0m in \u001b[0;36mdeserialize\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m     53\u001b[0m                                     \u001b[0mmodule_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m                                     \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m                                     printable_module_name='layer')\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    142\u001b[0m                 return cls.from_config(config['config'],\n\u001b[1;32m    143\u001b[0m                                        custom_objects=dict(list(_GLOBAL_CUSTOM_OBJECTS.items()) +\n\u001b[0;32m--> 144\u001b[0;31m                                                            list(custom_objects.items())))\n\u001b[0m\u001b[1;32m    145\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mCustomObjectScope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'config'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/models.py\u001b[0m in \u001b[0;36mfrom_config\u001b[0;34m(cls, config, custom_objects)\u001b[0m\n\u001b[1;32m   1366\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfrom_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'class_name'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'class_name'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Merge'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1368\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_from_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1370\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/models.py\u001b[0m in \u001b[0;36mlegacy_from_config\u001b[0;34m(cls, config, layer_cache)\u001b[0m\n\u001b[1;32m   1442\u001b[0m                 \u001b[0mmerge_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerge_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1443\u001b[0m             \u001b[0mfirst_layer_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'layers'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmerge_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1444\u001b[0;31m             \u001b[0mmerge\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlegacy_layers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMerge\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst_layer_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1445\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1446\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/legacy/layers.py\u001b[0m in \u001b[0;36mfrom_config\u001b[0;34m(cls, config)\u001b[0m\n\u001b[1;32m    401\u001b[0m         \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'output_shape'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m         \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'output_mask'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMerge\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36mfrom_config\u001b[0;34m(cls, config)\u001b[0m\n\u001b[1;32m   1269\u001b[0m             \u001b[0mA\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1270\u001b[0m         \"\"\"\n\u001b[0;32m-> 1271\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1273\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcount_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/legacy/layers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, layers, mode, concat_axis, dot_axes, output_shape, output_mask, arguments, node_indices, tensor_indices, name)\u001b[0m\n\u001b[1;32m    116\u001b[0m             self._arguments_validation(layers, mode,\n\u001b[1;32m    117\u001b[0m                                        \u001b[0mconcat_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdot_axes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m                                        node_indices, tensor_indices)\n\u001b[0m\u001b[1;32m    119\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0minput_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/legacy/layers.py\u001b[0m in \u001b[0;36m_arguments_validation\u001b[0;34m(self, layers, mode, concat_axis, dot_axes, node_indices, tensor_indices)\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0minput_shapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m             \u001b[0mlayer_output_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_output_shape_at\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_indices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_output_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m                 \u001b[0;31m# Case: the layer has multiple output tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36mget_output_shape_at\u001b[0;34m(self, node_index)\u001b[0m\n\u001b[1;32m    856\u001b[0m         return self._get_node_attribute_at_index(node_index,\n\u001b[1;32m    857\u001b[0m                                                  \u001b[0;34m'output_shapes'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 858\u001b[0;31m                                                  'output shape')\n\u001b[0m\u001b[1;32m    859\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_input_at\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36m_get_node_attribute_at_index\u001b[0;34m(self, node_index, attr, attr_name)\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inbound_nodes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m             raise RuntimeError('The layer has never been called '\n\u001b[0;32m--> 814\u001b[0;31m                                'and thus has no defined ' + attr_name + '.')\n\u001b[0m\u001b[1;32m    815\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inbound_nodes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mnode_index\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m             raise ValueError('Asked to get ' + attr_name +\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The layer has never been called and thus has no defined output shape."
     ]
    }
   ],
   "source": [
    "merge_model = load_model(\"merge_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the merged dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_merge_data(X_voice, y_voice,\\\n",
    "                        X_leap, y_leap,\\\n",
    "                        X_video, y_video,\\\n",
    "                       augment_index=1, ):\n",
    "\n",
    "    X_merge_voice = []\n",
    "    X_merge_leap = []\n",
    "    X_merge_video = []\n",
    "    y_merge = []\n",
    "\n",
    "    for i in range(6):\n",
    "\n",
    "        voice_tmp = list(map(lambda d:d[0], filter(lambda d: np.argmax(d[1])==i, zip(X_voice,y_voice))))\n",
    "        leap_tmp = list(map(lambda d:d[0], filter(lambda d: np.argmax(d[1])==i, zip(X_leap,y_leap))))\n",
    "        video_tmp = list(map(lambda d:d[0], filter(lambda d: np.argmax(d[1])==i, zip(X_video,y_video))))\n",
    "        \n",
    "        for _ in range(augment_index):\n",
    "            \n",
    "            shuffle(voice_tmp)\n",
    "            shuffle(leap_tmp)\n",
    "            shuffle(video_tmp)\n",
    "\n",
    "            for tuple_3 in zip(voice_tmp, leap_tmp, video_tmp):\n",
    "                X_merge_voice.append(tuple_3[0])\n",
    "                X_merge_leap.append(tuple_3[1])\n",
    "                X_merge_video.append(tuple_3[2])\n",
    "\n",
    "                y_merge.append(i)\n",
    "                \n",
    "    ohe = OneHotEncoder(sparse=False)\n",
    "    \n",
    "    return np.array(X_merge_voice), np.array(X_merge_leap), np.array(X_merge_video), ohe.fit_transform(np.array(y_merge).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_merge_voice_train,\\\n",
    "X_merge_leap_train,\\\n",
    "X_merge_video_train,\\\n",
    "y_merge_train = generate_merge_data(X_voice_train,\\\n",
    "                                    y_voice_train,\\\n",
    "                                    X_leap_train,\\\n",
    "                                    y_leap_train,\\\n",
    "                                    X_video_train,\\\n",
    "                                    y_video_train,\\\n",
    "                                    augment_index=5)\n",
    "\n",
    "X_merge_voice_val,\\\n",
    "X_merge_leap_val,\\\n",
    "X_merge_video_val,\\\n",
    "y_merge_val = generate_merge_data(X_voice_train,\\\n",
    "                                    y_voice_train,\\\n",
    "                                    X_leap_train,\\\n",
    "                                    y_leap_train,\\\n",
    "                                    X_video_train,\\\n",
    "                                    y_video_train,\\\n",
    "                                    augment_index=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4435, 1280)\n",
      "(4435, 100, 87)\n",
      "(4435, 81920)\n",
      "(4435, 6)\n"
     ]
    }
   ],
   "source": [
    "print((X_merge_voice_train.shape))\n",
    "print((X_merge_leap_train.shape))\n",
    "print((X_merge_video_train.shape))\n",
    "print((y_merge_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(887, 1280)\n",
      "(887, 100, 87)\n",
      "(887, 81920)\n",
      "(887, 6)\n"
     ]
    }
   ],
   "source": [
    "print((X_merge_voice_val.shape))\n",
    "print((X_merge_leap_val.shape))\n",
    "print((X_merge_video_val.shape))\n",
    "print((y_merge_val.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_merge_voice_test,\\\n",
    "X_merge_leap_test,\\\n",
    "X_merge_video_test,\\\n",
    "y_merge_test = generate_merge_data(X_voice_test,\\\n",
    "                                    y_voice_test,\\\n",
    "                                    X_leap_test,\\\n",
    "                                    y_leap_test,\\\n",
    "                                    X_video_test,\\\n",
    "                                    y_video_test,\\\n",
    "                                    augment_index=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1260, 1280)\n",
      "(1260, 100, 87)\n",
      "(1260, 81920)\n",
      "(1260, 6)\n"
     ]
    }
   ],
   "source": [
    "print((X_merge_voice_test.shape))\n",
    "print((X_merge_leap_test.shape))\n",
    "print((X_merge_video_test.shape))\n",
    "print((y_merge_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1260/1260 [==============================] - 8s 6ms/step\n"
     ]
    }
   ],
   "source": [
    "acc = []\n",
    "num_test = 50\n",
    "\n",
    "for i in range(num_test):\n",
    "    \n",
    "    if i > 0 and i % 5 == 0:\n",
    "        print(\"Test %d times\" % (i))\n",
    "        \n",
    "    X_merge_voice_test,\\\n",
    "    X_merge_leap_test,\\\n",
    "    X_merge_video_test,\\\n",
    "    y_merge_test = generate_merge_data(X_voice_test,\\\n",
    "                                        y_voice_test,\\\n",
    "                                        X_leap_test,\\\n",
    "                                        y_leap_test,\\\n",
    "                                        X_video_test,\\\n",
    "                                        y_video_test,\\\n",
    "                                        augment_index=5)\n",
    "    \n",
    "    score = merge_model.evaluate([X_merge_video_test, X_merge_leap_test, X_merge_voice_test], y_merge_test, verbose=1)\n",
    "    acc.append(score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(list(range(10)), acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
