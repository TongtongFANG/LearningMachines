{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import librosa\n",
    "from librosa import display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from matplotlib.pyplot import specgram\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "plt.rcParams['font.serif'] = 'Ubuntu'\n",
    "plt.rcParams['font.monospace'] = 'Ubuntu Mono'\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.rcParams['axes.labelsize'] = 11\n",
    "plt.rcParams['axes.labelweight'] = 'bold'\n",
    "plt.rcParams['axes.titlesize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 10\n",
    "plt.rcParams['ytick.labelsize'] = 10\n",
    "plt.rcParams['legend.fontsize'] = 11\n",
    "plt.rcParams['figure.titlesize'] = 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "features = np.loadtxt('nn_simple_features.csv', delimiter=',')\n",
    "labels = np.array(np.loadtxt('nn_simple_labels.csv', delimiter=','), dtype=np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "X_all = features\n",
    "y_all = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8544, 1280)\n",
      "(8544, 5)\n",
      "(1508, 1280)\n",
      "(1508, 5)\n",
      "(1774, 1280)\n",
      "(1774, 5)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "\n",
    "X_not_test, X_test, y_not_rest, y_test = train_test_split(\n",
    "    X_all, y_all, stratify=y_all, train_size=.85, random_state=round(time.time()))\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_not_test, y_not_rest, stratify=y_not_rest, train_size=.85, random_state=round(time.time()))\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_val.shape)\n",
    "print(y_val.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "# learning_rate = 0.005\n",
    "\n",
    "with tf.name_scope(\"learning_rate\"):\n",
    "    global_step = tf.Variable(0, trainable=False)\n",
    "    starter_learning_rate = 0.005\n",
    "    learning_rate = tf.train.exponential_decay(starter_learning_rate, global_step,\n",
    "                                               75, 0.99, staircase=True)\n",
    "    tf.summary.scalar(\"learning_rate\", learning_rate)\n",
    "\n",
    "epochs = 40\n",
    "batch_size = 32\n",
    "\n",
    "# Network Parameters\n",
    "n_input = 40 * 32\n",
    "n_classes = 5\n",
    "dropout = .8 # Dropout, probability to keep units\n",
    "\n",
    "# 1. Define Variables and Placeholders\n",
    "x = tf.placeholder(tf.float32, [None, n_input])\n",
    "y = tf.placeholder(tf.float32, [None, n_classes])\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32) #dropout (keep probability)\n",
    "\n",
    "def build_model(x, dropout, activation):\n",
    "    \n",
    "    x = tf.reshape(x, shape=[-1, 40, 32, 1])\n",
    "    \n",
    "    conv1 = tf.layers.conv2d(x, 4, 5, activation=activation)\n",
    "    conv1 = tf.layers.batch_normalization(conv1)\n",
    "    conv1 = tf.layers.max_pooling2d(conv1, 2, 2)\n",
    "    conv1 = tf.nn.dropout(conv1, dropout)\n",
    "    \n",
    "    conv2 = tf.layers.conv2d(conv1, 8, 3, activation=activation)\n",
    "    conv2 = tf.layers.batch_normalization(conv2)\n",
    "    conv2 = tf.layers.max_pooling2d(conv2, 2, 2)\n",
    "    conv2 = tf.nn.dropout(conv2, dropout)\n",
    "    \n",
    "    fc1 = tf.contrib.layers.flatten(conv2)\n",
    "\n",
    "    fc1 = tf.layers.dense(fc1, 128, activation=activation)\n",
    "    fc1 = tf.layers.batch_normalization(fc1)\n",
    "    fc1 = tf.nn.dropout(fc1, dropout)\n",
    "\n",
    "    fc2 = tf.layers.dense(fc1, 64, activation=activation)\n",
    "    fc2 = tf.layers.batch_normalization(fc2)\n",
    "    fc2 = tf.nn.dropout(fc2, dropout)\n",
    "    \n",
    "    out = tf.layers.dense(fc2, n_classes)\n",
    "\n",
    "    return out\n",
    "\n",
    "predictions = build_model(x, keep_prob, activation=tf.nn.relu)\n",
    "# 3. Define the loss function\n",
    "with tf.name_scope(\"loss\"):\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=predictions, labels=y), name='loss')\n",
    "    tf.summary.scalar(\"loss\", loss)\n",
    "    \n",
    "\n",
    "# 4. Define the accuracy \n",
    "with tf.name_scope(\"accuracy\"):\n",
    "    correct_pred = tf.equal(tf.argmax(predictions, 1), tf.argmax(y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "    tf.summary.scalar(\"accuracy\", accuracy)\n",
    "\n",
    "summary = tf.summary.merge_all()\n",
    "# 5. Define an optimizer\n",
    "# optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss, global_step=global_step)\n",
    "\n",
    "def feed_next_batch(train_size, batch_size=64):\n",
    "    \n",
    "    start = 0\n",
    "    while start < train_size:\n",
    "        yield start, start + batch_size\n",
    "        start += batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 20\n",
      "learning_rate: 0.005\n",
      "Training loss: 1.60346 , Training acc:  0.2397\n",
      "Test loss: 1.60229 , Test acc:  0.252653\n",
      "--------------------------------------------------------------------------------\n",
      "Step 40\n",
      "learning_rate: 0.005\n",
      "Training loss: 1.61462 , Training acc:  0.208567\n",
      "Test loss: 1.61443 , Test acc:  0.215517\n",
      "--------------------------------------------------------------------------------\n",
      "Step 60\n",
      "learning_rate: 0.005\n",
      "Training loss: 1.60304 , Training acc:  0.237008\n",
      "Test loss: 1.60472 , Test acc:  0.220822\n",
      "--------------------------------------------------------------------------------\n",
      "Step 80\n",
      "learning_rate: 0.00495\n",
      "Training loss: 1.58033 , Training acc:  0.291901\n",
      "Test loss: 1.58512 , Test acc:  0.265915\n",
      "--------------------------------------------------------------------------------\n",
      "Step 100\n",
      "learning_rate: 0.00495\n",
      "Training loss: 1.50796 , Training acc:  0.346559\n",
      "Test loss: 1.51007 , Test acc:  0.344828\n",
      "--------------------------------------------------------------------------------\n",
      "Step 120\n",
      "learning_rate: 0.00495\n",
      "Training loss: 1.55653 , Training acc:  0.260066\n",
      "Test loss: 1.5607 , Test acc:  0.256631\n",
      "--------------------------------------------------------------------------------\n",
      "Step 140\n",
      "learning_rate: 0.00495\n",
      "Training loss: 1.50297 , Training acc:  0.32713\n",
      "Test loss: 1.51068 , Test acc:  0.337533\n",
      "--------------------------------------------------------------------------------\n",
      "Step 160\n",
      "learning_rate: 0.0049005\n",
      "Training loss: 1.33606 , Training acc:  0.427669\n",
      "Test loss: 1.34024 , Test acc:  0.426393\n",
      "--------------------------------------------------------------------------------\n",
      "Step 180\n",
      "learning_rate: 0.0049005\n",
      "Training loss: 1.29898 , Training acc:  0.469569\n",
      "Test loss: 1.30826 , Test acc:  0.454907\n",
      "--------------------------------------------------------------------------------\n",
      "Step 200\n",
      "learning_rate: 0.0049005\n",
      "Training loss: 1.26312 , Training acc:  0.449087\n",
      "Test loss: 1.27365 , Test acc:  0.441645\n",
      "--------------------------------------------------------------------------------\n",
      "Step 220\n",
      "learning_rate: 0.0049005\n",
      "Training loss: 1.24941 , Training acc:  0.479752\n",
      "Test loss: 1.26123 , Test acc:  0.468833\n",
      "--------------------------------------------------------------------------------\n",
      "Step 240\n",
      "learning_rate: 0.00485149\n",
      "Training loss: 1.20927 , Training acc:  0.509831\n",
      "Test loss: 1.22198 , Test acc:  0.494032\n",
      "--------------------------------------------------------------------------------\n",
      "Step 260\n",
      "learning_rate: 0.00485149\n",
      "Training loss: 1.17839 , Training acc:  0.525281\n",
      "Test loss: 1.19757 , Test acc:  0.494695\n",
      "--------------------------------------------------------------------------------\n",
      "Step 280\n",
      "learning_rate: 0.00485149\n",
      "Training loss: 1.15551 , Training acc:  0.523525\n",
      "Test loss: 1.17827 , Test acc:  0.503316\n",
      "--------------------------------------------------------------------------------\n",
      "Step 300\n",
      "learning_rate: 0.00480298\n",
      "Training loss: 1.09863 , Training acc:  0.552903\n",
      "Test loss: 1.116 , Test acc:  0.539788\n",
      "--------------------------------------------------------------------------------\n",
      "Step 320\n",
      "learning_rate: 0.00480298\n",
      "Training loss: 1.12568 , Training acc:  0.532772\n",
      "Test loss: 1.14573 , Test acc:  0.517241\n",
      "--------------------------------------------------------------------------------\n",
      "Step 340\n",
      "learning_rate: 0.00480298\n",
      "Training loss: 1.0571 , Training acc:  0.547402\n",
      "Test loss: 1.08712 , Test acc:  0.535809\n",
      "--------------------------------------------------------------------------------\n",
      "Step 360\n",
      "learning_rate: 0.00480298\n",
      "Training loss: 1.10736 , Training acc:  0.539911\n",
      "Test loss: 1.14082 , Test acc:  0.505968\n",
      "--------------------------------------------------------------------------------\n",
      "Step 380\n",
      "learning_rate: 0.00475495\n",
      "Training loss: 1.06082 , Training acc:  0.590239\n",
      "Test loss: 1.08305 , Test acc:  0.559019\n",
      "--------------------------------------------------------------------------------\n",
      "Step 400\n",
      "learning_rate: 0.00475495\n",
      "Training loss: 1.07075 , Training acc:  0.552552\n",
      "Test loss: 1.09528 , Test acc:  0.539788\n",
      "--------------------------------------------------------------------------------\n",
      "Step 420\n",
      "learning_rate: 0.00475495\n",
      "Training loss: 1.01615 , Training acc:  0.58345\n",
      "Test loss: 1.04582 , Test acc:  0.563661\n",
      "--------------------------------------------------------------------------------\n",
      "Step 440\n",
      "learning_rate: 0.00475495\n",
      "Training loss: 1.00354 , Training acc:  0.579237\n",
      "Test loss: 1.02591 , Test acc:  0.569629\n",
      "--------------------------------------------------------------------------------\n",
      "Step 460\n",
      "learning_rate: 0.0047074\n",
      "Training loss: 0.976831 , Training acc:  0.626053\n",
      "Test loss: 1.00391 , Test acc:  0.585544\n",
      "--------------------------------------------------------------------------------\n",
      "Step 480\n",
      "learning_rate: 0.0047074\n",
      "Training loss: 0.983604 , Training acc:  0.6147\n",
      "Test loss: 1.00843 , Test acc:  0.598143\n",
      "--------------------------------------------------------------------------------\n",
      "Step 500\n",
      "learning_rate: 0.0047074\n",
      "Training loss: 0.967265 , Training acc:  0.610604\n",
      "Test loss: 0.989586 , Test acc:  0.598806\n",
      "--------------------------------------------------------------------------------\n",
      "Step 520\n",
      "learning_rate: 0.0047074\n",
      "Training loss: 1.08456 , Training acc:  0.531835\n",
      "Test loss: 1.0983 , Test acc:  0.525862\n",
      "--------------------------------------------------------------------------------\n",
      "Step 540\n",
      "learning_rate: 0.00466033\n",
      "Training loss: 1.00358 , Training acc:  0.592814\n",
      "Test loss: 1.03955 , Test acc:  0.568302\n",
      "--------------------------------------------------------------------------------\n",
      "Step 560\n",
      "learning_rate: 0.00466033\n",
      "Training loss: 1.0024 , Training acc:  0.587079\n",
      "Test loss: 1.03632 , Test acc:  0.574934\n",
      "--------------------------------------------------------------------------------\n",
      "Step 580\n",
      "learning_rate: 0.00466033\n",
      "Training loss: 0.94452 , Training acc:  0.64279\n",
      "Test loss: 0.976742 , Test acc:  0.625995\n",
      "--------------------------------------------------------------------------------\n",
      "Step 600\n",
      "learning_rate: 0.00461372\n",
      "Training loss: 0.903966 , Training acc:  0.654494\n",
      "Test loss: 0.943684 , Test acc:  0.632626\n",
      "--------------------------------------------------------------------------------\n",
      "Step 620\n",
      "learning_rate: 0.00461372\n",
      "Training loss: 0.960826 , Training acc:  0.604284\n",
      "Test loss: 0.989481 , Test acc:  0.59748\n",
      "--------------------------------------------------------------------------------\n",
      "Step 640\n",
      "learning_rate: 0.00461372\n",
      "Training loss: 0.931277 , Training acc:  0.635651\n",
      "Test loss: 0.970258 , Test acc:  0.608753\n",
      "--------------------------------------------------------------------------------\n",
      "Step 660\n",
      "learning_rate: 0.00461372\n",
      "Training loss: 0.932926 , Training acc:  0.609316\n",
      "Test loss: 0.964658 , Test acc:  0.595491\n",
      "--------------------------------------------------------------------------------\n",
      "Step 680\n",
      "learning_rate: 0.00456759\n",
      "Training loss: 0.886948 , Training acc:  0.676849\n",
      "Test loss: 0.941532 , Test acc:  0.641247\n",
      "--------------------------------------------------------------------------------\n",
      "Step 700\n",
      "learning_rate: 0.00456759\n",
      "Training loss: 0.866961 , Training acc:  0.668539\n",
      "Test loss: 0.91078 , Test acc:  0.649867\n",
      "--------------------------------------------------------------------------------\n",
      "Step 720\n",
      "learning_rate: 0.00456759\n",
      "Training loss: 0.840238 , Training acc:  0.687734\n",
      "Test loss: 0.903244 , Test acc:  0.651857\n",
      "--------------------------------------------------------------------------------\n",
      "Step 740\n",
      "learning_rate: 0.00456759\n",
      "Training loss: 0.802412 , Training acc:  0.710323\n",
      "Test loss: 0.864401 , Test acc:  0.689655\n",
      "--------------------------------------------------------------------------------\n",
      "Step 760\n",
      "learning_rate: 0.00452191\n",
      "Training loss: 0.742146 , Training acc:  0.720974\n",
      "Test loss: 0.802911 , Test acc:  0.691645\n",
      "--------------------------------------------------------------------------------\n",
      "Step 780\n",
      "learning_rate: 0.00452191\n",
      "Training loss: 0.735607 , Training acc:  0.730571\n",
      "Test loss: 0.806164 , Test acc:  0.698276\n",
      "--------------------------------------------------------------------------------\n",
      "Step 800\n",
      "learning_rate: 0.00452191\n",
      "Training loss: 0.816913 , Training acc:  0.724719\n",
      "Test loss: 0.873292 , Test acc:  0.682361\n",
      "--------------------------------------------------------------------------------\n",
      "Step 820\n",
      "learning_rate: 0.00452191\n",
      "Training loss: 0.753676 , Training acc:  0.729401\n",
      "Test loss: 0.817859 , Test acc:  0.698276\n",
      "--------------------------------------------------------------------------------\n",
      "Step 840\n",
      "learning_rate: 0.00447669\n",
      "Training loss: 0.805743 , Training acc:  0.684574\n",
      "Test loss: 0.878775 , Test acc:  0.66313\n",
      "--------------------------------------------------------------------------------\n",
      "Step 860\n",
      "learning_rate: 0.00447669\n",
      "Training loss: 0.750657 , Training acc:  0.720506\n",
      "Test loss: 0.812547 , Test acc:  0.696286\n",
      "--------------------------------------------------------------------------------\n",
      "Step 880\n",
      "learning_rate: 0.00447669\n",
      "Training loss: 0.737356 , Training acc:  0.733263\n",
      "Test loss: 0.799483 , Test acc:  0.700265\n",
      "--------------------------------------------------------------------------------\n",
      "Step 900\n",
      "learning_rate: 0.00443192\n",
      "Training loss: 0.693791 , Training acc:  0.742743\n",
      "Test loss: 0.763451 , Test acc:  0.709549\n",
      "--------------------------------------------------------------------------------\n",
      "Step 920\n",
      "learning_rate: 0.00443192\n",
      "Training loss: 0.733306 , Training acc:  0.737828\n",
      "Test loss: 0.792231 , Test acc:  0.698939\n",
      "--------------------------------------------------------------------------------\n",
      "Step 940\n",
      "learning_rate: 0.00443192\n",
      "Training loss: 0.736125 , Training acc:  0.7239\n",
      "Test loss: 0.792567 , Test acc:  0.702255\n",
      "--------------------------------------------------------------------------------\n",
      "Step 960\n",
      "learning_rate: 0.00443192\n",
      "Training loss: 0.710514 , Training acc:  0.740052\n",
      "Test loss: 0.767234 , Test acc:  0.717507\n",
      "--------------------------------------------------------------------------------\n",
      "Step 980\n",
      "learning_rate: 0.00438761\n",
      "Training loss: 0.669144 , Training acc:  0.766854\n",
      "Test loss: 0.732546 , Test acc:  0.746684\n",
      "--------------------------------------------------------------------------------\n",
      "Step 1000\n",
      "learning_rate: 0.00438761\n",
      "Training loss: 0.732814 , Training acc:  0.717463\n",
      "Test loss: 0.79582 , Test acc:  0.69496\n",
      "--------------------------------------------------------------------------------\n",
      "Step 1020\n",
      "learning_rate: 0.00438761\n",
      "Training loss: 0.615002 , Training acc:  0.785229\n",
      "Test loss: 0.675163 , Test acc:  0.758621\n",
      "--------------------------------------------------------------------------------\n",
      "Step 1040\n",
      "learning_rate: 0.00438761\n",
      "Training loss: 0.606892 , Training acc:  0.792252\n",
      "Test loss: 0.671051 , Test acc:  0.761273\n",
      "--------------------------------------------------------------------------------\n",
      "Step 1060\n",
      "learning_rate: 0.00434373\n",
      "Training loss: 0.630622 , Training acc:  0.778324\n",
      "Test loss: 0.687089 , Test acc:  0.749337\n",
      "--------------------------------------------------------------------------------\n",
      "Step 1080\n",
      "learning_rate: 0.00434373\n",
      "Training loss: 0.705935 , Training acc:  0.737477\n",
      "Test loss: 0.771982 , Test acc:  0.700928\n",
      "--------------------------------------------------------------------------------\n",
      "Step 1100\n",
      "learning_rate: 0.00434373\n",
      "Training loss: 0.638355 , Training acc:  0.766035\n",
      "Test loss: 0.726509 , Test acc:  0.737401\n",
      "--------------------------------------------------------------------------------\n",
      "Step 1120\n",
      "learning_rate: 0.00434373\n",
      "Training loss: 0.631515 , Training acc:  0.786751\n",
      "Test loss: 0.697286 , Test acc:  0.748674\n",
      "--------------------------------------------------------------------------------\n",
      "Step 1140\n",
      "learning_rate: 0.00430029\n",
      "Training loss: 0.619162 , Training acc:  0.788624\n",
      "Test loss: 0.686912 , Test acc:  0.751326\n",
      "--------------------------------------------------------------------------------\n",
      "Step 1160\n",
      "learning_rate: 0.00430029\n",
      "Training loss: 0.590932 , Training acc:  0.791433\n",
      "Test loss: 0.665319 , Test acc:  0.753979\n",
      "--------------------------------------------------------------------------------\n",
      "Step 1180\n",
      "learning_rate: 0.00430029\n",
      "Training loss: 0.598424 , Training acc:  0.793773\n",
      "Test loss: 0.666786 , Test acc:  0.769894\n",
      "--------------------------------------------------------------------------------\n",
      "Step 1200\n",
      "learning_rate: 0.00425729\n",
      "Training loss: 0.573561 , Training acc:  0.810861\n",
      "Test loss: 0.638434 , Test acc:  0.776525\n",
      "--------------------------------------------------------------------------------\n",
      "Step 1220\n",
      "learning_rate: 0.00425729\n",
      "Training loss: 0.564303 , Training acc:  0.815894\n",
      "Test loss: 0.63924 , Test acc:  0.78183\n",
      "--------------------------------------------------------------------------------\n",
      "Step 1240\n",
      "learning_rate: 0.00425729\n",
      "Training loss: 0.564808 , Training acc:  0.804658\n",
      "Test loss: 0.640497 , Test acc:  0.780504\n",
      "--------------------------------------------------------------------------------\n",
      "Step 1260\n",
      "learning_rate: 0.00425729\n",
      "Training loss: 0.545578 , Training acc:  0.799508\n",
      "Test loss: 0.616713 , Test acc:  0.765915\n",
      "--------------------------------------------------------------------------------\n",
      "Step 1280\n",
      "learning_rate: 0.00421472\n",
      "Training loss: 0.560332 , Training acc:  0.805243\n",
      "Test loss: 0.630394 , Test acc:  0.757958\n",
      "--------------------------------------------------------------------------------\n",
      "Step 1300\n",
      "learning_rate: 0.00421472\n",
      "Training loss: 0.550342 , Training acc:  0.799274\n",
      "Test loss: 0.62386 , Test acc:  0.77321\n",
      "--------------------------------------------------------------------------------\n",
      "Step 1320\n",
      "learning_rate: 0.00421472\n",
      "Training loss: 0.591648 , Training acc:  0.793071\n",
      "Test loss: 0.6728 , Test acc:  0.767241\n",
      "--------------------------------------------------------------------------------\n",
      "Step 1340\n",
      "learning_rate: 0.00421472\n",
      "Training loss: 0.603275 , Training acc:  0.773174\n",
      "Test loss: 0.685542 , Test acc:  0.730106\n",
      "--------------------------------------------------------------------------------\n",
      "Step 1360\n",
      "learning_rate: 0.00417257\n",
      "Training loss: 0.525441 , Training acc:  0.821512\n",
      "Test loss: 0.601995 , Test acc:  0.788462\n",
      "--------------------------------------------------------------------------------\n",
      "Step 1380\n",
      "learning_rate: 0.00417257\n",
      "Training loss: 0.567119 , Training acc:  0.800328\n",
      "Test loss: 0.650828 , Test acc:  0.778515\n",
      "--------------------------------------------------------------------------------\n",
      "Step 1400\n",
      "learning_rate: 0.00417257\n",
      "Training loss: 0.519405 , Training acc:  0.822566\n",
      "Test loss: 0.589687 , Test acc:  0.791777\n",
      "--------------------------------------------------------------------------------\n",
      "Step 1420\n",
      "learning_rate: 0.00417257\n",
      "Training loss: 0.427924 , Training acc:  0.848432\n",
      "Test loss: 0.512363 , Test acc:  0.809682\n",
      "--------------------------------------------------------------------------------\n",
      "Step 1440\n",
      "learning_rate: 0.00413084\n",
      "Training loss: 0.478247 , Training acc:  0.825023\n",
      "Test loss: 0.558606 , Test acc:  0.797745\n",
      "--------------------------------------------------------------------------------\n",
      "Step 1460\n",
      "learning_rate: 0.00413084\n",
      "Training loss: 0.507086 , Training acc:  0.815894\n",
      "Test loss: 0.590139 , Test acc:  0.787798\n",
      "--------------------------------------------------------------------------------\n",
      "Step 1480\n",
      "learning_rate: 0.00413084\n",
      "Training loss: 0.450551 , Training acc:  0.847495\n",
      "Test loss: 0.532372 , Test acc:  0.80305\n",
      "--------------------------------------------------------------------------------\n",
      "Step 1500\n",
      "learning_rate: 0.00408954\n",
      "Training loss: 0.454904 , Training acc:  0.843165\n",
      "Test loss: 0.553026 , Test acc:  0.806366\n",
      "--------------------------------------------------------------------------------\n",
      "Step 1520\n",
      "learning_rate: 0.00408954\n",
      "Training loss: 0.468701 , Training acc:  0.847729\n",
      "Test loss: 0.551666 , Test acc:  0.810345\n",
      "--------------------------------------------------------------------------------\n",
      "Step 1540\n",
      "learning_rate: 0.00408954\n",
      "Training loss: 0.468243 , Training acc:  0.844569\n",
      "Test loss: 0.555935 , Test acc:  0.801061\n",
      "--------------------------------------------------------------------------------\n",
      "Step 1560\n",
      "learning_rate: 0.00408954\n",
      "Training loss: 0.433314 , Training acc:  0.849719\n",
      "Test loss: 0.519645 , Test acc:  0.808355\n",
      "--------------------------------------------------------------------------------\n",
      "Step 1580\n",
      "learning_rate: 0.00404864\n",
      "Training loss: 0.456449 , Training acc:  0.851007\n",
      "Test loss: 0.547348 , Test acc:  0.793103\n",
      "--------------------------------------------------------------------------------\n",
      "Step 1600\n",
      "learning_rate: 0.00404864\n",
      "Training loss: 0.414335 , Training acc:  0.863179\n",
      "Test loss: 0.508817 , Test acc:  0.818302\n",
      "--------------------------------------------------------------------------------\n",
      "Step 1620\n",
      "learning_rate: 0.00404864\n",
      "Training loss: 0.506379 , Training acc:  0.837898\n",
      "Test loss: 0.594679 , Test acc:  0.793103\n",
      "--------------------------------------------------------------------------------\n",
      "Step 1640\n",
      "learning_rate: 0.00404864\n",
      "Training loss: 0.439112 , Training acc:  0.8489\n",
      "Test loss: 0.53099 , Test acc:  0.809019\n",
      "--------------------------------------------------------------------------------\n",
      "Step 1660\n",
      "learning_rate: 0.00400815\n",
      "Training loss: 0.433208 , Training acc:  0.852177\n",
      "Test loss: 0.533988 , Test acc:  0.809682\n",
      "--------------------------------------------------------------------------------\n",
      "Step 1680\n",
      "learning_rate: 0.00400815\n",
      "Training loss: 0.430115 , Training acc:  0.853581\n",
      "Test loss: 0.530925 , Test acc:  0.80305\n",
      "--------------------------------------------------------------------------------\n",
      "Step 1700\n",
      "learning_rate: 0.00400815\n",
      "Training loss: 0.401161 , Training acc:  0.867977\n",
      "Test loss: 0.515351 , Test acc:  0.81565\n",
      "--------------------------------------------------------------------------------\n",
      "Step 1720\n",
      "learning_rate: 0.00400815\n",
      "Training loss: 0.401012 , Training acc:  0.863881\n",
      "Test loss: 0.49686 , Test acc:  0.816313\n",
      "--------------------------------------------------------------------------------\n",
      "Step 1740\n",
      "learning_rate: 0.00396807\n",
      "Training loss: 0.431549 , Training acc:  0.8489\n",
      "Test loss: 0.532499 , Test acc:  0.800398\n",
      "--------------------------------------------------------------------------------\n",
      "Step 1760\n",
      "learning_rate: 0.00396807\n",
      "Training loss: 0.428331 , Training acc:  0.860838\n",
      "Test loss: 0.517682 , Test acc:  0.814987\n",
      "--------------------------------------------------------------------------------\n",
      "Step 1780\n",
      "learning_rate: 0.00396807\n",
      "Training loss: 0.421405 , Training acc:  0.864817\n",
      "Test loss: 0.509597 , Test acc:  0.829576\n",
      "--------------------------------------------------------------------------------\n",
      "Step 1800\n",
      "learning_rate: 0.00392839\n",
      "Training loss: 0.405771 , Training acc:  0.862477\n",
      "Test loss: 0.499618 , Test acc:  0.824934\n",
      "--------------------------------------------------------------------------------\n",
      "Step 1820\n",
      "learning_rate: 0.00392839\n",
      "Training loss: 0.391243 , Training acc:  0.867041\n",
      "Test loss: 0.481899 , Test acc:  0.822281\n",
      "--------------------------------------------------------------------------------\n",
      "Step 1840\n",
      "learning_rate: 0.00392839\n",
      "Training loss: 0.367575 , Training acc:  0.879916\n",
      "Test loss: 0.460247 , Test acc:  0.840849\n",
      "--------------------------------------------------------------------------------\n",
      "Step 1860\n",
      "learning_rate: 0.00392839\n",
      "Training loss: 0.374709 , Training acc:  0.876053\n",
      "Test loss: 0.478053 , Test acc:  0.830239\n",
      "--------------------------------------------------------------------------------\n",
      "Step 1880\n",
      "learning_rate: 0.00388911\n",
      "Training loss: 0.373196 , Training acc:  0.869616\n",
      "Test loss: 0.458799 , Test acc:  0.837533\n",
      "--------------------------------------------------------------------------------\n",
      "Step 1900\n",
      "learning_rate: 0.00388911\n",
      "Training loss: 0.389472 , Training acc:  0.865286\n",
      "Test loss: 0.500544 , Test acc:  0.828912\n",
      "--------------------------------------------------------------------------------\n",
      "Step 1920\n",
      "learning_rate: 0.00388911\n",
      "Training loss: 0.379077 , Training acc:  0.866105\n",
      "Test loss: 0.489582 , Test acc:  0.803714\n",
      "--------------------------------------------------------------------------------\n",
      "Step 1940\n",
      "learning_rate: 0.00388911\n",
      "Training loss: 0.398453 , Training acc:  0.86037\n",
      "Test loss: 0.518391 , Test acc:  0.811671\n",
      "--------------------------------------------------------------------------------\n",
      "Step 1960\n",
      "learning_rate: 0.00385022\n",
      "Training loss: 0.454081 , Training acc:  0.836142\n",
      "Test loss: 0.562405 , Test acc:  0.787798\n",
      "--------------------------------------------------------------------------------\n",
      "Step 1980\n",
      "learning_rate: 0.00385022\n",
      "Training loss: 0.392606 , Training acc:  0.876287\n",
      "Test loss: 0.504306 , Test acc:  0.832891\n",
      "--------------------------------------------------------------------------------\n",
      "Step 2000\n",
      "learning_rate: 0.00385022\n",
      "Training loss: 0.388806 , Training acc:  0.870084\n",
      "Test loss: 0.477485 , Test acc:  0.836207\n",
      "--------------------------------------------------------------------------------\n",
      "Step 2020\n",
      "learning_rate: 0.00385022\n",
      "Training loss: 0.37894 , Training acc:  0.870084\n",
      "Test loss: 0.476557 , Test acc:  0.828912\n",
      "--------------------------------------------------------------------------------\n",
      "Step 2040\n",
      "learning_rate: 0.00381171\n",
      "Training loss: 0.352198 , Training acc:  0.881086\n",
      "Test loss: 0.453521 , Test acc:  0.846817\n",
      "--------------------------------------------------------------------------------\n",
      "Step 2060\n",
      "learning_rate: 0.00381171\n",
      "Training loss: 0.390221 , Training acc:  0.86154\n",
      "Test loss: 0.485083 , Test acc:  0.818302\n",
      "--------------------------------------------------------------------------------\n",
      "Step 2080\n",
      "learning_rate: 0.00381171\n",
      "Training loss: 0.357168 , Training acc:  0.884714\n",
      "Test loss: 0.455656 , Test acc:  0.840186\n",
      "--------------------------------------------------------------------------------\n",
      "Step 2100\n",
      "learning_rate: 0.0037736\n",
      "Training loss: 0.35659 , Training acc:  0.882725\n",
      "Test loss: 0.45402 , Test acc:  0.840186\n",
      "--------------------------------------------------------------------------------\n",
      "Step 2120\n",
      "learning_rate: 0.0037736\n",
      "Training loss: 0.334014 , Training acc:  0.885417\n",
      "Test loss: 0.437594 , Test acc:  0.83687\n",
      "--------------------------------------------------------------------------------\n",
      "Step 2140\n",
      "learning_rate: 0.0037736\n",
      "Training loss: 0.357931 , Training acc:  0.886236\n",
      "Test loss: 0.46548 , Test acc:  0.835544\n",
      "--------------------------------------------------------------------------------\n",
      "Step 2160\n",
      "learning_rate: 0.0037736\n",
      "Training loss: 0.376464 , Training acc:  0.871606\n",
      "Test loss: 0.491749 , Test acc:  0.827586\n",
      "--------------------------------------------------------------------------------\n",
      "Step 2180\n",
      "learning_rate: 0.00373586\n",
      "Training loss: 0.391838 , Training acc:  0.863413\n",
      "Test loss: 0.514634 , Test acc:  0.812334\n",
      "--------------------------------------------------------------------------------\n",
      "Step 2200\n",
      "learning_rate: 0.00373586\n",
      "Training loss: 0.336923 , Training acc:  0.882491\n",
      "Test loss: 0.442958 , Test acc:  0.832891\n",
      "--------------------------------------------------------------------------------\n",
      "Step 2220\n",
      "learning_rate: 0.00373586\n",
      "Training loss: 0.358288 , Training acc:  0.884129\n",
      "Test loss: 0.47058 , Test acc:  0.832228\n",
      "--------------------------------------------------------------------------------\n",
      "Step 2240\n",
      "learning_rate: 0.00373586\n",
      "Training loss: 0.397283 , Training acc:  0.870084\n",
      "Test loss: 0.514205 , Test acc:  0.818965\n",
      "--------------------------------------------------------------------------------\n",
      "Step 2260\n",
      "learning_rate: 0.0036985\n",
      "Training loss: 0.366419 , Training acc:  0.88132\n",
      "Test loss: 0.490808 , Test acc:  0.824934\n",
      "--------------------------------------------------------------------------------\n",
      "Step 2280\n",
      "learning_rate: 0.0036985\n",
      "Training loss: 0.334809 , Training acc:  0.892088\n",
      "Test loss: 0.453472 , Test acc:  0.846154\n",
      "--------------------------------------------------------------------------------\n",
      "Step 2300\n",
      "learning_rate: 0.0036985\n",
      "Training loss: 0.363597 , Training acc:  0.873947\n",
      "Test loss: 0.47697 , Test acc:  0.830239\n",
      "--------------------------------------------------------------------------------\n",
      "Step 2320\n",
      "learning_rate: 0.0036985\n",
      "Training loss: 0.31203 , Training acc:  0.891503\n",
      "Test loss: 0.439099 , Test acc:  0.846817\n",
      "--------------------------------------------------------------------------------\n",
      "Step 2340\n",
      "learning_rate: 0.00366152\n",
      "Training loss: 0.311226 , Training acc:  0.895833\n",
      "Test loss: 0.430994 , Test acc:  0.849469\n",
      "--------------------------------------------------------------------------------\n",
      "Step 2360\n",
      "learning_rate: 0.00366152\n",
      "Training loss: 0.311672 , Training acc:  0.900164\n",
      "Test loss: 0.428791 , Test acc:  0.854111\n",
      "--------------------------------------------------------------------------------\n",
      "Step 2380\n",
      "learning_rate: 0.00366152\n",
      "Training loss: 0.304762 , Training acc:  0.90309\n",
      "Test loss: 0.423428 , Test acc:  0.854111\n",
      "--------------------------------------------------------------------------------\n",
      "Step 2400\n",
      "learning_rate: 0.0036249\n",
      "Training loss: 0.31539 , Training acc:  0.903792\n",
      "Test loss: 0.440942 , Test acc:  0.840186\n",
      "--------------------------------------------------------------------------------\n",
      "Step 2420\n",
      "learning_rate: 0.0036249\n",
      "Training loss: 0.314151 , Training acc:  0.905899\n",
      "Test loss: 0.433125 , Test acc:  0.86008\n",
      "--------------------------------------------------------------------------------\n",
      "Step 2440\n",
      "learning_rate: 0.0036249\n",
      "Training loss: 0.320618 , Training acc:  0.895716\n",
      "Test loss: 0.432369 , Test acc:  0.848143\n",
      "--------------------------------------------------------------------------------\n",
      "Step 2460\n",
      "learning_rate: 0.0036249\n",
      "Training loss: 0.337715 , Training acc:  0.886236\n",
      "Test loss: 0.457485 , Test acc:  0.84748\n",
      "--------------------------------------------------------------------------------\n",
      "Step 2480\n",
      "learning_rate: 0.00358865\n",
      "Training loss: 0.329444 , Training acc:  0.895833\n",
      "Test loss: 0.441367 , Test acc:  0.852785\n",
      "--------------------------------------------------------------------------------\n",
      "Step 2500\n",
      "learning_rate: 0.00358865\n",
      "Training loss: 0.325622 , Training acc:  0.901685\n",
      "Test loss: 0.447201 , Test acc:  0.858753\n",
      "--------------------------------------------------------------------------------\n",
      "Step 2520\n",
      "learning_rate: 0.00358865\n",
      "Training loss: 0.31208 , Training acc:  0.89993\n",
      "Test loss: 0.418844 , Test acc:  0.856764\n",
      "--------------------------------------------------------------------------------\n",
      "Step 2540\n",
      "learning_rate: 0.00358865\n",
      "Training loss: 0.2977 , Training acc:  0.897472\n",
      "Test loss: 0.408188 , Test acc:  0.858753\n",
      "--------------------------------------------------------------------------------\n",
      "Step 2560\n",
      "learning_rate: 0.00355277\n",
      "Training loss: 0.290367 , Training acc:  0.909176\n",
      "Test loss: 0.403632 , Test acc:  0.85809\n",
      "--------------------------------------------------------------------------------\n",
      "Step 2580\n",
      "learning_rate: 0.00355277\n",
      "Training loss: 0.316275 , Training acc:  0.896536\n",
      "Test loss: 0.428343 , Test acc:  0.843501\n",
      "--------------------------------------------------------------------------------\n",
      "Step 2600\n",
      "learning_rate: 0.00355277\n",
      "Training loss: 0.325738 , Training acc:  0.893375\n",
      "Test loss: 0.447345 , Test acc:  0.843501\n",
      "--------------------------------------------------------------------------------\n",
      "Step 2620\n",
      "learning_rate: 0.00355277\n",
      "Training loss: 0.298747 , Training acc:  0.897121\n",
      "Test loss: 0.431546 , Test acc:  0.842838\n",
      "--------------------------------------------------------------------------------\n",
      "Step 2640\n",
      "learning_rate: 0.00351724\n",
      "Training loss: 0.316222 , Training acc:  0.891035\n",
      "Test loss: 0.448118 , Test acc:  0.835544\n",
      "--------------------------------------------------------------------------------\n",
      "Step 2660\n",
      "learning_rate: 0.00351724\n",
      "Training loss: 0.450121 , Training acc:  0.843399\n",
      "Test loss: 0.60141 , Test acc:  0.791114\n",
      "--------------------------------------------------------------------------------\n",
      "Step 2680\n",
      "learning_rate: 0.00351724\n",
      "Training loss: 0.317721 , Training acc:  0.891737\n",
      "Test loss: 0.45516 , Test acc:  0.824271\n",
      "--------------------------------------------------------------------------------\n",
      "Step 2700\n",
      "learning_rate: 0.00348207\n",
      "Training loss: 0.291132 , Training acc:  0.907537\n",
      "Test loss: 0.416672 , Test acc:  0.849469\n",
      "--------------------------------------------------------------------------------\n",
      "Step 2720\n",
      "learning_rate: 0.00348207\n",
      "Training loss: 0.286666 , Training acc:  0.903792\n",
      "Test loss: 0.42089 , Test acc:  0.844164\n",
      "--------------------------------------------------------------------------------\n",
      "Step 2740\n",
      "learning_rate: 0.00348207\n",
      "Training loss: 0.275247 , Training acc:  0.910464\n",
      "Test loss: 0.409524 , Test acc:  0.858753\n",
      "--------------------------------------------------------------------------------\n",
      "Step 2760\n",
      "learning_rate: 0.00348207\n",
      "Training loss: 0.29983 , Training acc:  0.898993\n",
      "Test loss: 0.4318 , Test acc:  0.842838\n",
      "--------------------------------------------------------------------------------\n",
      "Step 2780\n",
      "learning_rate: 0.00344725\n",
      "Training loss: 0.267717 , Training acc:  0.912453\n",
      "Test loss: 0.4016 , Test acc:  0.853448\n",
      "--------------------------------------------------------------------------------\n",
      "Step 2800\n",
      "learning_rate: 0.00344725\n",
      "Training loss: 0.268888 , Training acc:  0.91257\n",
      "Test loss: 0.395308 , Test acc:  0.866048\n",
      "--------------------------------------------------------------------------------\n",
      "Step 2820\n",
      "learning_rate: 0.00344725\n",
      "Training loss: 0.287562 , Training acc:  0.909176\n",
      "Test loss: 0.417602 , Test acc:  0.852122\n",
      "--------------------------------------------------------------------------------\n",
      "Step 2840\n",
      "learning_rate: 0.00344725\n",
      "Training loss: 0.324082 , Training acc:  0.892205\n",
      "Test loss: 0.449344 , Test acc:  0.831565\n",
      "--------------------------------------------------------------------------------\n",
      "Step 2860\n",
      "learning_rate: 0.00341277\n",
      "Training loss: 0.290342 , Training acc:  0.906016\n",
      "Test loss: 0.416657 , Test acc:  0.862732\n",
      "--------------------------------------------------------------------------------\n",
      "Step 2880\n",
      "learning_rate: 0.00341277\n",
      "Training loss: 0.383437 , Training acc:  0.873478\n",
      "Test loss: 0.517338 , Test acc:  0.819629\n",
      "--------------------------------------------------------------------------------\n",
      "Step 2900\n",
      "learning_rate: 0.00341277\n",
      "Training loss: 0.442194 , Training acc:  0.840707\n",
      "Test loss: 0.577554 , Test acc:  0.788462\n",
      "--------------------------------------------------------------------------------\n",
      "Step 2920\n",
      "learning_rate: 0.00341277\n",
      "Training loss: 0.308771 , Training acc:  0.901568\n",
      "Test loss: 0.443548 , Test acc:  0.839523\n",
      "--------------------------------------------------------------------------------\n",
      "Step 2940\n",
      "learning_rate: 0.00337865\n",
      "Training loss: 0.28514 , Training acc:  0.905782\n",
      "Test loss: 0.410887 , Test acc:  0.848806\n",
      "--------------------------------------------------------------------------------\n",
      "Step 2960\n",
      "learning_rate: 0.00337865\n",
      "Training loss: 0.334961 , Training acc:  0.881554\n",
      "Test loss: 0.46972 , Test acc:  0.823607\n",
      "--------------------------------------------------------------------------------\n",
      "Step 2980\n",
      "learning_rate: 0.00337865\n",
      "Training loss: 0.296957 , Training acc:  0.902973\n",
      "Test loss: 0.437062 , Test acc:  0.840849\n",
      "--------------------------------------------------------------------------------\n",
      "Step 3000\n",
      "learning_rate: 0.00334486\n",
      "Training loss: 0.2777 , Training acc:  0.917954\n",
      "Test loss: 0.412971 , Test acc:  0.860743\n",
      "--------------------------------------------------------------------------------\n",
      "Step 3020\n",
      "learning_rate: 0.00334486\n",
      "Training loss: 0.266155 , Training acc:  0.913155\n",
      "Test loss: 0.406657 , Test acc:  0.854111\n",
      "--------------------------------------------------------------------------------\n",
      "Step 3040\n",
      "learning_rate: 0.00334486\n",
      "Training loss: 0.261009 , Training acc:  0.909059\n",
      "Test loss: 0.402636 , Test acc:  0.85809\n",
      "--------------------------------------------------------------------------------\n",
      "Step 3060\n",
      "learning_rate: 0.00334486\n",
      "Training loss: 0.287168 , Training acc:  0.903324\n",
      "Test loss: 0.423097 , Test acc:  0.842838\n",
      "--------------------------------------------------------------------------------\n",
      "Step 3080\n",
      "learning_rate: 0.00331141\n",
      "Training loss: 0.307442 , Training acc:  0.900515\n",
      "Test loss: 0.433858 , Test acc:  0.846817\n",
      "--------------------------------------------------------------------------------\n",
      "Step 3100\n",
      "learning_rate: 0.00331141\n",
      "Training loss: 0.279853 , Training acc:  0.912804\n",
      "Test loss: 0.416705 , Test acc:  0.842175\n",
      "--------------------------------------------------------------------------------\n",
      "Step 3120\n",
      "learning_rate: 0.00331141\n",
      "Training loss: 0.296659 , Training acc:  0.898642\n",
      "Test loss: 0.438025 , Test acc:  0.836207\n",
      "--------------------------------------------------------------------------------\n",
      "Step 3140\n",
      "learning_rate: 0.00331141\n",
      "Training loss: 0.243179 , Training acc:  0.920763\n",
      "Test loss: 0.381289 , Test acc:  0.863395\n",
      "--------------------------------------------------------------------------------\n",
      "Step 3160\n",
      "learning_rate: 0.0032783\n",
      "Training loss: 0.24555 , Training acc:  0.916316\n",
      "Test loss: 0.390365 , Test acc:  0.859416\n",
      "--------------------------------------------------------------------------------\n",
      "Step 3180\n",
      "learning_rate: 0.0032783\n",
      "Training loss: 0.253014 , Training acc:  0.919125\n",
      "Test loss: 0.393664 , Test acc:  0.864721\n",
      "--------------------------------------------------------------------------------\n",
      "Step 3200\n",
      "learning_rate: 0.0032783\n",
      "Training loss: 0.269551 , Training acc:  0.91971\n",
      "Test loss: 0.402931 , Test acc:  0.853448\n",
      "--------------------------------------------------------------------------------\n",
      "Step 3220\n",
      "learning_rate: 0.0032783\n",
      "Training loss: 0.250611 , Training acc:  0.923221\n",
      "Test loss: 0.388772 , Test acc:  0.856764\n",
      "--------------------------------------------------------------------------------\n",
      "Step 3240\n",
      "learning_rate: 0.00324551\n",
      "Training loss: 0.234703 , Training acc:  0.931999\n",
      "Test loss: 0.368971 , Test acc:  0.869363\n",
      "--------------------------------------------------------------------------------\n",
      "Step 3260\n",
      "learning_rate: 0.00324551\n",
      "Training loss: 0.235919 , Training acc:  0.92404\n",
      "Test loss: 0.373977 , Test acc:  0.866711\n",
      "--------------------------------------------------------------------------------\n",
      "Step 3280\n",
      "learning_rate: 0.00324551\n",
      "Training loss: 0.257298 , Training acc:  0.91889\n",
      "Test loss: 0.38395 , Test acc:  0.866048\n",
      "--------------------------------------------------------------------------------\n",
      "Step 3300\n",
      "learning_rate: 0.00321306\n",
      "Training loss: 0.256644 , Training acc:  0.920178\n",
      "Test loss: 0.38328 , Test acc:  0.874005\n",
      "--------------------------------------------------------------------------------\n",
      "Step 3320\n",
      "learning_rate: 0.00321306\n",
      "Training loss: 0.240023 , Training acc:  0.925211\n",
      "Test loss: 0.373993 , Test acc:  0.874005\n",
      "--------------------------------------------------------------------------------\n",
      "Step 3340\n",
      "learning_rate: 0.00321306\n",
      "Training loss: 0.231916 , Training acc:  0.923689\n",
      "Test loss: 0.380335 , Test acc:  0.85809\n",
      "--------------------------------------------------------------------------------\n",
      "Step 3360\n",
      "learning_rate: 0.00321306\n",
      "Training loss: 0.236995 , Training acc:  0.92486\n",
      "Test loss: 0.383097 , Test acc:  0.866711\n",
      "--------------------------------------------------------------------------------\n",
      "Step 3380\n",
      "learning_rate: 0.00318093\n",
      "Training loss: 0.241805 , Training acc:  0.923221\n",
      "Test loss: 0.361823 , Test acc:  0.876658\n",
      "--------------------------------------------------------------------------------\n",
      "Step 3400\n",
      "learning_rate: 0.00318093\n",
      "Training loss: 0.266894 , Training acc:  0.916784\n",
      "Test loss: 0.390356 , Test acc:  0.867374\n",
      "--------------------------------------------------------------------------------\n",
      "Step 3420\n",
      "learning_rate: 0.00318093\n",
      "Training loss: 0.229547 , Training acc:  0.927669\n",
      "Test loss: 0.368633 , Test acc:  0.872016\n",
      "--------------------------------------------------------------------------------\n",
      "Step 3440\n",
      "learning_rate: 0.00318093\n",
      "Training loss: 0.211938 , Training acc:  0.934457\n",
      "Test loss: 0.358423 , Test acc:  0.875332\n",
      "--------------------------------------------------------------------------------\n",
      "Step 3460\n",
      "learning_rate: 0.00314912\n",
      "Training loss: 0.254274 , Training acc:  0.911868\n",
      "Test loss: 0.411433 , Test acc:  0.845491\n",
      "--------------------------------------------------------------------------------\n",
      "Step 3480\n",
      "learning_rate: 0.00314912\n",
      "Training loss: 0.241907 , Training acc:  0.922753\n",
      "Test loss: 0.393474 , Test acc:  0.850796\n",
      "--------------------------------------------------------------------------------\n",
      "Step 3500\n",
      "learning_rate: 0.00314912\n",
      "Training loss: 0.22747 , Training acc:  0.924391\n",
      "Test loss: 0.38044 , Test acc:  0.858753\n",
      "--------------------------------------------------------------------------------\n",
      "Step 3520\n",
      "learning_rate: 0.00314912\n",
      "Training loss: 0.247006 , Training acc:  0.921816\n",
      "Test loss: 0.402512 , Test acc:  0.850133\n",
      "--------------------------------------------------------------------------------\n",
      "Step 3540\n",
      "learning_rate: 0.00311763\n",
      "Training loss: 0.228793 , Training acc:  0.925328\n",
      "Test loss: 0.366508 , Test acc:  0.87069\n",
      "--------------------------------------------------------------------------------\n",
      "Step 3560\n",
      "learning_rate: 0.00311763\n",
      "Training loss: 0.211376 , Training acc:  0.933521\n",
      "Test loss: 0.345044 , Test acc:  0.876658\n",
      "--------------------------------------------------------------------------------\n",
      "Step 3580\n",
      "learning_rate: 0.00311763\n",
      "Training loss: 0.205929 , Training acc:  0.938787\n",
      "Test loss: 0.337026 , Test acc:  0.877984\n",
      "--------------------------------------------------------------------------------\n",
      "Step 3600\n",
      "learning_rate: 0.00308645\n",
      "Training loss: 0.233643 , Training acc:  0.922168\n",
      "Test loss: 0.363864 , Test acc:  0.868037\n",
      "--------------------------------------------------------------------------------\n",
      "Step 3620\n",
      "learning_rate: 0.00308645\n",
      "Training loss: 0.202501 , Training acc:  0.933638\n",
      "Test loss: 0.345796 , Test acc:  0.867374\n",
      "--------------------------------------------------------------------------------\n",
      "Step 3640\n",
      "learning_rate: 0.00308645\n",
      "Training loss: 0.213109 , Training acc:  0.930595\n",
      "Test loss: 0.348881 , Test acc:  0.87069\n",
      "--------------------------------------------------------------------------------\n",
      "Step 3660\n",
      "learning_rate: 0.00308645\n",
      "Training loss: 0.212983 , Training acc:  0.935276\n",
      "Test loss: 0.355612 , Test acc:  0.866711\n",
      "--------------------------------------------------------------------------------\n",
      "Step 3680\n",
      "learning_rate: 0.00305559\n",
      "Training loss: 0.215576 , Training acc:  0.936798\n",
      "Test loss: 0.369105 , Test acc:  0.866048\n",
      "--------------------------------------------------------------------------------\n",
      "Step 3700\n",
      "learning_rate: 0.00305559\n",
      "Training loss: 0.238891 , Training acc:  0.930243\n",
      "Test loss: 0.374162 , Test acc:  0.866048\n",
      "--------------------------------------------------------------------------------\n",
      "Step 3720\n",
      "learning_rate: 0.00305559\n",
      "Training loss: 0.241647 , Training acc:  0.926264\n",
      "Test loss: 0.388599 , Test acc:  0.864058\n",
      "--------------------------------------------------------------------------------\n",
      "Step 3740\n",
      "learning_rate: 0.00305559\n",
      "Training loss: 0.227847 , Training acc:  0.928722\n",
      "Test loss: 0.377018 , Test acc:  0.862732\n",
      "--------------------------------------------------------------------------------\n",
      "Step 3760\n",
      "learning_rate: 0.00302503\n",
      "Training loss: 0.213968 , Training acc:  0.928605\n",
      "Test loss: 0.369987 , Test acc:  0.864058\n",
      "--------------------------------------------------------------------------------\n",
      "Step 3780\n",
      "learning_rate: 0.00302503\n",
      "Training loss: 0.208171 , Training acc:  0.933989\n",
      "Test loss: 0.360661 , Test acc:  0.869363\n",
      "--------------------------------------------------------------------------------\n",
      "Step 3800\n",
      "learning_rate: 0.00302503\n",
      "Training loss: 0.207582 , Training acc:  0.934223\n",
      "Test loss: 0.36685 , Test acc:  0.872016\n",
      "--------------------------------------------------------------------------------\n",
      "Step 3820\n",
      "learning_rate: 0.00302503\n",
      "Training loss: 0.221338 , Training acc:  0.933052\n",
      "Test loss: 0.366622 , Test acc:  0.865385\n",
      "--------------------------------------------------------------------------------\n",
      "Step 3840\n",
      "learning_rate: 0.00299478\n",
      "Training loss: 0.229656 , Training acc:  0.936095\n",
      "Test loss: 0.361211 , Test acc:  0.872016\n",
      "--------------------------------------------------------------------------------\n",
      "Step 3860\n",
      "learning_rate: 0.00299478\n",
      "Training loss: 0.239774 , Training acc:  0.924391\n",
      "Test loss: 0.388328 , Test acc:  0.857427\n",
      "--------------------------------------------------------------------------------\n",
      "Step 3880\n",
      "learning_rate: 0.00299478\n",
      "Training loss: 0.209362 , Training acc:  0.930477\n",
      "Test loss: 0.355743 , Test acc:  0.874668\n",
      "--------------------------------------------------------------------------------\n",
      "Step 3900\n",
      "learning_rate: 0.00296483\n",
      "Training loss: 0.219504 , Training acc:  0.929775\n",
      "Test loss: 0.361282 , Test acc:  0.873342\n",
      "--------------------------------------------------------------------------------\n",
      "Step 3920\n",
      "learning_rate: 0.00296483\n",
      "Training loss: 0.201369 , Training acc:  0.935393\n",
      "Test loss: 0.34397 , Test acc:  0.877321\n",
      "--------------------------------------------------------------------------------\n",
      "Step 3940\n",
      "learning_rate: 0.00296483\n",
      "Training loss: 0.189895 , Training acc:  0.942416\n",
      "Test loss: 0.333473 , Test acc:  0.878647\n",
      "--------------------------------------------------------------------------------\n",
      "Step 3960\n",
      "learning_rate: 0.00296483\n",
      "Training loss: 0.200566 , Training acc:  0.93867\n",
      "Test loss: 0.35339 , Test acc:  0.872016\n",
      "--------------------------------------------------------------------------------\n",
      "Step 3980\n",
      "learning_rate: 0.00293519\n",
      "Training loss: 0.21759 , Training acc:  0.933755\n",
      "Test loss: 0.361451 , Test acc:  0.877984\n",
      "--------------------------------------------------------------------------------\n",
      "Step 4000\n",
      "learning_rate: 0.00293519\n",
      "Training loss: 0.198522 , Training acc:  0.940309\n",
      "Test loss: 0.352546 , Test acc:  0.871353\n",
      "--------------------------------------------------------------------------------\n",
      "Step 4020\n",
      "learning_rate: 0.00293519\n",
      "Training loss: 0.203534 , Training acc:  0.933521\n",
      "Test loss: 0.357876 , Test acc:  0.865385\n",
      "--------------------------------------------------------------------------------\n",
      "Step 4040\n",
      "learning_rate: 0.00293519\n",
      "Training loss: 0.204295 , Training acc:  0.931414\n",
      "Test loss: 0.359294 , Test acc:  0.866048\n",
      "--------------------------------------------------------------------------------\n",
      "Step 4060\n",
      "learning_rate: 0.00290583\n",
      "Training loss: 0.216854 , Training acc:  0.92802\n",
      "Test loss: 0.366947 , Test acc:  0.865385\n",
      "--------------------------------------------------------------------------------\n",
      "Step 4080\n",
      "learning_rate: 0.00290583\n",
      "Training loss: 0.187302 , Training acc:  0.944405\n",
      "Test loss: 0.340255 , Test acc:  0.876658\n",
      "--------------------------------------------------------------------------------\n",
      "Step 4100\n",
      "learning_rate: 0.00290583\n",
      "Training loss: 0.192124 , Training acc:  0.940192\n",
      "Test loss: 0.348982 , Test acc:  0.871353\n",
      "--------------------------------------------------------------------------------\n",
      "Step 4120\n",
      "learning_rate: 0.00290583\n",
      "Training loss: 0.191068 , Training acc:  0.940894\n",
      "Test loss: 0.349894 , Test acc:  0.869363\n",
      "--------------------------------------------------------------------------------\n",
      "Step 4140\n",
      "learning_rate: 0.00287678\n",
      "Training loss: 0.191009 , Training acc:  0.936213\n",
      "Test loss: 0.354749 , Test acc:  0.875995\n",
      "--------------------------------------------------------------------------------\n",
      "Step 4160\n",
      "learning_rate: 0.00287678\n",
      "Training loss: 0.179044 , Training acc:  0.941479\n",
      "Test loss: 0.344131 , Test acc:  0.867374\n",
      "--------------------------------------------------------------------------------\n",
      "Step 4180\n",
      "learning_rate: 0.00287678\n",
      "Training loss: 0.225763 , Training acc:  0.925796\n",
      "Test loss: 0.388395 , Test acc:  0.857427\n",
      "--------------------------------------------------------------------------------\n",
      "Step 4200\n",
      "learning_rate: 0.00284801\n",
      "Training loss: 0.251303 , Training acc:  0.925211\n",
      "Test loss: 0.405246 , Test acc:  0.861406\n",
      "--------------------------------------------------------------------------------\n",
      "Step 4220\n",
      "learning_rate: 0.00284801\n",
      "Training loss: 0.21448 , Training acc:  0.930946\n",
      "Test loss: 0.37467 , Test acc:  0.870027\n",
      "--------------------------------------------------------------------------------\n",
      "Step 4240\n",
      "learning_rate: 0.00284801\n",
      "Training loss: 0.191955 , Training acc:  0.938319\n",
      "Test loss: 0.362694 , Test acc:  0.866711\n",
      "--------------------------------------------------------------------------------\n",
      "Step 4260\n",
      "learning_rate: 0.00284801\n",
      "Training loss: 0.222181 , Training acc:  0.926381\n",
      "Test loss: 0.390142 , Test acc:  0.857427\n",
      "--------------------------------------------------------------------------------\n",
      "Step 4280\n",
      "learning_rate: 0.00281953\n",
      "Training loss: 0.182028 , Training acc:  0.942065\n",
      "Test loss: 0.343069 , Test acc:  0.874668\n",
      "--------------------------------------------------------------------------------\n",
      "Step 4300\n",
      "learning_rate: 0.00281953\n",
      "Training loss: 0.17179 , Training acc:  0.949204\n",
      "Test loss: 0.330716 , Test acc:  0.871353\n",
      "--------------------------------------------------------------------------------\n",
      "Step 4320\n",
      "learning_rate: 0.00281953\n",
      "Training loss: 0.18363 , Training acc:  0.942182\n",
      "Test loss: 0.34317 , Test acc:  0.871353\n",
      "--------------------------------------------------------------------------------\n",
      "Step 4340\n",
      "learning_rate: 0.00281953\n",
      "Training loss: 0.187463 , Training acc:  0.938905\n",
      "Test loss: 0.36165 , Test acc:  0.864058\n",
      "--------------------------------------------------------------------------------\n",
      "Step 4360\n",
      "learning_rate: 0.00279133\n",
      "Training loss: 0.205885 , Training acc:  0.932935\n",
      "Test loss: 0.378567 , Test acc:  0.865385\n",
      "--------------------------------------------------------------------------------\n",
      "Step 4380\n",
      "learning_rate: 0.00279133\n",
      "Training loss: 0.205511 , Training acc:  0.929658\n",
      "Test loss: 0.379204 , Test acc:  0.860743\n",
      "--------------------------------------------------------------------------------\n",
      "Step 4400\n",
      "learning_rate: 0.00279133\n",
      "Training loss: 0.193881 , Training acc:  0.939724\n",
      "Test loss: 0.359365 , Test acc:  0.859416\n",
      "--------------------------------------------------------------------------------\n",
      "Step 4420\n",
      "learning_rate: 0.00279133\n",
      "Training loss: 0.176623 , Training acc:  0.947683\n",
      "Test loss: 0.341909 , Test acc:  0.876658\n",
      "--------------------------------------------------------------------------------\n",
      "Step 4440\n",
      "learning_rate: 0.00276342\n",
      "Training loss: 0.16821 , Training acc:  0.94581\n",
      "Test loss: 0.333218 , Test acc:  0.875332\n",
      "--------------------------------------------------------------------------------\n",
      "Step 4460\n",
      "learning_rate: 0.00276342\n",
      "Training loss: 0.182808 , Training acc:  0.939373\n",
      "Test loss: 0.345192 , Test acc:  0.878647\n",
      "--------------------------------------------------------------------------------\n",
      "Step 4480\n",
      "learning_rate: 0.00276342\n",
      "Training loss: 0.212255 , Training acc:  0.934223\n",
      "Test loss: 0.375108 , Test acc:  0.857427\n",
      "--------------------------------------------------------------------------------\n",
      "Step 4500\n",
      "learning_rate: 0.00273578\n",
      "Training loss: 0.203033 , Training acc:  0.936798\n",
      "Test loss: 0.362738 , Test acc:  0.866048\n",
      "--------------------------------------------------------------------------------\n",
      "Step 4520\n",
      "learning_rate: 0.00273578\n",
      "Training loss: 0.176495 , Training acc:  0.94581\n",
      "Test loss: 0.348933 , Test acc:  0.877984\n",
      "--------------------------------------------------------------------------------\n",
      "Step 4540\n",
      "learning_rate: 0.00273578\n",
      "Training loss: 0.204966 , Training acc:  0.93036\n",
      "Test loss: 0.373701 , Test acc:  0.865385\n",
      "--------------------------------------------------------------------------------\n",
      "Step 4560\n",
      "learning_rate: 0.00273578\n",
      "Training loss: 0.199356 , Training acc:  0.942416\n",
      "Test loss: 0.350486 , Test acc:  0.875995\n",
      "--------------------------------------------------------------------------------\n",
      "Step 4580\n",
      "learning_rate: 0.00270843\n",
      "Training loss: 0.184185 , Training acc:  0.944171\n",
      "Test loss: 0.360856 , Test acc:  0.868037\n",
      "--------------------------------------------------------------------------------\n",
      "Step 4600\n",
      "learning_rate: 0.00270843\n",
      "Training loss: 0.183948 , Training acc:  0.939022\n",
      "Test loss: 0.361157 , Test acc:  0.872679\n",
      "--------------------------------------------------------------------------------\n",
      "Step 4620\n",
      "learning_rate: 0.00270843\n",
      "Training loss: 0.169922 , Training acc:  0.946395\n",
      "Test loss: 0.331172 , Test acc:  0.877984\n",
      "--------------------------------------------------------------------------------\n",
      "Step 4640\n",
      "learning_rate: 0.00270843\n",
      "Training loss: 0.164978 , Training acc:  0.951545\n",
      "Test loss: 0.336351 , Test acc:  0.876658\n",
      "--------------------------------------------------------------------------------\n",
      "Step 4660\n",
      "learning_rate: 0.00268134\n",
      "Training loss: 0.168372 , Training acc:  0.95096\n",
      "Test loss: 0.347139 , Test acc:  0.878647\n",
      "--------------------------------------------------------------------------------\n",
      "Step 4680\n",
      "learning_rate: 0.00268134\n",
      "Training loss: 0.164872 , Training acc:  0.947214\n",
      "Test loss: 0.345555 , Test acc:  0.876658\n",
      "--------------------------------------------------------------------------------\n",
      "Step 4700\n",
      "learning_rate: 0.00268134\n",
      "Training loss: 0.177139 , Training acc:  0.944288\n",
      "Test loss: 0.350308 , Test acc:  0.875995\n",
      "--------------------------------------------------------------------------------\n",
      "Step 4720\n",
      "learning_rate: 0.00268134\n",
      "Training loss: 0.173132 , Training acc:  0.947097\n",
      "Test loss: 0.342864 , Test acc:  0.87931\n",
      "--------------------------------------------------------------------------------\n",
      "Step 4740\n",
      "learning_rate: 0.00265453\n",
      "Training loss: 0.20554 , Training acc:  0.928488\n",
      "Test loss: 0.382647 , Test acc:  0.86008\n",
      "--------------------------------------------------------------------------------\n",
      "Step 4760\n",
      "learning_rate: 0.00265453\n",
      "Training loss: 0.172416 , Training acc:  0.946044\n",
      "Test loss: 0.351789 , Test acc:  0.875332\n",
      "--------------------------------------------------------------------------------\n",
      "Step 4780\n",
      "learning_rate: 0.00265453\n",
      "Training loss: 0.162646 , Training acc:  0.955758\n",
      "Test loss: 0.340408 , Test acc:  0.874005\n",
      "--------------------------------------------------------------------------------\n",
      "Step 4800\n",
      "learning_rate: 0.00262798\n",
      "Training loss: 0.16102 , Training acc:  0.95096\n",
      "Test loss: 0.329252 , Test acc:  0.880637\n",
      "--------------------------------------------------------------------------------\n",
      "Step 4820\n",
      "learning_rate: 0.00262798\n",
      "Training loss: 0.161719 , Training acc:  0.951428\n",
      "Test loss: 0.328254 , Test acc:  0.880637\n",
      "--------------------------------------------------------------------------------\n",
      "Step 4840\n",
      "learning_rate: 0.00262798\n",
      "Training loss: 0.162313 , Training acc:  0.954705\n",
      "Test loss: 0.335004 , Test acc:  0.876658\n",
      "--------------------------------------------------------------------------------\n",
      "Step 4860\n",
      "learning_rate: 0.00262798\n",
      "Training loss: 0.168715 , Training acc:  0.950609\n",
      "Test loss: 0.346421 , Test acc:  0.875995\n",
      "--------------------------------------------------------------------------------\n",
      "Step 4880\n",
      "learning_rate: 0.0026017\n",
      "Training loss: 0.167648 , Training acc:  0.951662\n",
      "Test loss: 0.331626 , Test acc:  0.877984\n",
      "--------------------------------------------------------------------------------\n",
      "Step 4900\n",
      "learning_rate: 0.0026017\n",
      "Training loss: 0.173291 , Training acc:  0.94581\n",
      "Test loss: 0.336635 , Test acc:  0.877321\n",
      "--------------------------------------------------------------------------------\n",
      "Step 4920\n",
      "learning_rate: 0.0026017\n",
      "Training loss: 0.168887 , Training acc:  0.947683\n",
      "Test loss: 0.350846 , Test acc:  0.875332\n",
      "--------------------------------------------------------------------------------\n",
      "Step 4940\n",
      "learning_rate: 0.0026017\n",
      "Training loss: 0.157074 , Training acc:  0.955173\n",
      "Test loss: 0.335407 , Test acc:  0.877321\n",
      "--------------------------------------------------------------------------------\n",
      "Step 4960\n",
      "learning_rate: 0.00257569\n",
      "Training loss: 0.158923 , Training acc:  0.951311\n",
      "Test loss: 0.342513 , Test acc:  0.873342\n",
      "--------------------------------------------------------------------------------\n",
      "Step 4980\n",
      "learning_rate: 0.00257569\n",
      "Training loss: 0.182963 , Training acc:  0.938319\n",
      "Test loss: 0.388255 , Test acc:  0.862732\n",
      "--------------------------------------------------------------------------------\n",
      "Step 5000\n",
      "learning_rate: 0.00257569\n",
      "Training loss: 0.172846 , Training acc:  0.946863\n",
      "Test loss: 0.362852 , Test acc:  0.872016\n",
      "--------------------------------------------------------------------------------\n",
      "Step 5020\n",
      "learning_rate: 0.00257569\n",
      "Training loss: 0.160009 , Training acc:  0.95529\n",
      "Test loss: 0.332669 , Test acc:  0.885279\n",
      "--------------------------------------------------------------------------------\n",
      "Step 5040\n",
      "learning_rate: 0.00254993\n",
      "Training loss: 0.162898 , Training acc:  0.952247\n",
      "Test loss: 0.335657 , Test acc:  0.879973\n",
      "--------------------------------------------------------------------------------\n",
      "Step 5060\n",
      "learning_rate: 0.00254993\n",
      "Training loss: 0.149929 , Training acc:  0.960206\n",
      "Test loss: 0.32369 , Test acc:  0.872679\n",
      "--------------------------------------------------------------------------------\n",
      "Step 5080\n",
      "learning_rate: 0.00254993\n",
      "Training loss: 0.154069 , Training acc:  0.956578\n",
      "Test loss: 0.335766 , Test acc:  0.878647\n",
      "--------------------------------------------------------------------------------\n",
      "Step 5100\n",
      "learning_rate: 0.00252443\n",
      "Training loss: 0.154595 , Training acc:  0.954705\n",
      "Test loss: 0.350891 , Test acc:  0.874005\n",
      "--------------------------------------------------------------------------------\n",
      "Step 5120\n",
      "learning_rate: 0.00252443\n",
      "Training loss: 0.157424 , Training acc:  0.954354\n",
      "Test loss: 0.356976 , Test acc:  0.881963\n",
      "--------------------------------------------------------------------------------\n",
      "Step 5140\n",
      "learning_rate: 0.00252443\n",
      "Training loss: 0.20933 , Training acc:  0.92486\n",
      "Test loss: 0.415745 , Test acc:  0.854775\n",
      "--------------------------------------------------------------------------------\n",
      "Step 5160\n",
      "learning_rate: 0.00252443\n",
      "Training loss: 0.158199 , Training acc:  0.949204\n",
      "Test loss: 0.356568 , Test acc:  0.871353\n",
      "--------------------------------------------------------------------------------\n",
      "Step 5180\n",
      "learning_rate: 0.00249919\n",
      "Training loss: 0.140505 , Training acc:  0.96243\n",
      "Test loss: 0.340295 , Test acc:  0.870027\n",
      "--------------------------------------------------------------------------------\n",
      "Step 5200\n",
      "learning_rate: 0.00249919\n",
      "Training loss: 0.164045 , Training acc:  0.951428\n",
      "Test loss: 0.358966 , Test acc:  0.872679\n",
      "--------------------------------------------------------------------------------\n",
      "Step 5220\n",
      "learning_rate: 0.00249919\n",
      "Training loss: 0.151349 , Training acc:  0.96044\n",
      "Test loss: 0.336306 , Test acc:  0.875995\n",
      "--------------------------------------------------------------------------------\n",
      "Step 5240\n",
      "learning_rate: 0.00249919\n",
      "Training loss: 0.148433 , Training acc:  0.954705\n",
      "Test loss: 0.32641 , Test acc:  0.877321\n",
      "--------------------------------------------------------------------------------\n",
      "Step 5260\n",
      "learning_rate: 0.00247419\n",
      "Training loss: 0.138569 , Training acc:  0.960206\n",
      "Test loss: 0.316307 , Test acc:  0.88992\n",
      "--------------------------------------------------------------------------------\n",
      "Step 5280\n",
      "learning_rate: 0.00247419\n",
      "Training loss: 0.144846 , Training acc:  0.955407\n",
      "Test loss: 0.335266 , Test acc:  0.875995\n",
      "--------------------------------------------------------------------------------\n",
      "Step 5300\n",
      "learning_rate: 0.00247419\n",
      "Training loss: 0.188978 , Training acc:  0.935159\n",
      "Test loss: 0.383289 , Test acc:  0.854775\n",
      "--------------------------------------------------------------------------------\n",
      "Step 5320\n",
      "learning_rate: 0.00247419\n",
      "Training loss: 0.148272 , Training acc:  0.957046\n",
      "Test loss: 0.326192 , Test acc:  0.880637\n",
      "--------------------------------------------------------------------------------\n",
      "Step 5340\n",
      "learning_rate: 0.00244945\n",
      "Training loss: 0.134536 , Training acc:  0.962313\n",
      "Test loss: 0.318664 , Test acc:  0.87931\n",
      "--------------------------------------------------------------------------------\n",
      "Step 5360\n",
      "learning_rate: 0.00244945\n",
      "Training loss: 0.126016 , Training acc:  0.961727\n",
      "Test loss: 0.309652 , Test acc:  0.880637\n",
      "--------------------------------------------------------------------------------\n",
      "Step 5380\n",
      "learning_rate: 0.00244945\n",
      "Training loss: 0.131471 , Training acc:  0.964419\n",
      "Test loss: 0.322378 , Test acc:  0.87931\n",
      "--------------------------------------------------------------------------------\n",
      "Step 5400\n",
      "learning_rate: 0.00242496\n",
      "Training loss: 0.135418 , Training acc:  0.962898\n",
      "Test loss: 0.326917 , Test acc:  0.883952\n",
      "--------------------------------------------------------------------------------\n",
      "Step 5420\n",
      "learning_rate: 0.00242496\n",
      "Training loss: 0.136602 , Training acc:  0.963132\n",
      "Test loss: 0.328245 , Test acc:  0.877984\n",
      "--------------------------------------------------------------------------------\n",
      "Step 5440\n",
      "learning_rate: 0.00242496\n",
      "Training loss: 0.167031 , Training acc:  0.947683\n",
      "Test loss: 0.357553 , Test acc:  0.87069\n",
      "--------------------------------------------------------------------------------\n",
      "Step 5460\n",
      "learning_rate: 0.00242496\n",
      "Training loss: 0.168898 , Training acc:  0.942416\n",
      "Test loss: 0.356826 , Test acc:  0.861406\n",
      "--------------------------------------------------------------------------------\n",
      "Step 5480\n",
      "learning_rate: 0.00240071\n",
      "Training loss: 0.140559 , Training acc:  0.959036\n",
      "Test loss: 0.322535 , Test acc:  0.878647\n",
      "--------------------------------------------------------------------------------\n",
      "Step 5500\n",
      "learning_rate: 0.00240071\n",
      "Training loss: 0.145268 , Training acc:  0.956578\n",
      "Test loss: 0.336402 , Test acc:  0.874668\n",
      "--------------------------------------------------------------------------------\n",
      "Step 5520\n",
      "learning_rate: 0.00240071\n",
      "Training loss: 0.159653 , Training acc:  0.955524\n",
      "Test loss: 0.343048 , Test acc:  0.870027\n",
      "--------------------------------------------------------------------------------\n",
      "Step 5540\n",
      "learning_rate: 0.00240071\n",
      "Training loss: 0.143987 , Training acc:  0.956578\n",
      "Test loss: 0.332468 , Test acc:  0.883952\n",
      "--------------------------------------------------------------------------------\n",
      "Step 5560\n",
      "learning_rate: 0.0023767\n",
      "Training loss: 0.128098 , Training acc:  0.960791\n",
      "Test loss: 0.321048 , Test acc:  0.885942\n",
      "--------------------------------------------------------------------------------\n",
      "Step 5580\n",
      "learning_rate: 0.0023767\n",
      "Training loss: 0.126058 , Training acc:  0.963483\n",
      "Test loss: 0.318225 , Test acc:  0.887931\n",
      "--------------------------------------------------------------------------------\n",
      "Step 5600\n",
      "learning_rate: 0.0023767\n",
      "Training loss: 0.134231 , Training acc:  0.959972\n",
      "Test loss: 0.316997 , Test acc:  0.885942\n",
      "--------------------------------------------------------------------------------\n",
      "Step 5620\n",
      "learning_rate: 0.0023767\n",
      "Training loss: 0.13615 , Training acc:  0.962079\n",
      "Test loss: 0.320399 , Test acc:  0.886605\n",
      "--------------------------------------------------------------------------------\n",
      "Step 5640\n",
      "learning_rate: 0.00235293\n",
      "Training loss: 0.137395 , Training acc:  0.961493\n",
      "Test loss: 0.33722 , Test acc:  0.87931\n",
      "--------------------------------------------------------------------------------\n",
      "Step 5660\n",
      "learning_rate: 0.00235293\n",
      "Training loss: 0.128104 , Training acc:  0.965005\n",
      "Test loss: 0.331305 , Test acc:  0.877984\n",
      "--------------------------------------------------------------------------------\n",
      "Step 5680\n",
      "learning_rate: 0.00235293\n",
      "Training loss: 0.129437 , Training acc:  0.962664\n",
      "Test loss: 0.329754 , Test acc:  0.87069\n",
      "--------------------------------------------------------------------------------\n",
      "Step 5700\n",
      "learning_rate: 0.00232941\n",
      "Training loss: 0.13257 , Training acc:  0.964185\n",
      "Test loss: 0.32413 , Test acc:  0.881963\n",
      "--------------------------------------------------------------------------------\n",
      "Step 5720\n",
      "learning_rate: 0.00232941\n",
      "Training loss: 0.127399 , Training acc:  0.963015\n",
      "Test loss: 0.323273 , Test acc:  0.879973\n",
      "--------------------------------------------------------------------------------\n",
      "Step 5740\n",
      "learning_rate: 0.00232941\n",
      "Training loss: 0.142917 , Training acc:  0.956695\n",
      "Test loss: 0.342174 , Test acc:  0.876658\n",
      "--------------------------------------------------------------------------------\n",
      "Step 5760\n",
      "learning_rate: 0.00232941\n",
      "Training loss: 0.120065 , Training acc:  0.965005\n",
      "Test loss: 0.314304 , Test acc:  0.879973\n",
      "--------------------------------------------------------------------------------\n",
      "Step 5780\n",
      "learning_rate: 0.00230611\n",
      "Training loss: 0.117404 , Training acc:  0.964888\n",
      "Test loss: 0.318936 , Test acc:  0.879973\n",
      "--------------------------------------------------------------------------------\n",
      "Step 5800\n",
      "learning_rate: 0.00230611\n",
      "Training loss: 0.119976 , Training acc:  0.967345\n",
      "Test loss: 0.322506 , Test acc:  0.88992\n",
      "--------------------------------------------------------------------------------\n",
      "Step 5820\n",
      "learning_rate: 0.00230611\n",
      "Training loss: 0.13113 , Training acc:  0.960908\n",
      "Test loss: 0.317342 , Test acc:  0.887268\n",
      "--------------------------------------------------------------------------------\n",
      "Step 5840\n",
      "learning_rate: 0.00230611\n",
      "Training loss: 0.148185 , Training acc:  0.955056\n",
      "Test loss: 0.347465 , Test acc:  0.881963\n",
      "--------------------------------------------------------------------------------\n",
      "Step 5860\n",
      "learning_rate: 0.00228305\n",
      "Training loss: 0.13215 , Training acc:  0.962781\n",
      "Test loss: 0.323133 , Test acc:  0.883289\n",
      "--------------------------------------------------------------------------------\n",
      "Step 5880\n",
      "learning_rate: 0.00228305\n",
      "Training loss: 0.124472 , Training acc:  0.96758\n",
      "Test loss: 0.318072 , Test acc:  0.883952\n",
      "--------------------------------------------------------------------------------\n",
      "Step 5900\n",
      "learning_rate: 0.00228305\n",
      "Training loss: 0.140216 , Training acc:  0.957631\n",
      "Test loss: 0.343256 , Test acc:  0.883952\n",
      "--------------------------------------------------------------------------------\n",
      "Step 5920\n",
      "learning_rate: 0.00228305\n",
      "Training loss: 0.140038 , Training acc:  0.956929\n",
      "Test loss: 0.328947 , Test acc:  0.876658\n",
      "--------------------------------------------------------------------------------\n",
      "Step 5940\n",
      "learning_rate: 0.00226022\n",
      "Training loss: 0.132927 , Training acc:  0.961376\n",
      "Test loss: 0.332618 , Test acc:  0.883289\n",
      "--------------------------------------------------------------------------------\n",
      "Step 5960\n",
      "learning_rate: 0.00226022\n",
      "Training loss: 0.142186 , Training acc:  0.955524\n",
      "Test loss: 0.353334 , Test acc:  0.877321\n",
      "--------------------------------------------------------------------------------\n",
      "Step 5980\n",
      "learning_rate: 0.00226022\n",
      "Training loss: 0.131446 , Training acc:  0.959855\n",
      "Test loss: 0.329203 , Test acc:  0.881963\n",
      "--------------------------------------------------------------------------------\n",
      "Step 6000\n",
      "learning_rate: 0.00223762\n",
      "Training loss: 0.13337 , Training acc:  0.962313\n",
      "Test loss: 0.335808 , Test acc:  0.879973\n",
      "--------------------------------------------------------------------------------\n",
      "Step 6020\n",
      "learning_rate: 0.00223762\n",
      "Training loss: 0.12053 , Training acc:  0.965824\n",
      "Test loss: 0.323328 , Test acc:  0.883289\n",
      "--------------------------------------------------------------------------------\n",
      "Step 6040\n",
      "learning_rate: 0.00223762\n",
      "Training loss: 0.122861 , Training acc:  0.964419\n",
      "Test loss: 0.334224 , Test acc:  0.877321\n",
      "--------------------------------------------------------------------------------\n",
      "Step 6060\n",
      "learning_rate: 0.00223762\n",
      "Training loss: 0.124562 , Training acc:  0.968399\n",
      "Test loss: 0.32302 , Test acc:  0.8813\n",
      "--------------------------------------------------------------------------------\n",
      "Step 6080\n",
      "learning_rate: 0.00221524\n",
      "Training loss: 0.133638 , Training acc:  0.961845\n",
      "Test loss: 0.317368 , Test acc:  0.883952\n",
      "--------------------------------------------------------------------------------\n",
      "Step 6100\n",
      "learning_rate: 0.00221524\n",
      "Training loss: 0.154605 , Training acc:  0.950843\n",
      "Test loss: 0.359009 , Test acc:  0.875332\n",
      "--------------------------------------------------------------------------------\n",
      "Step 6120\n",
      "learning_rate: 0.00221524\n",
      "Training loss: 0.116472 , Training acc:  0.966877\n",
      "Test loss: 0.316469 , Test acc:  0.886605\n",
      "--------------------------------------------------------------------------------\n",
      "Step 6140\n",
      "learning_rate: 0.00221524\n",
      "Training loss: 0.123353 , Training acc:  0.966643\n",
      "Test loss: 0.314084 , Test acc:  0.885942\n",
      "--------------------------------------------------------------------------------\n",
      "Step 6160\n",
      "learning_rate: 0.00219309\n",
      "Training loss: 0.128908 , Training acc:  0.964654\n",
      "Test loss: 0.322098 , Test acc:  0.876658\n",
      "--------------------------------------------------------------------------------\n",
      "Step 6180\n",
      "learning_rate: 0.00219309\n",
      "Training loss: 0.133445 , Training acc:  0.960908\n",
      "Test loss: 0.323201 , Test acc:  0.882626\n",
      "--------------------------------------------------------------------------------\n",
      "Step 6200\n",
      "learning_rate: 0.00219309\n",
      "Training loss: 0.135667 , Training acc:  0.961493\n",
      "Test loss: 0.339881 , Test acc:  0.875332\n",
      "--------------------------------------------------------------------------------\n",
      "Step 6220\n",
      "learning_rate: 0.00219309\n",
      "Training loss: 0.133988 , Training acc:  0.962079\n",
      "Test loss: 0.338277 , Test acc:  0.883289\n",
      "--------------------------------------------------------------------------------\n",
      "Step 6240\n",
      "learning_rate: 0.00217116\n",
      "Training loss: 0.120165 , Training acc:  0.967814\n",
      "Test loss: 0.308431 , Test acc:  0.884615\n",
      "--------------------------------------------------------------------------------\n",
      "Step 6260\n",
      "learning_rate: 0.00217116\n",
      "Training loss: 0.121373 , Training acc:  0.966409\n",
      "Test loss: 0.319235 , Test acc:  0.879973\n",
      "--------------------------------------------------------------------------------\n",
      "Step 6280\n",
      "learning_rate: 0.00217116\n",
      "Training loss: 0.107872 , Training acc:  0.96875\n",
      "Test loss: 0.310062 , Test acc:  0.885279\n",
      "--------------------------------------------------------------------------------\n",
      "Step 6300\n",
      "learning_rate: 0.00214945\n",
      "Training loss: 0.109424 , Training acc:  0.970272\n",
      "Test loss: 0.30462 , Test acc:  0.888594\n",
      "--------------------------------------------------------------------------------\n",
      "Step 6320\n",
      "learning_rate: 0.00214945\n",
      "Training loss: 0.132291 , Training acc:  0.961962\n",
      "Test loss: 0.343375 , Test acc:  0.876658\n",
      "--------------------------------------------------------------------------------\n",
      "Step 6340\n",
      "learning_rate: 0.00214945\n",
      "Training loss: 0.107692 , Training acc:  0.971442\n",
      "Test loss: 0.308368 , Test acc:  0.89191\n",
      "--------------------------------------------------------------------------------\n",
      "Step 6360\n",
      "learning_rate: 0.00214945\n",
      "Training loss: 0.109653 , Training acc:  0.970272\n",
      "Test loss: 0.313093 , Test acc:  0.894562\n",
      "--------------------------------------------------------------------------------\n",
      "Step 6380\n",
      "learning_rate: 0.00212795\n",
      "Training loss: 0.10799 , Training acc:  0.971559\n",
      "Test loss: 0.305633 , Test acc:  0.887931\n",
      "--------------------------------------------------------------------------------\n",
      "Step 6400\n",
      "learning_rate: 0.00212795\n",
      "Training loss: 0.0988158 , Training acc:  0.974836\n",
      "Test loss: 0.300927 , Test acc:  0.887931\n",
      "--------------------------------------------------------------------------------\n",
      "Step 6420\n",
      "learning_rate: 0.00212795\n",
      "Training loss: 0.113579 , Training acc:  0.971325\n",
      "Test loss: 0.318893 , Test acc:  0.885279\n",
      "--------------------------------------------------------------------------------\n",
      "Step 6440\n",
      "learning_rate: 0.00212795\n",
      "Training loss: 0.122827 , Training acc:  0.963249\n",
      "Test loss: 0.32395 , Test acc:  0.882626\n",
      "--------------------------------------------------------------------------------\n",
      "Step 6460\n",
      "learning_rate: 0.00210667\n",
      "Training loss: 0.122285 , Training acc:  0.962079\n",
      "Test loss: 0.330494 , Test acc:  0.875995\n",
      "--------------------------------------------------------------------------------\n",
      "Step 6480\n",
      "learning_rate: 0.00210667\n",
      "Training loss: 0.106686 , Training acc:  0.972729\n",
      "Test loss: 0.315356 , Test acc:  0.888594\n",
      "--------------------------------------------------------------------------------\n",
      "Step 6500\n",
      "learning_rate: 0.00210667\n",
      "Training loss: 0.119435 , Training acc:  0.965005\n",
      "Test loss: 0.326106 , Test acc:  0.880637\n",
      "--------------------------------------------------------------------------------\n",
      "Step 6520\n",
      "learning_rate: 0.00210667\n",
      "Training loss: 0.100665 , Training acc:  0.974251\n",
      "Test loss: 0.307735 , Test acc:  0.887931\n",
      "--------------------------------------------------------------------------------\n",
      "Step 6540\n",
      "learning_rate: 0.00208561\n",
      "Training loss: 0.110397 , Training acc:  0.970272\n",
      "Test loss: 0.331904 , Test acc:  0.877984\n",
      "--------------------------------------------------------------------------------\n",
      "Step 6560\n",
      "learning_rate: 0.00208561\n",
      "Training loss: 0.112315 , Training acc:  0.969803\n",
      "Test loss: 0.332053 , Test acc:  0.884615\n",
      "--------------------------------------------------------------------------------\n",
      "Step 6580\n",
      "learning_rate: 0.00208561\n",
      "Training loss: 0.118446 , Training acc:  0.967228\n",
      "Test loss: 0.338206 , Test acc:  0.874668\n",
      "--------------------------------------------------------------------------------\n",
      "Step 6600\n",
      "learning_rate: 0.00206475\n",
      "Training loss: 0.115545 , Training acc:  0.968984\n",
      "Test loss: 0.340981 , Test acc:  0.872016\n",
      "--------------------------------------------------------------------------------\n",
      "Step 6620\n",
      "learning_rate: 0.00206475\n",
      "Training loss: 0.115193 , Training acc:  0.965473\n",
      "Test loss: 0.338111 , Test acc:  0.885279\n",
      "--------------------------------------------------------------------------------\n",
      "Step 6640\n",
      "learning_rate: 0.00206475\n",
      "Training loss: 0.0964619 , Training acc:  0.975655\n",
      "Test loss: 0.300279 , Test acc:  0.891247\n",
      "--------------------------------------------------------------------------------\n",
      "Step 6660\n",
      "learning_rate: 0.00206475\n",
      "Training loss: 0.105352 , Training acc:  0.972495\n",
      "Test loss: 0.314908 , Test acc:  0.886605\n",
      "--------------------------------------------------------------------------------\n",
      "Step 6680\n",
      "learning_rate: 0.0020441\n",
      "Training loss: 0.11088 , Training acc:  0.970155\n",
      "Test loss: 0.327707 , Test acc:  0.883289\n",
      "--------------------------------------------------------------------------------\n",
      "Step 6700\n",
      "learning_rate: 0.0020441\n",
      "Training loss: 0.102359 , Training acc:  0.974953\n",
      "Test loss: 0.317096 , Test acc:  0.884615\n",
      "--------------------------------------------------------------------------------\n",
      "Step 6720\n",
      "learning_rate: 0.0020441\n",
      "Training loss: 0.105804 , Training acc:  0.970623\n",
      "Test loss: 0.320883 , Test acc:  0.883952\n",
      "--------------------------------------------------------------------------------\n",
      "Step 6740\n",
      "learning_rate: 0.0020441\n",
      "Training loss: 0.0963643 , Training acc:  0.974836\n",
      "Test loss: 0.30125 , Test acc:  0.892573\n",
      "--------------------------------------------------------------------------------\n",
      "Step 6760\n",
      "learning_rate: 0.00202366\n",
      "Training loss: 0.107017 , Training acc:  0.968867\n",
      "Test loss: 0.319757 , Test acc:  0.886605\n",
      "--------------------------------------------------------------------------------\n",
      "Step 6780\n",
      "learning_rate: 0.00202366\n",
      "Training loss: 0.101156 , Training acc:  0.9739\n",
      "Test loss: 0.314397 , Test acc:  0.890584\n",
      "--------------------------------------------------------------------------------\n",
      "Step 6800\n",
      "learning_rate: 0.00202366\n",
      "Training loss: 0.109632 , Training acc:  0.970272\n",
      "Test loss: 0.314638 , Test acc:  0.887268\n",
      "--------------------------------------------------------------------------------\n",
      "Step 6820\n",
      "learning_rate: 0.00202366\n",
      "Training loss: 0.0975577 , Training acc:  0.974485\n",
      "Test loss: 0.307106 , Test acc:  0.887268\n",
      "--------------------------------------------------------------------------------\n",
      "Step 6840\n",
      "learning_rate: 0.00200343\n",
      "Training loss: 0.108908 , Training acc:  0.970857\n",
      "Test loss: 0.329048 , Test acc:  0.877984\n",
      "--------------------------------------------------------------------------------\n",
      "Step 6860\n",
      "learning_rate: 0.00200343\n",
      "Training loss: 0.0990374 , Training acc:  0.9739\n",
      "Test loss: 0.318386 , Test acc:  0.885942\n",
      "--------------------------------------------------------------------------------\n",
      "Step 6880\n",
      "learning_rate: 0.00200343\n",
      "Training loss: 0.133415 , Training acc:  0.958802\n",
      "Test loss: 0.349172 , Test acc:  0.871353\n",
      "--------------------------------------------------------------------------------\n",
      "Step 6900\n",
      "learning_rate: 0.00198339\n",
      "Training loss: 0.112498 , Training acc:  0.970974\n",
      "Test loss: 0.316166 , Test acc:  0.88992\n",
      "--------------------------------------------------------------------------------\n",
      "Step 6920\n",
      "learning_rate: 0.00198339\n",
      "Training loss: 0.115982 , Training acc:  0.964185\n",
      "Test loss: 0.324968 , Test acc:  0.8813\n",
      "--------------------------------------------------------------------------------\n",
      "Step 6940\n",
      "learning_rate: 0.00198339\n",
      "Training loss: 0.0977667 , Training acc:  0.970857\n",
      "Test loss: 0.297798 , Test acc:  0.895225\n",
      "--------------------------------------------------------------------------------\n",
      "Step 6960\n",
      "learning_rate: 0.00198339\n",
      "Training loss: 0.106688 , Training acc:  0.972144\n",
      "Test loss: 0.321196 , Test acc:  0.887931\n",
      "--------------------------------------------------------------------------------\n",
      "Step 6980\n",
      "learning_rate: 0.00196356\n",
      "Training loss: 0.0956288 , Training acc:  0.974719\n",
      "Test loss: 0.302784 , Test acc:  0.890584\n",
      "--------------------------------------------------------------------------------\n",
      "Step 7000\n",
      "learning_rate: 0.00196356\n",
      "Training loss: 0.094397 , Training acc:  0.974485\n",
      "Test loss: 0.302824 , Test acc:  0.888594\n",
      "--------------------------------------------------------------------------------\n",
      "Step 7020\n",
      "learning_rate: 0.00196356\n",
      "Training loss: 0.0975538 , Training acc:  0.974719\n",
      "Test loss: 0.312437 , Test acc:  0.888594\n",
      "--------------------------------------------------------------------------------\n",
      "Step 7040\n",
      "learning_rate: 0.00196356\n",
      "Training loss: 0.116889 , Training acc:  0.966994\n",
      "Test loss: 0.330723 , Test acc:  0.880637\n",
      "--------------------------------------------------------------------------------\n",
      "Step 7060\n",
      "learning_rate: 0.00194392\n",
      "Training loss: 0.0988403 , Training acc:  0.975187\n",
      "Test loss: 0.307171 , Test acc:  0.889257\n",
      "--------------------------------------------------------------------------------\n",
      "Step 7080\n",
      "learning_rate: 0.00194392\n",
      "Training loss: 0.093024 , Training acc:  0.975538\n",
      "Test loss: 0.302391 , Test acc:  0.895889\n",
      "--------------------------------------------------------------------------------\n",
      "Step 7100\n",
      "learning_rate: 0.00194392\n",
      "Training loss: 0.0867002 , Training acc:  0.975304\n",
      "Test loss: 0.296852 , Test acc:  0.894562\n",
      "--------------------------------------------------------------------------------\n",
      "Step 7120\n",
      "learning_rate: 0.00194392\n",
      "Training loss: 0.094695 , Training acc:  0.972729\n",
      "Test loss: 0.305198 , Test acc:  0.88992\n",
      "--------------------------------------------------------------------------------\n",
      "Step 7140\n",
      "learning_rate: 0.00192448\n",
      "Training loss: 0.0982013 , Training acc:  0.974251\n",
      "Test loss: 0.313535 , Test acc:  0.89191\n",
      "--------------------------------------------------------------------------------\n",
      "Step 7160\n",
      "learning_rate: 0.00192448\n",
      "Training loss: 0.103143 , Training acc:  0.971676\n",
      "Test loss: 0.325504 , Test acc:  0.885942\n",
      "--------------------------------------------------------------------------------\n",
      "Step 7180\n",
      "learning_rate: 0.00192448\n",
      "Training loss: 0.100318 , Training acc:  0.973549\n",
      "Test loss: 0.319152 , Test acc:  0.888594\n",
      "--------------------------------------------------------------------------------\n",
      "Step 7200\n",
      "learning_rate: 0.00190524\n",
      "Training loss: 0.098671 , Training acc:  0.974134\n",
      "Test loss: 0.321322 , Test acc:  0.885942\n",
      "--------------------------------------------------------------------------------\n",
      "Step 7220\n",
      "learning_rate: 0.00190524\n",
      "Training loss: 0.087339 , Training acc:  0.98139\n",
      "Test loss: 0.302738 , Test acc:  0.892573\n",
      "--------------------------------------------------------------------------------\n",
      "Step 7240\n",
      "learning_rate: 0.00190524\n",
      "Training loss: 0.0877243 , Training acc:  0.980922\n",
      "Test loss: 0.305208 , Test acc:  0.89191\n",
      "--------------------------------------------------------------------------------\n",
      "Step 7260\n",
      "learning_rate: 0.00190524\n",
      "Training loss: 0.0934336 , Training acc:  0.977294\n",
      "Test loss: 0.305339 , Test acc:  0.887931\n",
      "--------------------------------------------------------------------------------\n",
      "Step 7280\n",
      "learning_rate: 0.00188618\n",
      "Training loss: 0.0963543 , Training acc:  0.973432\n",
      "Test loss: 0.318557 , Test acc:  0.885279\n",
      "--------------------------------------------------------------------------------\n",
      "Step 7300\n",
      "learning_rate: 0.00188618\n",
      "Training loss: 0.0879985 , Training acc:  0.979284\n",
      "Test loss: 0.30051 , Test acc:  0.88992\n",
      "--------------------------------------------------------------------------------\n",
      "Step 7320\n",
      "learning_rate: 0.00188618\n",
      "Training loss: 0.0853831 , Training acc:  0.977528\n",
      "Test loss: 0.302406 , Test acc:  0.887931\n",
      "--------------------------------------------------------------------------------\n",
      "Step 7340\n",
      "learning_rate: 0.00188618\n",
      "Training loss: 0.0914366 , Training acc:  0.973666\n",
      "Test loss: 0.297315 , Test acc:  0.892573\n",
      "--------------------------------------------------------------------------------\n",
      "Step 7360\n",
      "learning_rate: 0.00186732\n",
      "Training loss: 0.086309 , Training acc:  0.97706\n",
      "Test loss: 0.29678 , Test acc:  0.888594\n",
      "--------------------------------------------------------------------------------\n",
      "Step 7380\n",
      "learning_rate: 0.00186732\n",
      "Training loss: 0.0822597 , Training acc:  0.977645\n",
      "Test loss: 0.296378 , Test acc:  0.89191\n",
      "--------------------------------------------------------------------------------\n",
      "Step 7400\n",
      "learning_rate: 0.00186732\n",
      "Training loss: 0.0753242 , Training acc:  0.981742\n",
      "Test loss: 0.29876 , Test acc:  0.897878\n",
      "--------------------------------------------------------------------------------\n",
      "Step 7420\n",
      "learning_rate: 0.00186732\n",
      "Training loss: 0.0737809 , Training acc:  0.981507\n",
      "Test loss: 0.291359 , Test acc:  0.893899\n",
      "--------------------------------------------------------------------------------\n",
      "Step 7440\n",
      "learning_rate: 0.00184865\n",
      "Training loss: 0.0866823 , Training acc:  0.977411\n",
      "Test loss: 0.300237 , Test acc:  0.895225\n",
      "--------------------------------------------------------------------------------\n",
      "Step 7460\n",
      "learning_rate: 0.00184865\n",
      "Training loss: 0.0867316 , Training acc:  0.978347\n",
      "Test loss: 0.299346 , Test acc:  0.897215\n",
      "--------------------------------------------------------------------------------\n",
      "Step 7480\n",
      "learning_rate: 0.00184865\n",
      "Training loss: 0.0843475 , Training acc:  0.977996\n",
      "Test loss: 0.296472 , Test acc:  0.893899\n",
      "--------------------------------------------------------------------------------\n",
      "Step 7500\n",
      "learning_rate: 0.00183016\n",
      "Training loss: 0.0781441 , Training acc:  0.982327\n",
      "Test loss: 0.282578 , Test acc:  0.899867\n",
      "--------------------------------------------------------------------------------\n",
      "Step 7520\n",
      "learning_rate: 0.00183016\n",
      "Training loss: 0.0843132 , Training acc:  0.977294\n",
      "Test loss: 0.295226 , Test acc:  0.898541\n",
      "--------------------------------------------------------------------------------\n",
      "Step 7540\n",
      "learning_rate: 0.00183016\n",
      "Training loss: 0.0788081 , Training acc:  0.980571\n",
      "Test loss: 0.287437 , Test acc:  0.895225\n",
      "--------------------------------------------------------------------------------\n",
      "Step 7560\n",
      "learning_rate: 0.00183016\n",
      "Training loss: 0.0771962 , Training acc:  0.981625\n",
      "Test loss: 0.285614 , Test acc:  0.895225\n",
      "--------------------------------------------------------------------------------\n",
      "Step 7580\n",
      "learning_rate: 0.00181186\n",
      "Training loss: 0.0812348 , Training acc:  0.978816\n",
      "Test loss: 0.299352 , Test acc:  0.897878\n",
      "--------------------------------------------------------------------------------\n",
      "Step 7600\n",
      "learning_rate: 0.00181186\n",
      "Training loss: 0.0758866 , Training acc:  0.983965\n",
      "Test loss: 0.282184 , Test acc:  0.895889\n",
      "--------------------------------------------------------------------------------\n",
      "Step 7620\n",
      "learning_rate: 0.00181186\n",
      "Training loss: 0.0787714 , Training acc:  0.980688\n",
      "Test loss: 0.289253 , Test acc:  0.897878\n",
      "--------------------------------------------------------------------------------\n",
      "Step 7640\n",
      "learning_rate: 0.00181186\n",
      "Training loss: 0.0815736 , Training acc:  0.979635\n",
      "Test loss: 0.308134 , Test acc:  0.887268\n",
      "--------------------------------------------------------------------------------\n",
      "Step 7660\n",
      "learning_rate: 0.00179374\n",
      "Training loss: 0.0832491 , Training acc:  0.981156\n",
      "Test loss: 0.297464 , Test acc:  0.88992\n",
      "--------------------------------------------------------------------------------\n",
      "Step 7680\n",
      "learning_rate: 0.00179374\n",
      "Training loss: 0.0855514 , Training acc:  0.980337\n",
      "Test loss: 0.301616 , Test acc:  0.887931\n",
      "--------------------------------------------------------------------------------\n",
      "Step 7700\n",
      "learning_rate: 0.00179374\n",
      "Training loss: 0.0824094 , Training acc:  0.980103\n",
      "Test loss: 0.293141 , Test acc:  0.898541\n",
      "--------------------------------------------------------------------------------\n",
      "Step 7720\n",
      "learning_rate: 0.00179374\n",
      "Training loss: 0.0789313 , Training acc:  0.98139\n",
      "Test loss: 0.290049 , Test acc:  0.898541\n",
      "--------------------------------------------------------------------------------\n",
      "Step 7740\n",
      "learning_rate: 0.00177581\n",
      "Training loss: 0.0879464 , Training acc:  0.978816\n",
      "Test loss: 0.299795 , Test acc:  0.899867\n",
      "--------------------------------------------------------------------------------\n",
      "Step 7760\n",
      "learning_rate: 0.00177581\n",
      "Training loss: 0.0797477 , Training acc:  0.984082\n",
      "Test loss: 0.299007 , Test acc:  0.893236\n",
      "--------------------------------------------------------------------------------\n",
      "Step 7780\n",
      "learning_rate: 0.00177581\n",
      "Training loss: 0.0785466 , Training acc:  0.983263\n",
      "Test loss: 0.302211 , Test acc:  0.89191\n",
      "--------------------------------------------------------------------------------\n",
      "Step 7800\n",
      "learning_rate: 0.00175805\n",
      "Training loss: 0.0802448 , Training acc:  0.980337\n",
      "Test loss: 0.29959 , Test acc:  0.892573\n",
      "--------------------------------------------------------------------------------\n",
      "Step 7820\n",
      "learning_rate: 0.00175805\n",
      "Training loss: 0.0854002 , Training acc:  0.976943\n",
      "Test loss: 0.304251 , Test acc:  0.888594\n",
      "--------------------------------------------------------------------------------\n",
      "Step 7840\n",
      "learning_rate: 0.00175805\n",
      "Training loss: 0.0811782 , Training acc:  0.980103\n",
      "Test loss: 0.302601 , Test acc:  0.892573\n",
      "--------------------------------------------------------------------------------\n",
      "Step 7860\n",
      "learning_rate: 0.00175805\n",
      "Training loss: 0.0973431 , Training acc:  0.973198\n",
      "Test loss: 0.333023 , Test acc:  0.884615\n",
      "--------------------------------------------------------------------------------\n",
      "Step 7880\n",
      "learning_rate: 0.00174047\n",
      "Training loss: 0.0813117 , Training acc:  0.980454\n",
      "Test loss: 0.296266 , Test acc:  0.89191\n",
      "--------------------------------------------------------------------------------\n",
      "Step 7900\n",
      "learning_rate: 0.00174047\n",
      "Training loss: 0.075928 , Training acc:  0.982678\n",
      "Test loss: 0.284663 , Test acc:  0.899867\n",
      "--------------------------------------------------------------------------------\n",
      "Step 7920\n",
      "learning_rate: 0.00174047\n",
      "Training loss: 0.0844039 , Training acc:  0.977879\n",
      "Test loss: 0.300052 , Test acc:  0.892573\n",
      "--------------------------------------------------------------------------------\n",
      "Step 7940\n",
      "learning_rate: 0.00174047\n",
      "Training loss: 0.0875681 , Training acc:  0.97706\n",
      "Test loss: 0.322379 , Test acc:  0.892573\n",
      "--------------------------------------------------------------------------------\n",
      "Step 7960\n",
      "learning_rate: 0.00172306\n",
      "Training loss: 0.0674852 , Training acc:  0.986774\n",
      "Test loss: 0.285211 , Test acc:  0.903846\n",
      "--------------------------------------------------------------------------------\n",
      "Step 7980\n",
      "learning_rate: 0.00172306\n",
      "Training loss: 0.0700302 , Training acc:  0.983848\n",
      "Test loss: 0.289276 , Test acc:  0.90252\n",
      "--------------------------------------------------------------------------------\n",
      "Step 8000\n",
      "learning_rate: 0.00172306\n",
      "Training loss: 0.0832982 , Training acc:  0.977762\n",
      "Test loss: 0.310824 , Test acc:  0.89191\n",
      "--------------------------------------------------------------------------------\n",
      "Step 8020\n",
      "learning_rate: 0.00172306\n",
      "Training loss: 0.0785099 , Training acc:  0.979752\n",
      "Test loss: 0.293396 , Test acc:  0.901857\n",
      "--------------------------------------------------------------------------------\n",
      "Step 8040\n",
      "learning_rate: 0.00170583\n",
      "Training loss: 0.0824988 , Training acc:  0.978113\n",
      "Test loss: 0.311442 , Test acc:  0.895889\n",
      "--------------------------------------------------------------------------------\n",
      "Step 8060\n",
      "learning_rate: 0.00170583\n",
      "Training loss: 0.0744464 , Training acc:  0.982444\n",
      "Test loss: 0.292512 , Test acc:  0.897215\n",
      "--------------------------------------------------------------------------------\n",
      "Step 8080\n",
      "learning_rate: 0.00170583\n",
      "Training loss: 0.0708279 , Training acc:  0.981039\n",
      "Test loss: 0.28632 , Test acc:  0.903183\n",
      "--------------------------------------------------------------------------------\n",
      "Step 8100\n",
      "learning_rate: 0.00168877\n",
      "Training loss: 0.0804433 , Training acc:  0.978816\n",
      "Test loss: 0.302209 , Test acc:  0.899867\n",
      "--------------------------------------------------------------------------------\n",
      "Step 8120\n",
      "learning_rate: 0.00168877\n",
      "Training loss: 0.0721311 , Training acc:  0.980688\n",
      "Test loss: 0.289851 , Test acc:  0.897878\n",
      "--------------------------------------------------------------------------------\n",
      "Step 8140\n",
      "learning_rate: 0.00168877\n",
      "Training loss: 0.0883062 , Training acc:  0.976358\n",
      "Test loss: 0.332811 , Test acc:  0.889257\n",
      "--------------------------------------------------------------------------------\n",
      "Step 8160\n",
      "learning_rate: 0.00168877\n",
      "Training loss: 0.0708079 , Training acc:  0.980571\n",
      "Test loss: 0.306683 , Test acc:  0.892573\n",
      "--------------------------------------------------------------------------------\n",
      "Step 8180\n",
      "learning_rate: 0.00167189\n",
      "Training loss: 0.0768058 , Training acc:  0.978933\n",
      "Test loss: 0.315946 , Test acc:  0.889257\n",
      "--------------------------------------------------------------------------------\n",
      "Step 8200\n",
      "learning_rate: 0.00167189\n",
      "Training loss: 0.0770252 , Training acc:  0.980103\n",
      "Test loss: 0.311391 , Test acc:  0.889257\n",
      "--------------------------------------------------------------------------------\n",
      "Step 8220\n",
      "learning_rate: 0.00167189\n",
      "Training loss: 0.0787899 , Training acc:  0.980571\n",
      "Test loss: 0.322022 , Test acc:  0.892573\n",
      "--------------------------------------------------------------------------------\n",
      "Step 8240\n",
      "learning_rate: 0.00167189\n",
      "Training loss: 0.0801555 , Training acc:  0.978698\n",
      "Test loss: 0.308173 , Test acc:  0.892573\n",
      "--------------------------------------------------------------------------------\n",
      "Step 8260\n",
      "learning_rate: 0.00165517\n",
      "Training loss: 0.07944 , Training acc:  0.980571\n",
      "Test loss: 0.310105 , Test acc:  0.890584\n",
      "--------------------------------------------------------------------------------\n",
      "Step 8280\n",
      "learning_rate: 0.00165517\n",
      "Training loss: 0.0695468 , Training acc:  0.983965\n",
      "Test loss: 0.300037 , Test acc:  0.895225\n",
      "--------------------------------------------------------------------------------\n",
      "Step 8300\n",
      "learning_rate: 0.00165517\n",
      "Training loss: 0.0729278 , Training acc:  0.98221\n",
      "Test loss: 0.309634 , Test acc:  0.886605\n",
      "--------------------------------------------------------------------------------\n",
      "Step 8320\n",
      "learning_rate: 0.00165517\n",
      "Training loss: 0.0695502 , Training acc:  0.982795\n",
      "Test loss: 0.312601 , Test acc:  0.89191\n",
      "--------------------------------------------------------------------------------\n",
      "Step 8340\n",
      "learning_rate: 0.00163862\n",
      "Training loss: 0.0685198 , Training acc:  0.984551\n",
      "Test loss: 0.314717 , Test acc:  0.891247\n",
      "--------------------------------------------------------------------------------\n",
      "Step 8360\n",
      "learning_rate: 0.00163862\n",
      "Training loss: 0.0686412 , Training acc:  0.982912\n",
      "Test loss: 0.312723 , Test acc:  0.88992\n",
      "--------------------------------------------------------------------------------\n",
      "Step 8380\n",
      "learning_rate: 0.00163862\n",
      "Training loss: 0.0759832 , Training acc:  0.978113\n",
      "Test loss: 0.324109 , Test acc:  0.888594\n",
      "--------------------------------------------------------------------------------\n",
      "Step 8400\n",
      "learning_rate: 0.00162223\n",
      "Training loss: 0.0742094 , Training acc:  0.979869\n",
      "Test loss: 0.323353 , Test acc:  0.885279\n",
      "--------------------------------------------------------------------------------\n",
      "Step 8420\n",
      "learning_rate: 0.00162223\n",
      "Training loss: 0.0665272 , Training acc:  0.983731\n",
      "Test loss: 0.310334 , Test acc:  0.894562\n",
      "--------------------------------------------------------------------------------\n",
      "Step 8440\n",
      "learning_rate: 0.00162223\n",
      "Training loss: 0.0647971 , Training acc:  0.984316\n",
      "Test loss: 0.30848 , Test acc:  0.896552\n",
      "--------------------------------------------------------------------------------\n",
      "Step 8460\n",
      "learning_rate: 0.00162223\n",
      "Training loss: 0.0626734 , Training acc:  0.984316\n",
      "Test loss: 0.299558 , Test acc:  0.89191\n",
      "--------------------------------------------------------------------------------\n",
      "Step 8480\n",
      "learning_rate: 0.00160601\n",
      "Training loss: 0.0708624 , Training acc:  0.981156\n",
      "Test loss: 0.309096 , Test acc:  0.895225\n",
      "--------------------------------------------------------------------------------\n",
      "Step 8500\n",
      "learning_rate: 0.00160601\n",
      "Training loss: 0.0599596 , Training acc:  0.985721\n",
      "Test loss: 0.290803 , Test acc:  0.88992\n",
      "--------------------------------------------------------------------------------\n",
      "Step 8520\n",
      "learning_rate: 0.00160601\n",
      "Training loss: 0.0702838 , Training acc:  0.983497\n",
      "Test loss: 0.311034 , Test acc:  0.892573\n",
      "--------------------------------------------------------------------------------\n",
      "Step 8540\n",
      "learning_rate: 0.00160601\n",
      "Training loss: 0.0707624 , Training acc:  0.984668\n",
      "Test loss: 0.295977 , Test acc:  0.89191\n",
      "--------------------------------------------------------------------------------\n",
      "Step 8560\n",
      "learning_rate: 0.00158995\n",
      "Training loss: 0.0757812 , Training acc:  0.981156\n",
      "Test loss: 0.319947 , Test acc:  0.887931\n",
      "--------------------------------------------------------------------------------\n",
      "Step 8580\n",
      "learning_rate: 0.00158995\n",
      "Training loss: 0.069212 , Training acc:  0.983146\n",
      "Test loss: 0.306187 , Test acc:  0.885279\n",
      "--------------------------------------------------------------------------------\n",
      "Step 8600\n",
      "learning_rate: 0.00158995\n",
      "Training loss: 0.07541 , Training acc:  0.980454\n",
      "Test loss: 0.318166 , Test acc:  0.887268\n",
      "--------------------------------------------------------------------------------\n",
      "Step 8620\n",
      "learning_rate: 0.00158995\n",
      "Training loss: 0.0696452 , Training acc:  0.983848\n",
      "Test loss: 0.300284 , Test acc:  0.896552\n",
      "--------------------------------------------------------------------------------\n",
      "Step 8640\n",
      "learning_rate: 0.00157405\n",
      "Training loss: 0.0764801 , Training acc:  0.980337\n",
      "Test loss: 0.306551 , Test acc:  0.887931\n",
      "--------------------------------------------------------------------------------\n",
      "Step 8660\n",
      "learning_rate: 0.00157405\n",
      "Training loss: 0.0653297 , Training acc:  0.984082\n",
      "Test loss: 0.310404 , Test acc:  0.894562\n",
      "--------------------------------------------------------------------------------\n",
      "Step 8680\n",
      "learning_rate: 0.00157405\n",
      "Training loss: 0.0699542 , Training acc:  0.982912\n",
      "Test loss: 0.309334 , Test acc:  0.892573\n",
      "--------------------------------------------------------------------------------\n",
      "Step 8700\n",
      "learning_rate: 0.00155831\n",
      "Training loss: 0.0698767 , Training acc:  0.984316\n",
      "Test loss: 0.307331 , Test acc:  0.891247\n",
      "--------------------------------------------------------------------------------\n",
      "Step 8720\n",
      "learning_rate: 0.00155831\n",
      "Training loss: 0.0737364 , Training acc:  0.981742\n",
      "Test loss: 0.308681 , Test acc:  0.888594\n",
      "--------------------------------------------------------------------------------\n",
      "Step 8740\n",
      "learning_rate: 0.00155831\n",
      "Training loss: 0.0677394 , Training acc:  0.983497\n",
      "Test loss: 0.312388 , Test acc:  0.890584\n",
      "--------------------------------------------------------------------------------\n",
      "Step 8760\n",
      "learning_rate: 0.00155831\n",
      "Training loss: 0.0664983 , Training acc:  0.984551\n",
      "Test loss: 0.314442 , Test acc:  0.899204\n",
      "--------------------------------------------------------------------------------\n",
      "Step 8780\n",
      "learning_rate: 0.00154272\n",
      "Training loss: 0.0749814 , Training acc:  0.97905\n",
      "Test loss: 0.316037 , Test acc:  0.888594\n",
      "--------------------------------------------------------------------------------\n",
      "Step 8800\n",
      "learning_rate: 0.00154272\n",
      "Training loss: 0.0742842 , Training acc:  0.979752\n",
      "Test loss: 0.313636 , Test acc:  0.895225\n",
      "--------------------------------------------------------------------------------\n",
      "Step 8820\n",
      "learning_rate: 0.00154272\n",
      "Training loss: 0.0676856 , Training acc:  0.985019\n",
      "Test loss: 0.303639 , Test acc:  0.893236\n",
      "--------------------------------------------------------------------------------\n",
      "Step 8840\n",
      "learning_rate: 0.00154272\n",
      "Training loss: 0.0691004 , Training acc:  0.984434\n",
      "Test loss: 0.294997 , Test acc:  0.893236\n",
      "--------------------------------------------------------------------------------\n",
      "Step 8860\n",
      "learning_rate: 0.0015273\n",
      "Training loss: 0.0670646 , Training acc:  0.981859\n",
      "Test loss: 0.290277 , Test acc:  0.899204\n",
      "--------------------------------------------------------------------------------\n",
      "Step 8880\n",
      "learning_rate: 0.0015273\n",
      "Training loss: 0.0646205 , Training acc:  0.985019\n",
      "Test loss: 0.293823 , Test acc:  0.897878\n",
      "--------------------------------------------------------------------------------\n",
      "Step 8900\n",
      "learning_rate: 0.0015273\n",
      "Training loss: 0.0608949 , Training acc:  0.988296\n",
      "Test loss: 0.297375 , Test acc:  0.897878\n",
      "--------------------------------------------------------------------------------\n",
      "Step 8920\n",
      "learning_rate: 0.0015273\n",
      "Training loss: 0.0570023 , Training acc:  0.988998\n",
      "Test loss: 0.286175 , Test acc:  0.899204\n",
      "--------------------------------------------------------------------------------\n",
      "Step 8940\n",
      "learning_rate: 0.00151202\n",
      "Training loss: 0.0590843 , Training acc:  0.987711\n",
      "Test loss: 0.293553 , Test acc:  0.893899\n",
      "--------------------------------------------------------------------------------\n",
      "Step 8960\n",
      "learning_rate: 0.00151202\n",
      "Training loss: 0.0581561 , Training acc:  0.98537\n",
      "Test loss: 0.297743 , Test acc:  0.901194\n",
      "--------------------------------------------------------------------------------\n",
      "Step 8980\n",
      "learning_rate: 0.00151202\n",
      "Training loss: 0.0610748 , Training acc:  0.985721\n",
      "Test loss: 0.30708 , Test acc:  0.891247\n",
      "--------------------------------------------------------------------------------\n",
      "Step 9000\n",
      "learning_rate: 0.0014969\n",
      "Training loss: 0.0592992 , Training acc:  0.985955\n",
      "Test loss: 0.298775 , Test acc:  0.887931\n",
      "--------------------------------------------------------------------------------\n",
      "Step 9020\n",
      "learning_rate: 0.0014969\n",
      "Training loss: 0.0642596 , Training acc:  0.984551\n",
      "Test loss: 0.307823 , Test acc:  0.894562\n",
      "--------------------------------------------------------------------------------\n",
      "Step 9040\n",
      "learning_rate: 0.0014969\n",
      "Training loss: 0.059642 , Training acc:  0.98654\n",
      "Test loss: 0.297026 , Test acc:  0.893236\n",
      "--------------------------------------------------------------------------------\n",
      "Step 9060\n",
      "learning_rate: 0.0014969\n",
      "Training loss: 0.0593239 , Training acc:  0.985487\n",
      "Test loss: 0.296151 , Test acc:  0.893236\n",
      "--------------------------------------------------------------------------------\n",
      "Step 9080\n",
      "learning_rate: 0.00148193\n",
      "Training loss: 0.0642672 , Training acc:  0.983965\n",
      "Test loss: 0.310384 , Test acc:  0.899204\n",
      "--------------------------------------------------------------------------------\n",
      "Step 9100\n",
      "learning_rate: 0.00148193\n",
      "Training loss: 0.0693849 , Training acc:  0.983029\n",
      "Test loss: 0.313773 , Test acc:  0.892573\n",
      "--------------------------------------------------------------------------------\n",
      "Step 9120\n",
      "learning_rate: 0.00148193\n",
      "Training loss: 0.0581061 , Training acc:  0.988179\n",
      "Test loss: 0.288892 , Test acc:  0.894562\n",
      "--------------------------------------------------------------------------------\n",
      "Step 9140\n",
      "learning_rate: 0.00148193\n",
      "Training loss: 0.0598281 , Training acc:  0.985721\n",
      "Test loss: 0.291784 , Test acc:  0.895889\n",
      "--------------------------------------------------------------------------------\n",
      "Step 9160\n",
      "learning_rate: 0.00146712\n",
      "Training loss: 0.0578012 , Training acc:  0.987008\n",
      "Test loss: 0.291368 , Test acc:  0.894562\n",
      "--------------------------------------------------------------------------------\n",
      "Step 9180\n",
      "learning_rate: 0.00146712\n",
      "Training loss: 0.0608511 , Training acc:  0.985019\n",
      "Test loss: 0.305342 , Test acc:  0.895225\n",
      "--------------------------------------------------------------------------------\n",
      "Step 9200\n",
      "learning_rate: 0.00146712\n",
      "Training loss: 0.0556291 , Training acc:  0.987125\n",
      "Test loss: 0.305804 , Test acc:  0.894562\n",
      "--------------------------------------------------------------------------------\n",
      "Step 9220\n",
      "learning_rate: 0.00146712\n",
      "Training loss: 0.0541914 , Training acc:  0.98853\n",
      "Test loss: 0.28144 , Test acc:  0.900531\n",
      "--------------------------------------------------------------------------------\n",
      "Step 9240\n",
      "learning_rate: 0.00145244\n",
      "Training loss: 0.0515719 , Training acc:  0.988179\n",
      "Test loss: 0.280115 , Test acc:  0.901857\n",
      "--------------------------------------------------------------------------------\n",
      "Step 9260\n",
      "learning_rate: 0.00145244\n",
      "Training loss: 0.0521969 , Training acc:  0.988413\n",
      "Test loss: 0.289123 , Test acc:  0.901857\n",
      "--------------------------------------------------------------------------------\n",
      "Step 9280\n",
      "learning_rate: 0.00145244\n",
      "Training loss: 0.052902 , Training acc:  0.98736\n",
      "Test loss: 0.290329 , Test acc:  0.893899\n",
      "--------------------------------------------------------------------------------\n",
      "Step 9300\n",
      "learning_rate: 0.00143792\n",
      "Training loss: 0.0570401 , Training acc:  0.987125\n",
      "Test loss: 0.285373 , Test acc:  0.893899\n",
      "--------------------------------------------------------------------------------\n",
      "Step 9320\n",
      "learning_rate: 0.00143792\n",
      "Training loss: 0.0652687 , Training acc:  0.983848\n",
      "Test loss: 0.303358 , Test acc:  0.899204\n",
      "--------------------------------------------------------------------------------\n",
      "Step 9340\n",
      "learning_rate: 0.00143792\n",
      "Training loss: 0.061219 , Training acc:  0.987243\n",
      "Test loss: 0.3032 , Test acc:  0.895889\n",
      "--------------------------------------------------------------------------------\n",
      "Step 9360\n",
      "learning_rate: 0.00143792\n",
      "Training loss: 0.0575715 , Training acc:  0.98736\n",
      "Test loss: 0.291983 , Test acc:  0.895889\n",
      "--------------------------------------------------------------------------------\n",
      "Step 9380\n",
      "learning_rate: 0.00142354\n",
      "Training loss: 0.0564321 , Training acc:  0.989349\n",
      "Test loss: 0.296697 , Test acc:  0.890584\n",
      "--------------------------------------------------------------------------------\n",
      "Step 9400\n",
      "learning_rate: 0.00142354\n",
      "Training loss: 0.0589797 , Training acc:  0.98654\n",
      "Test loss: 0.287001 , Test acc:  0.894562\n",
      "--------------------------------------------------------------------------------\n",
      "Step 9420\n",
      "learning_rate: 0.00142354\n",
      "Training loss: 0.0652183 , Training acc:  0.98537\n",
      "Test loss: 0.293717 , Test acc:  0.895889\n",
      "--------------------------------------------------------------------------------\n",
      "Step 9440\n",
      "learning_rate: 0.00142354\n",
      "Training loss: 0.067723 , Training acc:  0.985019\n",
      "Test loss: 0.288868 , Test acc:  0.903183\n",
      "--------------------------------------------------------------------------------\n",
      "Step 9460\n",
      "learning_rate: 0.00140931\n",
      "Training loss: 0.059196 , Training acc:  0.988296\n",
      "Test loss: 0.286234 , Test acc:  0.897215\n",
      "--------------------------------------------------------------------------------\n",
      "Step 9480\n",
      "learning_rate: 0.00140931\n",
      "Training loss: 0.0560032 , Training acc:  0.989115\n",
      "Test loss: 0.276226 , Test acc:  0.900531\n",
      "--------------------------------------------------------------------------------\n",
      "Step 9500\n",
      "learning_rate: 0.00140931\n",
      "Training loss: 0.0606499 , Training acc:  0.987243\n",
      "Test loss: 0.284562 , Test acc:  0.899867\n",
      "--------------------------------------------------------------------------------\n",
      "Step 9520\n",
      "learning_rate: 0.00140931\n",
      "Training loss: 0.0708367 , Training acc:  0.981859\n",
      "Test loss: 0.311887 , Test acc:  0.897878\n",
      "--------------------------------------------------------------------------------\n",
      "Step 9540\n",
      "learning_rate: 0.00139521\n",
      "Training loss: 0.0581114 , Training acc:  0.988764\n",
      "Test loss: 0.283607 , Test acc:  0.897215\n",
      "--------------------------------------------------------------------------------\n",
      "Step 9560\n",
      "learning_rate: 0.00139521\n",
      "Training loss: 0.06707 , Training acc:  0.984551\n",
      "Test loss: 0.29909 , Test acc:  0.887268\n",
      "--------------------------------------------------------------------------------\n",
      "Step 9580\n",
      "learning_rate: 0.00139521\n",
      "Training loss: 0.0573474 , Training acc:  0.988179\n",
      "Test loss: 0.291267 , Test acc:  0.894562\n",
      "--------------------------------------------------------------------------------\n",
      "Step 9600\n",
      "learning_rate: 0.00138126\n",
      "Training loss: 0.0507249 , Training acc:  0.991339\n",
      "Test loss: 0.280136 , Test acc:  0.903183\n",
      "--------------------------------------------------------------------------------\n",
      "Step 9620\n",
      "learning_rate: 0.00138126\n",
      "Training loss: 0.0566317 , Training acc:  0.987828\n",
      "Test loss: 0.286174 , Test acc:  0.899867\n",
      "--------------------------------------------------------------------------------\n",
      "Step 9640\n",
      "learning_rate: 0.00138126\n",
      "Training loss: 0.0540548 , Training acc:  0.989583\n",
      "Test loss: 0.296453 , Test acc:  0.90252\n",
      "--------------------------------------------------------------------------------\n",
      "Step 9660\n",
      "learning_rate: 0.00138126\n",
      "Training loss: 0.060391 , Training acc:  0.986072\n",
      "Test loss: 0.297052 , Test acc:  0.893899\n",
      "--------------------------------------------------------------------------------\n",
      "Step 9680\n",
      "learning_rate: 0.00136745\n",
      "Training loss: 0.0581747 , Training acc:  0.988764\n",
      "Test loss: 0.297672 , Test acc:  0.893236\n",
      "--------------------------------------------------------------------------------\n",
      "Step 9700\n",
      "learning_rate: 0.00136745\n",
      "Training loss: 0.0558873 , Training acc:  0.989466\n",
      "Test loss: 0.294171 , Test acc:  0.892573\n",
      "--------------------------------------------------------------------------------\n",
      "Step 9720\n",
      "learning_rate: 0.00136745\n",
      "Training loss: 0.0562517 , Training acc:  0.988647\n",
      "Test loss: 0.301901 , Test acc:  0.885279\n",
      "--------------------------------------------------------------------------------\n",
      "Step 9740\n",
      "learning_rate: 0.00136745\n",
      "Training loss: 0.0497766 , Training acc:  0.989583\n",
      "Test loss: 0.293305 , Test acc:  0.895889\n",
      "--------------------------------------------------------------------------------\n",
      "Step 9760\n",
      "learning_rate: 0.00135377\n",
      "Training loss: 0.0520921 , Training acc:  0.989466\n",
      "Test loss: 0.297631 , Test acc:  0.89191\n",
      "--------------------------------------------------------------------------------\n",
      "Step 9780\n",
      "learning_rate: 0.00135377\n",
      "Training loss: 0.0629954 , Training acc:  0.983965\n",
      "Test loss: 0.299539 , Test acc:  0.892573\n",
      "--------------------------------------------------------------------------------\n",
      "Step 9800\n",
      "learning_rate: 0.00135377\n",
      "Training loss: 0.055009 , Training acc:  0.986891\n",
      "Test loss: 0.302404 , Test acc:  0.899867\n",
      "--------------------------------------------------------------------------------\n",
      "Step 9820\n",
      "learning_rate: 0.00135377\n",
      "Training loss: 0.0479755 , Training acc:  0.990052\n",
      "Test loss: 0.287068 , Test acc:  0.90252\n",
      "--------------------------------------------------------------------------------\n",
      "Step 9840\n",
      "learning_rate: 0.00134024\n",
      "Training loss: 0.0480358 , Training acc:  0.9897\n",
      "Test loss: 0.287332 , Test acc:  0.901857\n",
      "--------------------------------------------------------------------------------\n",
      "Step 9860\n",
      "learning_rate: 0.00134024\n",
      "Training loss: 0.0492374 , Training acc:  0.989115\n",
      "Test loss: 0.291638 , Test acc:  0.901857\n",
      "--------------------------------------------------------------------------------\n",
      "Step 9880\n",
      "learning_rate: 0.00134024\n",
      "Training loss: 0.0495804 , Training acc:  0.989115\n",
      "Test loss: 0.29575 , Test acc:  0.897878\n",
      "--------------------------------------------------------------------------------\n",
      "Step 9900\n",
      "learning_rate: 0.00132683\n",
      "Training loss: 0.0545021 , Training acc:  0.987243\n",
      "Test loss: 0.308976 , Test acc:  0.893899\n",
      "--------------------------------------------------------------------------------\n",
      "Step 9920\n",
      "learning_rate: 0.00132683\n",
      "Training loss: 0.0538913 , Training acc:  0.985604\n",
      "Test loss: 0.306264 , Test acc:  0.896552\n",
      "--------------------------------------------------------------------------------\n",
      "Step 9940\n",
      "learning_rate: 0.00132683\n",
      "Training loss: 0.0544305 , Training acc:  0.986891\n",
      "Test loss: 0.303173 , Test acc:  0.895889\n",
      "--------------------------------------------------------------------------------\n",
      "Step 9960\n",
      "learning_rate: 0.00132683\n",
      "Training loss: 0.0526517 , Training acc:  0.989232\n",
      "Test loss: 0.29568 , Test acc:  0.896552\n",
      "--------------------------------------------------------------------------------\n",
      "Step 9980\n",
      "learning_rate: 0.00131356\n",
      "Training loss: 0.0556389 , Training acc:  0.987008\n",
      "Test loss: 0.303425 , Test acc:  0.904509\n",
      "--------------------------------------------------------------------------------\n",
      "Step 10000\n",
      "learning_rate: 0.00131356\n",
      "Training loss: 0.0519356 , Training acc:  0.989583\n",
      "Test loss: 0.295105 , Test acc:  0.895225\n",
      "--------------------------------------------------------------------------------\n",
      "Step 10020\n",
      "learning_rate: 0.00131356\n",
      "Training loss: 0.0537731 , Training acc:  0.988062\n",
      "Test loss: 0.313925 , Test acc:  0.893236\n",
      "--------------------------------------------------------------------------------\n",
      "Step 10040\n",
      "learning_rate: 0.00131356\n",
      "Training loss: 0.0493946 , Training acc:  0.988647\n",
      "Test loss: 0.307932 , Test acc:  0.896552\n",
      "--------------------------------------------------------------------------------\n",
      "Step 10060\n",
      "learning_rate: 0.00130043\n",
      "Training loss: 0.0483056 , Training acc:  0.988647\n",
      "Test loss: 0.297441 , Test acc:  0.899867\n",
      "--------------------------------------------------------------------------------\n",
      "Step 10080\n",
      "learning_rate: 0.00130043\n",
      "Training loss: 0.0565524 , Training acc:  0.984902\n",
      "Test loss: 0.297673 , Test acc:  0.889257\n",
      "--------------------------------------------------------------------------------\n",
      "Step 10100\n",
      "learning_rate: 0.00130043\n",
      "Training loss: 0.0472963 , Training acc:  0.989817\n",
      "Test loss: 0.289918 , Test acc:  0.90252\n",
      "--------------------------------------------------------------------------------\n",
      "Step 10120\n",
      "learning_rate: 0.00130043\n",
      "Training loss: 0.048623 , Training acc:  0.990286\n",
      "Test loss: 0.292463 , Test acc:  0.894562\n",
      "--------------------------------------------------------------------------------\n",
      "Step 10140\n",
      "learning_rate: 0.00128742\n",
      "Training loss: 0.0580307 , Training acc:  0.984199\n",
      "Test loss: 0.306438 , Test acc:  0.898541\n",
      "--------------------------------------------------------------------------------\n",
      "Step 10160\n",
      "learning_rate: 0.00128742\n",
      "Training loss: 0.0445558 , Training acc:  0.992509\n",
      "Test loss: 0.276629 , Test acc:  0.900531\n",
      "--------------------------------------------------------------------------------\n",
      "Step 10180\n",
      "learning_rate: 0.00128742\n",
      "Training loss: 0.0456263 , Training acc:  0.991456\n",
      "Test loss: 0.288265 , Test acc:  0.899867\n",
      "--------------------------------------------------------------------------------\n",
      "Step 10200\n",
      "learning_rate: 0.00127455\n",
      "Training loss: 0.0442046 , Training acc:  0.992392\n",
      "Test loss: 0.27924 , Test acc:  0.901857\n",
      "--------------------------------------------------------------------------------\n",
      "Step 10220\n",
      "learning_rate: 0.00127455\n",
      "Training loss: 0.0463366 , Training acc:  0.991456\n",
      "Test loss: 0.281944 , Test acc:  0.899867\n",
      "--------------------------------------------------------------------------------\n",
      "Step 10240\n",
      "learning_rate: 0.00127455\n",
      "Training loss: 0.0483312 , Training acc:  0.9897\n",
      "Test loss: 0.298695 , Test acc:  0.891247\n",
      "--------------------------------------------------------------------------------\n",
      "Step 10260\n",
      "learning_rate: 0.00127455\n",
      "Training loss: 0.044239 , Training acc:  0.991456\n",
      "Test loss: 0.295103 , Test acc:  0.897878\n",
      "--------------------------------------------------------------------------------\n",
      "Step 10280\n",
      "learning_rate: 0.0012618\n",
      "Training loss: 0.0480139 , Training acc:  0.990988\n",
      "Test loss: 0.302682 , Test acc:  0.895225\n",
      "--------------------------------------------------------------------------------\n",
      "Step 10300\n",
      "learning_rate: 0.0012618\n",
      "Training loss: 0.0472245 , Training acc:  0.990286\n",
      "Test loss: 0.291115 , Test acc:  0.894562\n",
      "--------------------------------------------------------------------------------\n",
      "Step 10320\n",
      "learning_rate: 0.0012618\n",
      "Training loss: 0.0438723 , Training acc:  0.992626\n",
      "Test loss: 0.281994 , Test acc:  0.899867\n",
      "--------------------------------------------------------------------------------\n",
      "Step 10340\n",
      "learning_rate: 0.0012618\n",
      "Training loss: 0.0446918 , Training acc:  0.991573\n",
      "Test loss: 0.285973 , Test acc:  0.905836\n",
      "--------------------------------------------------------------------------------\n",
      "Step 10360\n",
      "learning_rate: 0.00124919\n",
      "Training loss: 0.0422518 , Training acc:  0.991807\n",
      "Test loss: 0.286001 , Test acc:  0.903183\n",
      "--------------------------------------------------------------------------------\n",
      "Step 10380\n",
      "learning_rate: 0.00124919\n",
      "Training loss: 0.0447874 , Training acc:  0.990286\n",
      "Test loss: 0.29828 , Test acc:  0.900531\n",
      "--------------------------------------------------------------------------------\n",
      "Step 10400\n",
      "learning_rate: 0.00124919\n",
      "Training loss: 0.0440602 , Training acc:  0.990286\n",
      "Test loss: 0.29852 , Test acc:  0.899204\n",
      "--------------------------------------------------------------------------------\n",
      "Step 10420\n",
      "learning_rate: 0.00124919\n",
      "Training loss: 0.04313 , Training acc:  0.990754\n",
      "Test loss: 0.299886 , Test acc:  0.899867\n",
      "--------------------------------------------------------------------------------\n",
      "Step 10440\n",
      "learning_rate: 0.00123669\n",
      "Training loss: 0.0429383 , Training acc:  0.991222\n",
      "Test loss: 0.297106 , Test acc:  0.89191\n",
      "--------------------------------------------------------------------------------\n",
      "Step 10460\n",
      "learning_rate: 0.00123669\n",
      "Training loss: 0.0481561 , Training acc:  0.9897\n",
      "Test loss: 0.303935 , Test acc:  0.887931\n",
      "--------------------------------------------------------------------------------\n",
      "Step 10480\n",
      "learning_rate: 0.00123669\n",
      "Training loss: 0.0495919 , Training acc:  0.988998\n",
      "Test loss: 0.310437 , Test acc:  0.89191\n",
      "--------------------------------------------------------------------------------\n",
      "Step 10500\n",
      "learning_rate: 0.00122433\n",
      "Training loss: 0.0436343 , Training acc:  0.992392\n",
      "Test loss: 0.28742 , Test acc:  0.897878\n",
      "--------------------------------------------------------------------------------\n",
      "Step 10520\n",
      "learning_rate: 0.00122433\n",
      "Training loss: 0.0487091 , Training acc:  0.9897\n",
      "Test loss: 0.304967 , Test acc:  0.892573\n",
      "--------------------------------------------------------------------------------\n",
      "Step 10540\n",
      "learning_rate: 0.00122433\n",
      "Training loss: 0.0497818 , Training acc:  0.990169\n",
      "Test loss: 0.291278 , Test acc:  0.893899\n",
      "--------------------------------------------------------------------------------\n",
      "Step 10560\n",
      "learning_rate: 0.00122433\n",
      "Training loss: 0.0483154 , Training acc:  0.990052\n",
      "Test loss: 0.299474 , Test acc:  0.894562\n",
      "--------------------------------------------------------------------------------\n",
      "Step 10580\n",
      "learning_rate: 0.00121208\n",
      "Training loss: 0.0429629 , Training acc:  0.992743\n",
      "Test loss: 0.297483 , Test acc:  0.901194\n",
      "--------------------------------------------------------------------------------\n",
      "Step 10600\n",
      "learning_rate: 0.00121208\n",
      "Training loss: 0.0439077 , Training acc:  0.99052\n",
      "Test loss: 0.291237 , Test acc:  0.899867\n",
      "--------------------------------------------------------------------------------\n",
      "Step 10620\n",
      "learning_rate: 0.00121208\n",
      "Training loss: 0.0410848 , Training acc:  0.992626\n",
      "Test loss: 0.289787 , Test acc:  0.900531\n",
      "--------------------------------------------------------------------------------\n",
      "Step 10640\n",
      "learning_rate: 0.00121208\n",
      "Training loss: 0.0409844 , Training acc:  0.993329\n",
      "Test loss: 0.289547 , Test acc:  0.903183\n",
      "--------------------------------------------------------------------------------\n",
      "Step 10660\n",
      "learning_rate: 0.00119996\n",
      "Training loss: 0.0447663 , Training acc:  0.991105\n",
      "Test loss: 0.30124 , Test acc:  0.899867\n",
      "--------------------------------------------------------------------------------\n",
      "Step 10680\n",
      "learning_rate: 0.00119996\n",
      "Training loss: 0.0483563 , Training acc:  0.990637\n",
      "Test loss: 0.29843 , Test acc:  0.895225\n",
      "--------------------------------------------------------------------------------\n",
      "Optimization Finished!\n",
      "Training Accuracy: 0.990637\n",
      "Test Accuracy: 0.909808\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "RUN_NAME = 'train_val_test'\n",
    "writer_train = tf.summary.FileWriter('./log/' + RUN_NAME + '/train', graph=sess.graph)\n",
    "writer_test = tf.summary.FileWriter('./log/' + RUN_NAME + '/test', graph=sess.graph)\n",
    "\n",
    "steps = 0\n",
    "# Keep training until reach max iterations\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    indices = np.arange(len(y_train))\n",
    "    np.random.shuffle(indices)\n",
    "    X_train, y_train =  X_train[indices], y_train[indices]\n",
    "\n",
    "    for start, end in feed_next_batch(len(X_train), batch_size=batch_size):\n",
    "        # Run optimization op (backprop)\n",
    "        batch_x, batch_y = X_train[start:end], y_train[start:end]\n",
    "        sess.run(optimizer, feed_dict={x: batch_x, y: batch_y, keep_prob: dropout})\n",
    "        \n",
    "        steps += 1\n",
    "        \n",
    "        if steps % 20 == 0:\n",
    "\n",
    "            # Calculate batch loss and accuracy\n",
    "            train_loss, train_acc, train_lr, summary_train = sess.run([loss, accuracy, learning_rate, summary], \n",
    "                                                   feed_dict={x: X_train, y: y_train, keep_prob: 1.0})\n",
    "            writer_train.add_summary(summary_train, steps)\n",
    "\n",
    "            print('Step %d' % (steps))\n",
    "            print('learning_rate:', train_lr)\n",
    "            print (\"Training loss:\", train_loss, ', Training acc: ', train_acc)\n",
    "\n",
    "            val_loss, val_acc, summary_test = sess.run([loss, accuracy, summary], feed_dict={x: X_val, \n",
    "                                                                        y: y_val,\n",
    "                                                                       keep_prob: 1.0})\n",
    "            writer_test.add_summary(summary_test, steps)\n",
    "            print (\"Test loss:\", val_loss, ', Test acc: ', val_acc)\n",
    "            print('-' * 80)\n",
    "\n",
    "print (\"Optimization Finished!\")\n",
    "\n",
    "# Calculate accuracy for all test samples\n",
    "print (\"Training Accuracy:\", \\\n",
    "    sess.run(accuracy, feed_dict={x: X_train,\n",
    "                                  y: y_train,\n",
    "                                 keep_prob: 1.0}))\n",
    "print (\"Test Accuracy:\", \\\n",
    "    sess.run(accuracy, feed_dict={x: X_test,\n",
    "                                  y: y_test,\n",
    "                                 keep_prob: 1.0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/matplotlib/font_manager.py:1288: UserWarning: findfont: Font family ['serif'] not found. Falling back to Bitstream Vera Sans\n",
      "  (prop.get_family(), self.defaultFamily[fontext]))\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZQAAAEECAYAAAAPo8LjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x13c0e0438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sess.close()\n",
    "\n",
    "arr5 = np.arange(0, 3600)\n",
    "arr5 = 0.0075 * 0.99 ** (arr5/75)\n",
    "plt.plot(arr5, '--'),\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
