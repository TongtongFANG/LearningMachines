{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import librosa\n",
    "from librosa import display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from matplotlib.pyplot import specgram\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "plt.rcParams['font.serif'] = 'Ubuntu'\n",
    "plt.rcParams['font.monospace'] = 'Ubuntu Mono'\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.rcParams['axes.labelsize'] = 11\n",
    "plt.rcParams['axes.labelweight'] = 'bold'\n",
    "plt.rcParams['axes.titlesize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 10\n",
    "plt.rcParams['ytick.labelsize'] = 10\n",
    "plt.rcParams['legend.fontsize'] = 11\n",
    "plt.rcParams['figure.titlesize'] = 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "features = np.loadtxt('nn_simple_features.csv', delimiter=',')\n",
    "labels = np.array(np.loadtxt('nn_simple_labels.csv', delimiter=','), dtype=np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "X_all = features\n",
    "y_all = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10052, 1280)\n",
      "(10052, 5)\n",
      "(1774, 1280)\n",
      "(1774, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_all, y_all, stratify=y_all, train_size=.85, random_state=round(time.time()))\n",
    "\n",
    "# X_train, X_val, y_train, y_val = train_test_split(\n",
    "#     X_not_test, y_not_rest, stratify=y_not_rest, train_size=.9, random_state=round(time.time()))\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "# print(X_val.shape)\n",
    "# print(y_val.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "# learning_rate = 0.005\n",
    "\n",
    "with tf.name_scope(\"learning_rate\"):\n",
    "    global_step = tf.Variable(0, trainable=False)\n",
    "    starter_learning_rate = 0.005\n",
    "    learning_rate = tf.train.exponential_decay(starter_learning_rate, global_step,\n",
    "                                               75, 0.99, staircase=True)\n",
    "    tf.summary.scalar(\"learning_rate\", learning_rate)\n",
    "\n",
    "epochs = 40\n",
    "batch_size = 32\n",
    "\n",
    "# Network Parameters\n",
    "n_input = 40 * 32\n",
    "n_classes = 5\n",
    "dropout = .8 # Dropout, probability to keep units\n",
    "\n",
    "# 1. Define Variables and Placeholders\n",
    "x = tf.placeholder(tf.float32, [None, n_input])\n",
    "y = tf.placeholder(tf.float32, [None, n_classes])\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32) #dropout (keep probability)\n",
    "\n",
    "def build_model(x, dropout, activation):\n",
    "    \n",
    "    x = tf.reshape(x, shape=[-1, 40, 32, 1])\n",
    "    \n",
    "    conv1 = tf.layers.conv2d(x, 4, 5, activation=activation)\n",
    "    conv1 = tf.layers.batch_normalization(conv1)\n",
    "    conv1 = tf.layers.max_pooling2d(conv1, 2, 2)\n",
    "    conv1 = tf.nn.dropout(conv1, dropout)\n",
    "    \n",
    "    conv2 = tf.layers.conv2d(conv1, 8, 3, activation=activation)\n",
    "    conv2 = tf.layers.batch_normalization(conv2)\n",
    "    conv2 = tf.layers.max_pooling2d(conv2, 2, 2)\n",
    "    conv2 = tf.nn.dropout(conv2, dropout)\n",
    "    \n",
    "    fc1 = tf.contrib.layers.flatten(conv2)\n",
    "\n",
    "    fc1 = tf.layers.dense(fc1, 128, activation=activation)\n",
    "    fc1 = tf.layers.batch_normalization(fc1)\n",
    "    fc1 = tf.nn.dropout(fc1, dropout)\n",
    "\n",
    "    fc2 = tf.layers.dense(fc1, 64, activation=activation)\n",
    "    fc2 = tf.layers.batch_normalization(fc2)\n",
    "    fc2 = tf.nn.dropout(fc2, dropout)\n",
    "    \n",
    "    out = tf.layers.dense(fc2, n_classes)\n",
    "\n",
    "    return out\n",
    "\n",
    "predictions = build_model(x, keep_prob, activation=tf.nn.relu)\n",
    "# 3. Define the loss function\n",
    "with tf.name_scope(\"loss\"):\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=predictions, labels=y), name='loss')\n",
    "    tf.summary.scalar(\"loss\", loss)\n",
    "    \n",
    "\n",
    "# 4. Define the accuracy \n",
    "with tf.name_scope(\"accuracy\"):\n",
    "    correct_pred = tf.equal(tf.argmax(predictions, 1), tf.argmax(y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "    tf.summary.scalar(\"accuracy\", accuracy)\n",
    "\n",
    "summary = tf.summary.merge_all()\n",
    "# 5. Define an optimizer\n",
    "# optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss, global_step=global_step)\n",
    "\n",
    "def feed_next_batch(train_size, batch_size=64):\n",
    "    \n",
    "    start = 0\n",
    "    while start < train_size:\n",
    "        yield start, start + batch_size\n",
    "        start += batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steps 20\n",
      "learning_rate: 0.005\n",
      "Training loss: 1.61048 , Training acc:  0.211102\n",
      "Test loss: 1.61289 , Test acc:  0.215896\n",
      "--------------------------------------------------------------------------------\n",
      "steps 40\n",
      "learning_rate: 0.005\n",
      "Training loss: 1.6138 , Training acc:  0.209411\n",
      "Test loss: 1.61385 , Test acc:  0.217024\n",
      "--------------------------------------------------------------------------------\n",
      "steps 60\n",
      "learning_rate: 0.005\n",
      "Training loss: 1.60062 , Training acc:  0.243733\n",
      "Test loss: 1.60041 , Test acc:  0.245772\n",
      "--------------------------------------------------------------------------------\n",
      "steps 80\n",
      "learning_rate: 0.00495\n",
      "Training loss: 1.58599 , Training acc:  0.255571\n",
      "Test loss: 1.58594 , Test acc:  0.25761\n",
      "--------------------------------------------------------------------------------\n",
      "steps 100\n",
      "learning_rate: 0.00495\n",
      "Training loss: 1.53411 , Training acc:  0.317748\n",
      "Test loss: 1.53171 , Test acc:  0.307779\n",
      "--------------------------------------------------------------------------------\n",
      "steps 120\n",
      "learning_rate: 0.00495\n",
      "Training loss: 1.5507 , Training acc:  0.299443\n",
      "Test loss: 1.54756 , Test acc:  0.301015\n",
      "--------------------------------------------------------------------------------\n",
      "steps 140\n",
      "learning_rate: 0.00495\n",
      "Training loss: 1.53722 , Training acc:  0.316952\n",
      "Test loss: 1.53542 , Test acc:  0.314543\n",
      "--------------------------------------------------------------------------------\n",
      "steps 160\n",
      "learning_rate: 0.0049005\n",
      "Training loss: 1.45899 , Training acc:  0.362913\n",
      "Test loss: 1.4631 , Test acc:  0.348365\n",
      "--------------------------------------------------------------------------------\n",
      "steps 180\n",
      "learning_rate: 0.0049005\n",
      "Training loss: 1.39359 , Training acc:  0.384899\n",
      "Test loss: 1.39897 , Test acc:  0.372041\n",
      "--------------------------------------------------------------------------------\n",
      "steps 200\n",
      "learning_rate: 0.0049005\n",
      "Training loss: 1.38386 , Training acc:  0.402308\n",
      "Test loss: 1.38388 , Test acc:  0.397971\n",
      "--------------------------------------------------------------------------------\n",
      "steps 220\n",
      "learning_rate: 0.0049005\n",
      "Training loss: 1.36254 , Training acc:  0.400816\n",
      "Test loss: 1.36693 , Test acc:  0.399662\n",
      "--------------------------------------------------------------------------------\n",
      "steps 240\n",
      "learning_rate: 0.00485149\n",
      "Training loss: 1.30821 , Training acc:  0.445981\n",
      "Test loss: 1.30776 , Test acc:  0.459977\n",
      "--------------------------------------------------------------------------------\n",
      "steps 260\n",
      "learning_rate: 0.00485149\n",
      "Training loss: 1.28771 , Training acc:  0.447772\n",
      "Test loss: 1.29285 , Test acc:  0.43292\n",
      "--------------------------------------------------------------------------------\n",
      "steps 280\n",
      "learning_rate: 0.00485149\n",
      "Training loss: 1.20643 , Training acc:  0.477716\n",
      "Test loss: 1.21495 , Test acc:  0.465614\n",
      "--------------------------------------------------------------------------------\n",
      "steps 300\n",
      "learning_rate: 0.00480298\n",
      "Training loss: 1.1792 , Training acc:  0.476522\n",
      "Test loss: 1.18366 , Test acc:  0.449831\n",
      "--------------------------------------------------------------------------------\n",
      "steps 320\n",
      "learning_rate: 0.00480298\n",
      "Training loss: 1.24539 , Training acc:  0.428969\n",
      "Test loss: 1.25195 , Test acc:  0.410372\n",
      "--------------------------------------------------------------------------------\n",
      "steps 340\n",
      "learning_rate: 0.00480298\n",
      "Training loss: 1.13247 , Training acc:  0.497513\n",
      "Test loss: 1.14795 , Test acc:  0.492108\n",
      "--------------------------------------------------------------------------------\n",
      "steps 360\n",
      "learning_rate: 0.00480298\n",
      "Training loss: 1.06429 , Training acc:  0.544071\n",
      "Test loss: 1.08353 , Test acc:  0.524239\n",
      "--------------------------------------------------------------------------------\n",
      "steps 380\n",
      "learning_rate: 0.00475495\n",
      "Training loss: 1.04677 , Training acc:  0.564962\n",
      "Test loss: 1.06701 , Test acc:  0.541714\n",
      "--------------------------------------------------------------------------------\n",
      "steps 400\n",
      "learning_rate: 0.00475495\n",
      "Training loss: 1.06574 , Training acc:  0.55571\n",
      "Test loss: 1.0811 , Test acc:  0.537768\n",
      "--------------------------------------------------------------------------------\n",
      "steps 420\n",
      "learning_rate: 0.00475495\n",
      "Training loss: 1.03849 , Training acc:  0.566554\n",
      "Test loss: 1.05013 , Test acc:  0.558625\n",
      "--------------------------------------------------------------------------------\n",
      "steps 440\n",
      "learning_rate: 0.00475495\n",
      "Training loss: 0.985107 , Training acc:  0.596399\n",
      "Test loss: 0.99505 , Test acc:  0.578918\n",
      "--------------------------------------------------------------------------------\n",
      "steps 460\n",
      "learning_rate: 0.0047074\n",
      "Training loss: 0.940887 , Training acc:  0.606944\n",
      "Test loss: 0.953379 , Test acc:  0.610485\n",
      "--------------------------------------------------------------------------------\n",
      "steps 480\n",
      "learning_rate: 0.0047074\n",
      "Training loss: 1.07888 , Training acc:  0.535416\n",
      "Test loss: 1.09399 , Test acc:  0.503946\n",
      "--------------------------------------------------------------------------------\n",
      "steps 500\n",
      "learning_rate: 0.0047074\n",
      "Training loss: 0.925415 , Training acc:  0.623955\n",
      "Test loss: 0.938046 , Test acc:  0.617249\n",
      "--------------------------------------------------------------------------------\n",
      "steps 520\n",
      "learning_rate: 0.0047074\n",
      "Training loss: 0.952957 , Training acc:  0.619877\n",
      "Test loss: 0.950281 , Test acc:  0.60372\n",
      "--------------------------------------------------------------------------------\n",
      "steps 540\n",
      "learning_rate: 0.00466033\n",
      "Training loss: 0.927966 , Training acc:  0.620971\n",
      "Test loss: 0.937883 , Test acc:  0.604848\n",
      "--------------------------------------------------------------------------------\n",
      "steps 560\n",
      "learning_rate: 0.00466033\n",
      "Training loss: 0.866698 , Training acc:  0.677577\n",
      "Test loss: 0.888419 , Test acc:  0.655017\n",
      "--------------------------------------------------------------------------------\n",
      "steps 580\n",
      "learning_rate: 0.00466033\n",
      "Training loss: 0.858191 , Training acc:  0.666335\n",
      "Test loss: 0.883153 , Test acc:  0.663472\n",
      "--------------------------------------------------------------------------------\n",
      "steps 600\n",
      "learning_rate: 0.00461372\n",
      "Training loss: 0.889915 , Training acc:  0.647334\n",
      "Test loss: 0.905887 , Test acc:  0.631342\n",
      "--------------------------------------------------------------------------------\n",
      "steps 620\n",
      "learning_rate: 0.00461372\n",
      "Training loss: 0.859127 , Training acc:  0.654895\n",
      "Test loss: 0.862553 , Test acc:  0.645434\n",
      "--------------------------------------------------------------------------------\n",
      "steps 640\n",
      "learning_rate: 0.00461372\n",
      "Training loss: 0.895326 , Training acc:  0.646737\n",
      "Test loss: 0.900859 , Test acc:  0.63867\n",
      "--------------------------------------------------------------------------------\n",
      "steps 660\n",
      "learning_rate: 0.00461372\n",
      "Training loss: 0.859294 , Training acc:  0.651811\n",
      "Test loss: 0.875073 , Test acc:  0.646561\n",
      "--------------------------------------------------------------------------------\n",
      "steps 680\n",
      "learning_rate: 0.00456759\n",
      "Training loss: 0.853497 , Training acc:  0.657083\n",
      "Test loss: 0.873278 , Test acc:  0.639233\n",
      "--------------------------------------------------------------------------------\n",
      "steps 700\n",
      "learning_rate: 0.00456759\n",
      "Training loss: 0.794703 , Training acc:  0.68842\n",
      "Test loss: 0.812719 , Test acc:  0.687711\n",
      "--------------------------------------------------------------------------------\n",
      "steps 720\n",
      "learning_rate: 0.00456759\n",
      "Training loss: 0.820283 , Training acc:  0.680661\n",
      "Test loss: 0.843772 , Test acc:  0.662345\n",
      "--------------------------------------------------------------------------------\n",
      "steps 740\n",
      "learning_rate: 0.00456759\n",
      "Training loss: 0.79783 , Training acc:  0.701253\n",
      "Test loss: 0.813348 , Test acc:  0.68602\n",
      "--------------------------------------------------------------------------------\n",
      "steps 760\n",
      "learning_rate: 0.00452191\n",
      "Training loss: 0.738155 , Training acc:  0.713888\n",
      "Test loss: 0.765899 , Test acc:  0.697858\n",
      "--------------------------------------------------------------------------------\n",
      "steps 780\n",
      "learning_rate: 0.00452191\n",
      "Training loss: 0.77019 , Training acc:  0.705034\n",
      "Test loss: 0.799173 , Test acc:  0.687711\n",
      "--------------------------------------------------------------------------------\n",
      "steps 800\n",
      "learning_rate: 0.00452191\n",
      "Training loss: 0.786363 , Training acc:  0.70006\n",
      "Test loss: 0.80104 , Test acc:  0.685457\n",
      "--------------------------------------------------------------------------------\n",
      "steps 820\n",
      "learning_rate: 0.00452191\n",
      "Training loss: 0.77791 , Training acc:  0.716673\n",
      "Test loss: 0.802348 , Test acc:  0.698422\n",
      "--------------------------------------------------------------------------------\n",
      "steps 840\n",
      "learning_rate: 0.00447669\n",
      "Training loss: 0.711643 , Training acc:  0.737266\n",
      "Test loss: 0.741751 , Test acc:  0.714769\n",
      "--------------------------------------------------------------------------------\n",
      "steps 860\n",
      "learning_rate: 0.00447669\n",
      "Training loss: 0.736208 , Training acc:  0.729308\n",
      "Test loss: 0.753843 , Test acc:  0.719842\n",
      "--------------------------------------------------------------------------------\n",
      "steps 880\n",
      "learning_rate: 0.00447669\n",
      "Training loss: 0.686592 , Training acc:  0.738758\n",
      "Test loss: 0.700053 , Test acc:  0.732807\n",
      "--------------------------------------------------------------------------------\n",
      "steps 900\n",
      "learning_rate: 0.00443192\n",
      "Training loss: 0.723849 , Training acc:  0.710107\n",
      "Test loss: 0.751236 , Test acc:  0.708005\n",
      "--------------------------------------------------------------------------------\n",
      "steps 920\n",
      "learning_rate: 0.00443192\n",
      "Training loss: 0.683261 , Training acc:  0.756765\n",
      "Test loss: 0.69538 , Test acc:  0.748591\n",
      "--------------------------------------------------------------------------------\n",
      "steps 940\n",
      "learning_rate: 0.00443192\n",
      "Training loss: 0.705966 , Training acc:  0.736669\n",
      "Test loss: 0.726769 , Test acc:  0.736189\n",
      "--------------------------------------------------------------------------------\n",
      "steps 960\n",
      "learning_rate: 0.00443192\n",
      "Training loss: 0.694184 , Training acc:  0.737266\n",
      "Test loss: 0.719073 , Test acc:  0.712514\n",
      "--------------------------------------------------------------------------------\n",
      "steps 980\n",
      "learning_rate: 0.00438761\n",
      "Training loss: 0.686389 , Training acc:  0.737963\n",
      "Test loss: 0.70981 , Test acc:  0.723788\n",
      "--------------------------------------------------------------------------------\n",
      "steps 1000\n",
      "learning_rate: 0.00438761\n",
      "Training loss: 0.624668 , Training acc:  0.773975\n",
      "Test loss: 0.653305 , Test acc:  0.762683\n",
      "--------------------------------------------------------------------------------\n",
      "steps 1020\n",
      "learning_rate: 0.00438761\n",
      "Training loss: 0.716118 , Training acc:  0.710306\n",
      "Test loss: 0.767934 , Test acc:  0.705186\n",
      "--------------------------------------------------------------------------------\n",
      "steps 1040\n",
      "learning_rate: 0.00438761\n",
      "Training loss: 0.658203 , Training acc:  0.756765\n",
      "Test loss: 0.697355 , Test acc:  0.733371\n",
      "--------------------------------------------------------------------------------\n",
      "steps 1060\n",
      "learning_rate: 0.00434373\n",
      "Training loss: 0.64822 , Training acc:  0.77109\n",
      "Test loss: 0.677277 , Test acc:  0.756483\n",
      "--------------------------------------------------------------------------------\n",
      "steps 1080\n",
      "learning_rate: 0.00434373\n",
      "Training loss: 0.682272 , Training acc:  0.738659\n",
      "Test loss: 0.739358 , Test acc:  0.704059\n",
      "--------------------------------------------------------------------------------\n",
      "steps 1100\n",
      "learning_rate: 0.00434373\n",
      "Training loss: 0.626901 , Training acc:  0.770891\n",
      "Test loss: 0.659699 , Test acc:  0.749718\n",
      "--------------------------------------------------------------------------------\n",
      "steps 1120\n",
      "learning_rate: 0.00434373\n",
      "Training loss: 0.638148 , Training acc:  0.775766\n",
      "Test loss: 0.674613 , Test acc:  0.758174\n",
      "--------------------------------------------------------------------------------\n",
      "steps 1140\n",
      "learning_rate: 0.00430029\n",
      "Training loss: 0.66435 , Training acc:  0.762137\n",
      "Test loss: 0.704557 , Test acc:  0.735062\n",
      "--------------------------------------------------------------------------------\n",
      "steps 1160\n",
      "learning_rate: 0.00430029\n",
      "Training loss: 0.592557 , Training acc:  0.79616\n",
      "Test loss: 0.649065 , Test acc:  0.766065\n",
      "--------------------------------------------------------------------------------\n",
      "steps 1180\n",
      "learning_rate: 0.00430029\n",
      "Training loss: 0.641943 , Training acc:  0.758158\n",
      "Test loss: 0.696117 , Test acc:  0.729425\n",
      "--------------------------------------------------------------------------------\n",
      "steps 1200\n",
      "learning_rate: 0.00425729\n",
      "Training loss: 0.606988 , Training acc:  0.78273\n",
      "Test loss: 0.659303 , Test acc:  0.750846\n",
      "--------------------------------------------------------------------------------\n",
      "steps 1220\n",
      "learning_rate: 0.00425729\n",
      "Training loss: 0.580048 , Training acc:  0.796061\n",
      "Test loss: 0.617883 , Test acc:  0.782976\n",
      "--------------------------------------------------------------------------------\n",
      "steps 1240\n",
      "learning_rate: 0.00425729\n",
      "Training loss: 0.594631 , Training acc:  0.776761\n",
      "Test loss: 0.647552 , Test acc:  0.743517\n",
      "--------------------------------------------------------------------------------\n",
      "steps 1260\n",
      "learning_rate: 0.00425729\n",
      "Training loss: 0.63454 , Training acc:  0.764922\n",
      "Test loss: 0.680481 , Test acc:  0.737317\n",
      "--------------------------------------------------------------------------------\n",
      "steps 1280\n",
      "learning_rate: 0.00421472\n",
      "Training loss: 0.632221 , Training acc:  0.770593\n",
      "Test loss: 0.665982 , Test acc:  0.753664\n",
      "--------------------------------------------------------------------------------\n",
      "steps 1300\n",
      "learning_rate: 0.00421472\n",
      "Training loss: 0.611384 , Training acc:  0.777656\n",
      "Test loss: 0.657625 , Test acc:  0.750846\n",
      "--------------------------------------------------------------------------------\n",
      "steps 1320\n",
      "learning_rate: 0.00421472\n",
      "Training loss: 0.557487 , Training acc:  0.795762\n",
      "Test loss: 0.616608 , Test acc:  0.765502\n",
      "--------------------------------------------------------------------------------\n",
      "steps 1340\n",
      "learning_rate: 0.00421472\n",
      "Training loss: 0.54074 , Training acc:  0.810386\n",
      "Test loss: 0.57577 , Test acc:  0.796505\n",
      "--------------------------------------------------------------------------------\n",
      "steps 1360\n",
      "learning_rate: 0.00417257\n",
      "Training loss: 0.552042 , Training acc:  0.813271\n",
      "Test loss: 0.601301 , Test acc:  0.79876\n",
      "--------------------------------------------------------------------------------\n",
      "steps 1380\n",
      "learning_rate: 0.00417257\n",
      "Training loss: 0.530641 , Training acc:  0.816355\n",
      "Test loss: 0.573246 , Test acc:  0.793687\n",
      "--------------------------------------------------------------------------------\n",
      "steps 1400\n",
      "learning_rate: 0.00417257\n",
      "Training loss: 0.508851 , Training acc:  0.816852\n",
      "Test loss: 0.554915 , Test acc:  0.803833\n",
      "--------------------------------------------------------------------------------\n",
      "steps 1420\n",
      "learning_rate: 0.00417257\n",
      "Training loss: 0.534709 , Training acc:  0.809192\n",
      "Test loss: 0.596118 , Test acc:  0.778467\n",
      "--------------------------------------------------------------------------------\n",
      "steps 1440\n",
      "learning_rate: 0.00413084\n",
      "Training loss: 0.525067 , Training acc:  0.815261\n",
      "Test loss: 0.585331 , Test acc:  0.790868\n",
      "--------------------------------------------------------------------------------\n",
      "steps 1460\n",
      "learning_rate: 0.00413084\n",
      "Training loss: 0.530172 , Training acc:  0.811878\n",
      "Test loss: 0.57626 , Test acc:  0.791432\n",
      "--------------------------------------------------------------------------------\n",
      "steps 1480\n",
      "learning_rate: 0.00413084\n",
      "Training loss: 0.569814 , Training acc:  0.808595\n",
      "Test loss: 0.608025 , Test acc:  0.790868\n",
      "--------------------------------------------------------------------------------\n",
      "steps 1500\n",
      "learning_rate: 0.00408954\n",
      "Training loss: 0.478281 , Training acc:  0.841325\n",
      "Test loss: 0.524585 , Test acc:  0.81398\n",
      "--------------------------------------------------------------------------------\n",
      "steps 1520\n",
      "learning_rate: 0.00408954\n",
      "Training loss: 0.489061 , Training acc:  0.832372\n",
      "Test loss: 0.540491 , Test acc:  0.801578\n",
      "--------------------------------------------------------------------------------\n",
      "steps 1540\n",
      "learning_rate: 0.00408954\n",
      "Training loss: 0.49404 , Training acc:  0.820533\n",
      "Test loss: 0.559363 , Test acc:  0.790304\n",
      "--------------------------------------------------------------------------------\n",
      "steps 1560\n",
      "learning_rate: 0.00408954\n",
      "Training loss: 0.452594 , Training acc:  0.847095\n",
      "Test loss: 0.522202 , Test acc:  0.815107\n",
      "--------------------------------------------------------------------------------\n",
      "steps 1580\n",
      "learning_rate: 0.00404864\n",
      "Training loss: 0.472689 , Training acc:  0.835058\n",
      "Test loss: 0.529744 , Test acc:  0.808906\n",
      "--------------------------------------------------------------------------------\n",
      "steps 1600\n",
      "learning_rate: 0.00404864\n",
      "Training loss: 0.451852 , Training acc:  0.842121\n",
      "Test loss: 0.513918 , Test acc:  0.81398\n",
      "--------------------------------------------------------------------------------\n",
      "steps 1620\n",
      "learning_rate: 0.00404864\n",
      "Training loss: 0.52277 , Training acc:  0.812475\n",
      "Test loss: 0.59956 , Test acc:  0.780158\n",
      "--------------------------------------------------------------------------------\n",
      "steps 1640\n",
      "learning_rate: 0.00404864\n",
      "Training loss: 0.439553 , Training acc:  0.855153\n",
      "Test loss: 0.502725 , Test acc:  0.821871\n",
      "--------------------------------------------------------------------------------\n",
      "steps 1660\n",
      "learning_rate: 0.00400815\n",
      "Training loss: 0.426153 , Training acc:  0.860127\n",
      "Test loss: 0.473641 , Test acc:  0.842165\n",
      "--------------------------------------------------------------------------------\n",
      "steps 1680\n",
      "learning_rate: 0.00400815\n",
      "Training loss: 0.465855 , Training acc:  0.841922\n",
      "Test loss: 0.539029 , Test acc:  0.805524\n",
      "--------------------------------------------------------------------------------\n",
      "steps 1700\n",
      "learning_rate: 0.00400815\n",
      "Training loss: 0.472891 , Training acc:  0.833168\n",
      "Test loss: 0.553258 , Test acc:  0.807215\n",
      "--------------------------------------------------------------------------------\n",
      "steps 1720\n",
      "learning_rate: 0.00400815\n",
      "Training loss: 0.450346 , Training acc:  0.839932\n",
      "Test loss: 0.497199 , Test acc:  0.822435\n",
      "--------------------------------------------------------------------------------\n",
      "steps 1740\n",
      "learning_rate: 0.00396807\n",
      "Training loss: 0.416465 , Training acc:  0.862515\n",
      "Test loss: 0.478002 , Test acc:  0.838219\n",
      "--------------------------------------------------------------------------------\n",
      "steps 1760\n",
      "learning_rate: 0.00396807\n",
      "Training loss: 0.487501 , Training acc:  0.81924\n",
      "Test loss: 0.557562 , Test acc:  0.791995\n",
      "--------------------------------------------------------------------------------\n",
      "steps 1780\n",
      "learning_rate: 0.00396807\n",
      "Training loss: 0.39182 , Training acc:  0.872463\n",
      "Test loss: 0.450714 , Test acc:  0.848365\n",
      "--------------------------------------------------------------------------------\n",
      "steps 1800\n",
      "learning_rate: 0.00392839\n",
      "Training loss: 0.398155 , Training acc:  0.861918\n",
      "Test loss: 0.453593 , Test acc:  0.844419\n",
      "--------------------------------------------------------------------------------\n",
      "steps 1820\n",
      "learning_rate: 0.00392839\n",
      "Training loss: 0.399229 , Training acc:  0.866793\n",
      "Test loss: 0.454555 , Test acc:  0.838219\n",
      "--------------------------------------------------------------------------------\n",
      "steps 1840\n",
      "learning_rate: 0.00392839\n",
      "Training loss: 0.426692 , Training acc:  0.849184\n",
      "Test loss: 0.476063 , Test acc:  0.832018\n",
      "--------------------------------------------------------------------------------\n",
      "steps 1860\n",
      "learning_rate: 0.00392839\n",
      "Training loss: 0.361584 , Training acc:  0.882113\n",
      "Test loss: 0.426689 , Test acc:  0.85513\n",
      "--------------------------------------------------------------------------------\n",
      "steps 1880\n",
      "learning_rate: 0.00388911\n",
      "Training loss: 0.412136 , Training acc:  0.864505\n",
      "Test loss: 0.474108 , Test acc:  0.830327\n",
      "--------------------------------------------------------------------------------\n",
      "steps 1900\n",
      "learning_rate: 0.00388911\n",
      "Training loss: 0.396454 , Training acc:  0.868782\n",
      "Test loss: 0.452718 , Test acc:  0.848929\n",
      "--------------------------------------------------------------------------------\n",
      "steps 1920\n",
      "learning_rate: 0.00388911\n",
      "Training loss: 0.398779 , Training acc:  0.86739\n",
      "Test loss: 0.461421 , Test acc:  0.833709\n",
      "--------------------------------------------------------------------------------\n",
      "steps 1940\n",
      "learning_rate: 0.00388911\n",
      "Training loss: 0.383144 , Training acc:  0.871866\n",
      "Test loss: 0.449243 , Test acc:  0.843856\n",
      "--------------------------------------------------------------------------------\n",
      "steps 1960\n",
      "learning_rate: 0.00385022\n",
      "Training loss: 0.373882 , Training acc:  0.871269\n",
      "Test loss: 0.425628 , Test acc:  0.852875\n",
      "--------------------------------------------------------------------------------\n",
      "steps 1980\n",
      "learning_rate: 0.00385022\n",
      "Training loss: 0.401668 , Training acc:  0.85764\n",
      "Test loss: 0.485781 , Test acc:  0.825254\n",
      "--------------------------------------------------------------------------------\n",
      "steps 2000\n",
      "learning_rate: 0.00385022\n",
      "Training loss: 0.389998 , Training acc:  0.865698\n",
      "Test loss: 0.462133 , Test acc:  0.83991\n",
      "--------------------------------------------------------------------------------\n",
      "steps 2020\n",
      "learning_rate: 0.00385022\n",
      "Training loss: 0.368379 , Training acc:  0.876343\n",
      "Test loss: 0.445906 , Test acc:  0.846674\n",
      "--------------------------------------------------------------------------------\n",
      "steps 2040\n",
      "learning_rate: 0.00381171\n",
      "Training loss: 0.421902 , Training acc:  0.857541\n",
      "Test loss: 0.500454 , Test acc:  0.819617\n",
      "--------------------------------------------------------------------------------\n",
      "steps 2060\n",
      "learning_rate: 0.00381171\n",
      "Training loss: 0.39839 , Training acc:  0.859829\n",
      "Test loss: 0.468948 , Test acc:  0.827508\n",
      "--------------------------------------------------------------------------------\n",
      "steps 2080\n",
      "learning_rate: 0.00381171\n",
      "Training loss: 0.356422 , Training acc:  0.880024\n",
      "Test loss: 0.426007 , Test acc:  0.852875\n",
      "--------------------------------------------------------------------------------\n",
      "steps 2100\n",
      "learning_rate: 0.0037736\n",
      "Training loss: 0.357492 , Training acc:  0.878233\n",
      "Test loss: 0.423748 , Test acc:  0.852311\n",
      "--------------------------------------------------------------------------------\n",
      "steps 2120\n",
      "learning_rate: 0.0037736\n",
      "Training loss: 0.361391 , Training acc:  0.881118\n",
      "Test loss: 0.41978 , Test acc:  0.866967\n",
      "--------------------------------------------------------------------------------\n",
      "steps 2140\n",
      "learning_rate: 0.0037736\n",
      "Training loss: 0.419805 , Training acc:  0.847692\n",
      "Test loss: 0.484304 , Test acc:  0.823563\n",
      "--------------------------------------------------------------------------------\n",
      "steps 2160\n",
      "learning_rate: 0.0037736\n",
      "Training loss: 0.385387 , Training acc:  0.874154\n",
      "Test loss: 0.438809 , Test acc:  0.845547\n",
      "--------------------------------------------------------------------------------\n",
      "steps 2180\n",
      "learning_rate: 0.00373586\n",
      "Training loss: 0.388946 , Training acc:  0.875348\n",
      "Test loss: 0.444799 , Test acc:  0.844983\n",
      "--------------------------------------------------------------------------------\n",
      "steps 2200\n",
      "learning_rate: 0.00373586\n",
      "Training loss: 0.349626 , Training acc:  0.892061\n",
      "Test loss: 0.414683 , Test acc:  0.859076\n",
      "--------------------------------------------------------------------------------\n",
      "steps 2220\n",
      "learning_rate: 0.00373586\n",
      "Training loss: 0.378915 , Training acc:  0.868683\n",
      "Test loss: 0.444852 , Test acc:  0.838782\n",
      "--------------------------------------------------------------------------------\n",
      "steps 2240\n",
      "learning_rate: 0.00373586\n",
      "Training loss: 0.347066 , Training acc:  0.883605\n",
      "Test loss: 0.411633 , Test acc:  0.858512\n",
      "--------------------------------------------------------------------------------\n",
      "steps 2260\n",
      "learning_rate: 0.0036985\n",
      "Training loss: 0.348699 , Training acc:  0.889873\n",
      "Test loss: 0.424442 , Test acc:  0.86133\n",
      "--------------------------------------------------------------------------------\n",
      "steps 2280\n",
      "learning_rate: 0.0036985\n",
      "Training loss: 0.362839 , Training acc:  0.871568\n",
      "Test loss: 0.440631 , Test acc:  0.833709\n",
      "--------------------------------------------------------------------------------\n",
      "steps 2300\n",
      "learning_rate: 0.0036985\n",
      "Training loss: 0.365847 , Training acc:  0.875945\n",
      "Test loss: 0.447262 , Test acc:  0.838219\n",
      "--------------------------------------------------------------------------------\n",
      "steps 2320\n",
      "learning_rate: 0.0036985\n",
      "Training loss: 0.368241 , Training acc:  0.87694\n",
      "Test loss: 0.448621 , Test acc:  0.843292\n",
      "--------------------------------------------------------------------------------\n",
      "steps 2340\n",
      "learning_rate: 0.00366152\n",
      "Training loss: 0.341745 , Training acc:  0.887187\n",
      "Test loss: 0.41634 , Test acc:  0.859076\n",
      "--------------------------------------------------------------------------------\n",
      "steps 2360\n",
      "learning_rate: 0.00366152\n",
      "Training loss: 0.316751 , Training acc:  0.895941\n",
      "Test loss: 0.387773 , Test acc:  0.865276\n",
      "--------------------------------------------------------------------------------\n",
      "steps 2380\n",
      "learning_rate: 0.00366152\n",
      "Training loss: 0.334683 , Training acc:  0.88659\n",
      "Test loss: 0.4119 , Test acc:  0.860203\n",
      "--------------------------------------------------------------------------------\n",
      "steps 2400\n",
      "learning_rate: 0.0036249\n",
      "Training loss: 0.351336 , Training acc:  0.887585\n",
      "Test loss: 0.422374 , Test acc:  0.851184\n",
      "--------------------------------------------------------------------------------\n",
      "steps 2420\n",
      "learning_rate: 0.0036249\n",
      "Training loss: 0.360948 , Training acc:  0.871866\n",
      "Test loss: 0.434157 , Test acc:  0.832582\n",
      "--------------------------------------------------------------------------------\n",
      "steps 2440\n",
      "learning_rate: 0.0036249\n",
      "Training loss: 0.338533 , Training acc:  0.896339\n",
      "Test loss: 0.413056 , Test acc:  0.853439\n",
      "--------------------------------------------------------------------------------\n",
      "steps 2460\n",
      "learning_rate: 0.0036249\n",
      "Training loss: 0.382273 , Training acc:  0.872563\n",
      "Test loss: 0.451028 , Test acc:  0.844983\n",
      "--------------------------------------------------------------------------------\n",
      "steps 2480\n",
      "learning_rate: 0.00358865\n",
      "Training loss: 0.327172 , Training acc:  0.889077\n",
      "Test loss: 0.393994 , Test acc:  0.85513\n",
      "--------------------------------------------------------------------------------\n",
      "steps 2500\n",
      "learning_rate: 0.00358865\n",
      "Training loss: 0.306575 , Training acc:  0.898329\n",
      "Test loss: 0.39449 , Test acc:  0.869222\n",
      "--------------------------------------------------------------------------------\n",
      "steps 2520\n",
      "learning_rate: 0.00358865\n",
      "Training loss: 0.353957 , Training acc:  0.880123\n",
      "Test loss: 0.444504 , Test acc:  0.845547\n",
      "--------------------------------------------------------------------------------\n",
      "steps 2540\n",
      "learning_rate: 0.00358865\n",
      "Training loss: 0.325677 , Training acc:  0.894946\n",
      "Test loss: 0.407045 , Test acc:  0.858512\n",
      "--------------------------------------------------------------------------------\n",
      "steps 2560\n",
      "learning_rate: 0.00355277\n",
      "Training loss: 0.301217 , Training acc:  0.900617\n",
      "Test loss: 0.378438 , Test acc:  0.863585\n",
      "--------------------------------------------------------------------------------\n",
      "steps 2580\n",
      "learning_rate: 0.00355277\n",
      "Training loss: 0.338392 , Training acc:  0.879129\n",
      "Test loss: 0.417544 , Test acc:  0.852875\n",
      "--------------------------------------------------------------------------------\n",
      "steps 2600\n",
      "learning_rate: 0.00355277\n",
      "Training loss: 0.28773 , Training acc:  0.9039\n",
      "Test loss: 0.374772 , Test acc:  0.862458\n",
      "--------------------------------------------------------------------------------\n",
      "steps 2620\n",
      "learning_rate: 0.00355277\n",
      "Training loss: 0.374675 , Training acc:  0.863808\n",
      "Test loss: 0.468571 , Test acc:  0.828636\n",
      "--------------------------------------------------------------------------------\n",
      "steps 2640\n",
      "learning_rate: 0.00351724\n",
      "Training loss: 0.317951 , Training acc:  0.890271\n",
      "Test loss: 0.387134 , Test acc:  0.868658\n",
      "--------------------------------------------------------------------------------\n",
      "steps 2660\n",
      "learning_rate: 0.00351724\n",
      "Training loss: 0.322841 , Training acc:  0.895543\n",
      "Test loss: 0.388392 , Test acc:  0.870913\n",
      "--------------------------------------------------------------------------------\n",
      "steps 2680\n",
      "learning_rate: 0.00351724\n",
      "Training loss: 0.315099 , Training acc:  0.896339\n",
      "Test loss: 0.368608 , Test acc:  0.877114\n",
      "--------------------------------------------------------------------------------\n",
      "steps 2700\n",
      "learning_rate: 0.00348207\n",
      "Training loss: 0.306324 , Training acc:  0.898428\n",
      "Test loss: 0.369477 , Test acc:  0.870913\n",
      "--------------------------------------------------------------------------------\n",
      "steps 2720\n",
      "learning_rate: 0.00348207\n",
      "Training loss: 0.298818 , Training acc:  0.902706\n",
      "Test loss: 0.377808 , Test acc:  0.870349\n",
      "--------------------------------------------------------------------------------\n",
      "steps 2740\n",
      "learning_rate: 0.00348207\n",
      "Training loss: 0.313284 , Training acc:  0.892857\n",
      "Test loss: 0.394397 , Test acc:  0.857948\n",
      "--------------------------------------------------------------------------------\n",
      "steps 2760\n",
      "learning_rate: 0.00348207\n",
      "Training loss: 0.280838 , Training acc:  0.911958\n",
      "Test loss: 0.362877 , Test acc:  0.877114\n",
      "--------------------------------------------------------------------------------\n",
      "steps 2780\n",
      "learning_rate: 0.00344725\n",
      "Training loss: 0.291501 , Training acc:  0.901512\n",
      "Test loss: 0.384962 , Test acc:  0.866404\n",
      "--------------------------------------------------------------------------------\n",
      "steps 2800\n",
      "learning_rate: 0.00344725\n",
      "Training loss: 0.316016 , Training acc:  0.895842\n",
      "Test loss: 0.391431 , Test acc:  0.859076\n",
      "--------------------------------------------------------------------------------\n",
      "steps 2820\n",
      "learning_rate: 0.00344725\n",
      "Training loss: 0.289425 , Training acc:  0.908675\n",
      "Test loss: 0.35768 , Test acc:  0.88106\n",
      "--------------------------------------------------------------------------------\n",
      "steps 2840\n",
      "learning_rate: 0.00344725\n",
      "Training loss: 0.274611 , Training acc:  0.910963\n",
      "Test loss: 0.349989 , Test acc:  0.879932\n",
      "--------------------------------------------------------------------------------\n",
      "steps 2860\n",
      "learning_rate: 0.00341277\n",
      "Training loss: 0.278438 , Training acc:  0.91146\n",
      "Test loss: 0.364786 , Test acc:  0.879369\n",
      "--------------------------------------------------------------------------------\n",
      "steps 2880\n",
      "learning_rate: 0.00341277\n",
      "Training loss: 0.284557 , Training acc:  0.907879\n",
      "Test loss: 0.358769 , Test acc:  0.88106\n",
      "--------------------------------------------------------------------------------\n",
      "steps 2900\n",
      "learning_rate: 0.00341277\n",
      "Training loss: 0.262417 , Training acc:  0.909769\n",
      "Test loss: 0.34829 , Test acc:  0.872604\n",
      "--------------------------------------------------------------------------------\n",
      "steps 2920\n",
      "learning_rate: 0.00341277\n",
      "Training loss: 0.304667 , Training acc:  0.899125\n",
      "Test loss: 0.387266 , Test acc:  0.873732\n",
      "--------------------------------------------------------------------------------\n",
      "steps 2940\n",
      "learning_rate: 0.00337865\n",
      "Training loss: 0.28011 , Training acc:  0.912256\n",
      "Test loss: 0.355303 , Test acc:  0.882187\n",
      "--------------------------------------------------------------------------------\n",
      "steps 2960\n",
      "learning_rate: 0.00337865\n",
      "Training loss: 0.265651 , Training acc:  0.916932\n",
      "Test loss: 0.343975 , Test acc:  0.883315\n",
      "--------------------------------------------------------------------------------\n",
      "steps 2980\n",
      "learning_rate: 0.00337865\n",
      "Training loss: 0.320658 , Training acc:  0.894946\n",
      "Test loss: 0.408596 , Test acc:  0.864149\n",
      "--------------------------------------------------------------------------------\n",
      "steps 3000\n",
      "learning_rate: 0.00334486\n",
      "Training loss: 0.263815 , Training acc:  0.917827\n",
      "Test loss: 0.344596 , Test acc:  0.879932\n",
      "--------------------------------------------------------------------------------\n",
      "steps 3020\n",
      "learning_rate: 0.00334486\n",
      "Training loss: 0.283155 , Training acc:  0.908973\n",
      "Test loss: 0.36764 , Test acc:  0.870349\n",
      "--------------------------------------------------------------------------------\n",
      "steps 3040\n",
      "learning_rate: 0.00334486\n",
      "Training loss: 0.255107 , Training acc:  0.920513\n",
      "Test loss: 0.342815 , Test acc:  0.879932\n",
      "--------------------------------------------------------------------------------\n",
      "steps 3060\n",
      "learning_rate: 0.00334486\n",
      "Training loss: 0.26455 , Training acc:  0.917728\n",
      "Test loss: 0.343181 , Test acc:  0.885569\n",
      "--------------------------------------------------------------------------------\n",
      "steps 3080\n",
      "learning_rate: 0.00331141\n",
      "Training loss: 0.283875 , Training acc:  0.906785\n",
      "Test loss: 0.375566 , Test acc:  0.868095\n",
      "--------------------------------------------------------------------------------\n",
      "steps 3100\n",
      "learning_rate: 0.00331141\n",
      "Training loss: 0.238698 , Training acc:  0.921508\n",
      "Test loss: 0.328488 , Test acc:  0.880496\n",
      "--------------------------------------------------------------------------------\n",
      "steps 3120\n",
      "learning_rate: 0.00331141\n",
      "Training loss: 0.243966 , Training acc:  0.920613\n",
      "Test loss: 0.332699 , Test acc:  0.882187\n",
      "--------------------------------------------------------------------------------\n",
      "steps 3140\n",
      "learning_rate: 0.00331141\n",
      "Training loss: 0.324872 , Training acc:  0.891763\n",
      "Test loss: 0.434253 , Test acc:  0.847238\n",
      "--------------------------------------------------------------------------------\n",
      "steps 3160\n",
      "learning_rate: 0.0032783\n",
      "Training loss: 0.335394 , Training acc:  0.890171\n",
      "Test loss: 0.423539 , Test acc:  0.848365\n",
      "--------------------------------------------------------------------------------\n",
      "steps 3180\n",
      "learning_rate: 0.0032783\n",
      "Training loss: 0.292004 , Training acc:  0.903999\n",
      "Test loss: 0.381441 , Test acc:  0.868095\n",
      "--------------------------------------------------------------------------------\n",
      "steps 3200\n",
      "learning_rate: 0.0032783\n",
      "Training loss: 0.26815 , Training acc:  0.908177\n",
      "Test loss: 0.345335 , Test acc:  0.879369\n",
      "--------------------------------------------------------------------------------\n",
      "steps 3220\n",
      "learning_rate: 0.0032783\n",
      "Training loss: 0.279434 , Training acc:  0.910167\n",
      "Test loss: 0.35591 , Test acc:  0.88726\n",
      "--------------------------------------------------------------------------------\n",
      "steps 3240\n",
      "learning_rate: 0.00324551\n",
      "Training loss: 0.256294 , Training acc:  0.918325\n",
      "Test loss: 0.340048 , Test acc:  0.890079\n",
      "--------------------------------------------------------------------------------\n",
      "steps 3260\n",
      "learning_rate: 0.00324551\n",
      "Training loss: 0.246475 , Training acc:  0.924891\n",
      "Test loss: 0.333179 , Test acc:  0.88726\n",
      "--------------------------------------------------------------------------------\n",
      "steps 3280\n",
      "learning_rate: 0.00324551\n",
      "Training loss: 0.2421 , Training acc:  0.921309\n",
      "Test loss: 0.322492 , Test acc:  0.886697\n",
      "--------------------------------------------------------------------------------\n",
      "steps 3300\n",
      "learning_rate: 0.00321306\n",
      "Training loss: 0.261384 , Training acc:  0.91146\n",
      "Test loss: 0.343249 , Test acc:  0.88106\n",
      "--------------------------------------------------------------------------------\n",
      "steps 3320\n",
      "learning_rate: 0.00321306\n",
      "Training loss: 0.238776 , Training acc:  0.925288\n",
      "Test loss: 0.330335 , Test acc:  0.887824\n",
      "--------------------------------------------------------------------------------\n",
      "steps 3340\n",
      "learning_rate: 0.00321306\n",
      "Training loss: 0.246725 , Training acc:  0.924692\n",
      "Test loss: 0.334844 , Test acc:  0.887824\n",
      "--------------------------------------------------------------------------------\n",
      "steps 3360\n",
      "learning_rate: 0.00321306\n",
      "Training loss: 0.292618 , Training acc:  0.902606\n",
      "Test loss: 0.391844 , Test acc:  0.860203\n",
      "--------------------------------------------------------------------------------\n",
      "steps 3380\n",
      "learning_rate: 0.00318093\n",
      "Training loss: 0.234357 , Training acc:  0.926283\n",
      "Test loss: 0.325478 , Test acc:  0.890079\n",
      "--------------------------------------------------------------------------------\n",
      "steps 3400\n",
      "learning_rate: 0.00318093\n",
      "Training loss: 0.230542 , Training acc:  0.924294\n",
      "Test loss: 0.339394 , Test acc:  0.882751\n",
      "--------------------------------------------------------------------------------\n",
      "steps 3420\n",
      "learning_rate: 0.00318093\n",
      "Training loss: 0.238636 , Training acc:  0.923995\n",
      "Test loss: 0.32751 , Test acc:  0.891206\n",
      "--------------------------------------------------------------------------------\n",
      "steps 3440\n",
      "learning_rate: 0.00318093\n",
      "Training loss: 0.227425 , Training acc:  0.931357\n",
      "Test loss: 0.313532 , Test acc:  0.896843\n",
      "--------------------------------------------------------------------------------\n",
      "steps 3460\n",
      "learning_rate: 0.00314912\n",
      "Training loss: 0.223988 , Training acc:  0.929069\n",
      "Test loss: 0.31976 , Test acc:  0.894589\n",
      "--------------------------------------------------------------------------------\n",
      "steps 3480\n",
      "learning_rate: 0.00314912\n",
      "Training loss: 0.228911 , Training acc:  0.928173\n",
      "Test loss: 0.327079 , Test acc:  0.883878\n",
      "--------------------------------------------------------------------------------\n",
      "steps 3500\n",
      "learning_rate: 0.00314912\n",
      "Training loss: 0.232721 , Training acc:  0.926781\n",
      "Test loss: 0.334174 , Test acc:  0.880496\n",
      "--------------------------------------------------------------------------------\n",
      "steps 3520\n",
      "learning_rate: 0.00314912\n",
      "Training loss: 0.252697 , Training acc:  0.925885\n",
      "Test loss: 0.350525 , Test acc:  0.879369\n",
      "--------------------------------------------------------------------------------\n",
      "steps 3540\n",
      "learning_rate: 0.00311763\n",
      "Training loss: 0.234288 , Training acc:  0.934441\n",
      "Test loss: 0.312181 , Test acc:  0.90248\n",
      "--------------------------------------------------------------------------------\n",
      "steps 3560\n",
      "learning_rate: 0.00311763\n",
      "Training loss: 0.220537 , Training acc:  0.939216\n",
      "Test loss: 0.302738 , Test acc:  0.907554\n",
      "--------------------------------------------------------------------------------\n",
      "steps 3580\n",
      "learning_rate: 0.00311763\n",
      "Training loss: 0.233295 , Training acc:  0.933148\n",
      "Test loss: 0.31263 , Test acc:  0.901353\n",
      "--------------------------------------------------------------------------------\n",
      "steps 3600\n",
      "learning_rate: 0.00308645\n",
      "Training loss: 0.210182 , Training acc:  0.936132\n",
      "Test loss: 0.305399 , Test acc:  0.898534\n",
      "--------------------------------------------------------------------------------\n",
      "steps 3620\n",
      "learning_rate: 0.00308645\n",
      "Training loss: 0.213291 , Training acc:  0.930561\n",
      "Test loss: 0.299847 , Test acc:  0.897407\n",
      "--------------------------------------------------------------------------------\n",
      "steps 3640\n",
      "learning_rate: 0.00308645\n",
      "Training loss: 0.206383 , Training acc:  0.937326\n",
      "Test loss: 0.297413 , Test acc:  0.899662\n",
      "--------------------------------------------------------------------------------\n",
      "steps 3660\n",
      "learning_rate: 0.00308645\n",
      "Training loss: 0.197851 , Training acc:  0.940907\n",
      "Test loss: 0.288659 , Test acc:  0.904735\n",
      "--------------------------------------------------------------------------------\n",
      "steps 3680\n",
      "learning_rate: 0.00305559\n",
      "Training loss: 0.214887 , Training acc:  0.933446\n",
      "Test loss: 0.299444 , Test acc:  0.900789\n",
      "--------------------------------------------------------------------------------\n",
      "steps 3700\n",
      "learning_rate: 0.00305559\n",
      "Training loss: 0.217146 , Training acc:  0.934739\n",
      "Test loss: 0.29317 , Test acc:  0.905299\n",
      "--------------------------------------------------------------------------------\n",
      "steps 3720\n",
      "learning_rate: 0.00305559\n",
      "Training loss: 0.211781 , Training acc:  0.935038\n",
      "Test loss: 0.303415 , Test acc:  0.900789\n",
      "--------------------------------------------------------------------------------\n",
      "steps 3740\n",
      "learning_rate: 0.00305559\n",
      "Training loss: 0.206572 , Training acc:  0.932451\n",
      "Test loss: 0.311611 , Test acc:  0.895152\n",
      "--------------------------------------------------------------------------------\n",
      "steps 3760\n",
      "learning_rate: 0.00302503\n",
      "Training loss: 0.236807 , Training acc:  0.924592\n",
      "Test loss: 0.345005 , Test acc:  0.885569\n",
      "--------------------------------------------------------------------------------\n",
      "steps 3780\n",
      "learning_rate: 0.00302503\n",
      "Training loss: 0.237683 , Training acc:  0.927577\n",
      "Test loss: 0.329289 , Test acc:  0.892334\n",
      "--------------------------------------------------------------------------------\n",
      "steps 3800\n",
      "learning_rate: 0.00302503\n",
      "Training loss: 0.222234 , Training acc:  0.934043\n",
      "Test loss: 0.331268 , Test acc:  0.894025\n",
      "--------------------------------------------------------------------------------\n",
      "steps 3820\n",
      "learning_rate: 0.00302503\n",
      "Training loss: 0.212599 , Training acc:  0.935038\n",
      "Test loss: 0.327487 , Test acc:  0.89177\n",
      "--------------------------------------------------------------------------------\n",
      "steps 3840\n",
      "learning_rate: 0.00299478\n",
      "Training loss: 0.243156 , Training acc:  0.922602\n",
      "Test loss: 0.346005 , Test acc:  0.875986\n",
      "--------------------------------------------------------------------------------\n",
      "steps 3860\n",
      "learning_rate: 0.00299478\n",
      "Training loss: 0.230561 , Training acc:  0.929666\n",
      "Test loss: 0.323964 , Test acc:  0.890079\n",
      "--------------------------------------------------------------------------------\n",
      "steps 3880\n",
      "learning_rate: 0.00299478\n",
      "Training loss: 0.22872 , Training acc:  0.924592\n",
      "Test loss: 0.323501 , Test acc:  0.891206\n",
      "--------------------------------------------------------------------------------\n",
      "steps 3900\n",
      "learning_rate: 0.00296483\n",
      "Training loss: 0.198898 , Training acc:  0.937624\n",
      "Test loss: 0.297179 , Test acc:  0.904735\n",
      "--------------------------------------------------------------------------------\n",
      "steps 3920\n",
      "learning_rate: 0.00296483\n",
      "Training loss: 0.229147 , Training acc:  0.925189\n",
      "Test loss: 0.315522 , Test acc:  0.893461\n",
      "--------------------------------------------------------------------------------\n",
      "steps 3940\n",
      "learning_rate: 0.00296483\n",
      "Training loss: 0.216093 , Training acc:  0.933247\n",
      "Test loss: 0.303927 , Test acc:  0.899098\n",
      "--------------------------------------------------------------------------------\n",
      "steps 3960\n",
      "learning_rate: 0.00296483\n",
      "Training loss: 0.217397 , Training acc:  0.931954\n",
      "Test loss: 0.324534 , Test acc:  0.896843\n",
      "--------------------------------------------------------------------------------\n",
      "steps 3980\n",
      "learning_rate: 0.00293519\n",
      "Training loss: 0.201041 , Training acc:  0.939912\n",
      "Test loss: 0.302907 , Test acc:  0.901353\n",
      "--------------------------------------------------------------------------------\n",
      "steps 4000\n",
      "learning_rate: 0.00293519\n",
      "Training loss: 0.198211 , Training acc:  0.939614\n",
      "Test loss: 0.300724 , Test acc:  0.900225\n",
      "--------------------------------------------------------------------------------\n",
      "steps 4020\n",
      "learning_rate: 0.00293519\n",
      "Training loss: 0.19475 , Training acc:  0.941803\n",
      "Test loss: 0.296361 , Test acc:  0.900225\n",
      "--------------------------------------------------------------------------------\n",
      "steps 4040\n",
      "learning_rate: 0.00293519\n",
      "Training loss: 0.214409 , Training acc:  0.927975\n",
      "Test loss: 0.335424 , Test acc:  0.879369\n",
      "--------------------------------------------------------------------------------\n",
      "steps 4060\n",
      "learning_rate: 0.00290583\n",
      "Training loss: 0.207315 , Training acc:  0.935237\n",
      "Test loss: 0.310973 , Test acc:  0.900225\n",
      "--------------------------------------------------------------------------------\n",
      "steps 4080\n",
      "learning_rate: 0.00290583\n",
      "Training loss: 0.204615 , Training acc:  0.937525\n",
      "Test loss: 0.315956 , Test acc:  0.897407\n",
      "--------------------------------------------------------------------------------\n",
      "steps 4100\n",
      "learning_rate: 0.00290583\n",
      "Training loss: 0.217198 , Training acc:  0.932153\n",
      "Test loss: 0.312932 , Test acc:  0.892334\n",
      "--------------------------------------------------------------------------------\n",
      "steps 4120\n",
      "learning_rate: 0.00290583\n",
      "Training loss: 0.209416 , Training acc:  0.93663\n",
      "Test loss: 0.312283 , Test acc:  0.895716\n",
      "--------------------------------------------------------------------------------\n",
      "steps 4140\n",
      "learning_rate: 0.00287678\n",
      "Training loss: 0.198661 , Training acc:  0.93663\n",
      "Test loss: 0.301872 , Test acc:  0.895152\n",
      "--------------------------------------------------------------------------------\n",
      "steps 4160\n",
      "learning_rate: 0.00287678\n",
      "Training loss: 0.208851 , Training acc:  0.935535\n",
      "Test loss: 0.304583 , Test acc:  0.897971\n",
      "--------------------------------------------------------------------------------\n",
      "steps 4180\n",
      "learning_rate: 0.00287678\n",
      "Training loss: 0.21735 , Training acc:  0.929566\n",
      "Test loss: 0.319354 , Test acc:  0.895716\n",
      "--------------------------------------------------------------------------------\n",
      "steps 4200\n",
      "learning_rate: 0.00284801\n",
      "Training loss: 0.203667 , Training acc:  0.93663\n",
      "Test loss: 0.305143 , Test acc:  0.904171\n",
      "--------------------------------------------------------------------------------\n",
      "steps 4220\n",
      "learning_rate: 0.00284801\n",
      "Training loss: 0.194653 , Training acc:  0.939415\n",
      "Test loss: 0.299434 , Test acc:  0.901353\n",
      "--------------------------------------------------------------------------------\n",
      "steps 4240\n",
      "learning_rate: 0.00284801\n",
      "Training loss: 0.189759 , Training acc:  0.943295\n",
      "Test loss: 0.286205 , Test acc:  0.899662\n",
      "--------------------------------------------------------------------------------\n",
      "steps 4260\n",
      "learning_rate: 0.00284801\n",
      "Training loss: 0.182554 , Training acc:  0.947871\n",
      "Test loss: 0.280332 , Test acc:  0.906426\n",
      "--------------------------------------------------------------------------------\n",
      "steps 4280\n",
      "learning_rate: 0.00281953\n",
      "Training loss: 0.191028 , Training acc:  0.941703\n",
      "Test loss: 0.295747 , Test acc:  0.901917\n",
      "--------------------------------------------------------------------------------\n",
      "steps 4300\n",
      "learning_rate: 0.00281953\n",
      "Training loss: 0.188814 , Training acc:  0.94031\n",
      "Test loss: 0.297925 , Test acc:  0.891206\n",
      "--------------------------------------------------------------------------------\n",
      "steps 4320\n",
      "learning_rate: 0.00281953\n",
      "Training loss: 0.192986 , Training acc:  0.939515\n",
      "Test loss: 0.303834 , Test acc:  0.894025\n",
      "--------------------------------------------------------------------------------\n",
      "steps 4340\n",
      "learning_rate: 0.00281953\n",
      "Training loss: 0.189269 , Training acc:  0.938918\n",
      "Test loss: 0.296334 , Test acc:  0.898534\n",
      "--------------------------------------------------------------------------------\n",
      "steps 4360\n",
      "learning_rate: 0.00279133\n",
      "Training loss: 0.278503 , Training acc:  0.902606\n",
      "Test loss: 0.401364 , Test acc:  0.857948\n",
      "--------------------------------------------------------------------------------\n",
      "steps 4380\n",
      "learning_rate: 0.00279133\n",
      "Training loss: 0.226308 , Training acc:  0.928571\n",
      "Test loss: 0.350296 , Test acc:  0.879932\n",
      "--------------------------------------------------------------------------------\n",
      "steps 4400\n",
      "learning_rate: 0.00279133\n",
      "Training loss: 0.214483 , Training acc:  0.932352\n",
      "Test loss: 0.337454 , Test acc:  0.878805\n",
      "--------------------------------------------------------------------------------\n",
      "steps 4420\n",
      "learning_rate: 0.00279133\n",
      "Training loss: 0.211563 , Training acc:  0.927676\n",
      "Test loss: 0.330114 , Test acc:  0.884442\n",
      "--------------------------------------------------------------------------------\n",
      "steps 4440\n",
      "learning_rate: 0.00276342\n",
      "Training loss: 0.170782 , Training acc:  0.947573\n",
      "Test loss: 0.294814 , Test acc:  0.904735\n",
      "--------------------------------------------------------------------------------\n",
      "steps 4460\n",
      "learning_rate: 0.00276342\n",
      "Training loss: 0.184689 , Training acc:  0.9424\n",
      "Test loss: 0.30031 , Test acc:  0.892897\n",
      "--------------------------------------------------------------------------------\n",
      "steps 4480\n",
      "learning_rate: 0.00276342\n",
      "Training loss: 0.172521 , Training acc:  0.948468\n",
      "Test loss: 0.285561 , Test acc:  0.901353\n",
      "--------------------------------------------------------------------------------\n",
      "steps 4500\n",
      "learning_rate: 0.00273578\n",
      "Training loss: 0.178795 , Training acc:  0.946777\n",
      "Test loss: 0.295652 , Test acc:  0.897407\n",
      "--------------------------------------------------------------------------------\n",
      "steps 4520\n",
      "learning_rate: 0.00273578\n",
      "Training loss: 0.178184 , Training acc:  0.945484\n",
      "Test loss: 0.299322 , Test acc:  0.897407\n",
      "--------------------------------------------------------------------------------\n",
      "steps 4540\n",
      "learning_rate: 0.00273578\n",
      "Training loss: 0.18246 , Training acc:  0.940907\n",
      "Test loss: 0.300881 , Test acc:  0.896843\n",
      "--------------------------------------------------------------------------------\n",
      "steps 4560\n",
      "learning_rate: 0.00273578\n",
      "Training loss: 0.179087 , Training acc:  0.947573\n",
      "Test loss: 0.293273 , Test acc:  0.900225\n",
      "--------------------------------------------------------------------------------\n",
      "steps 4580\n",
      "learning_rate: 0.00270843\n",
      "Training loss: 0.177615 , Training acc:  0.951651\n",
      "Test loss: 0.299307 , Test acc:  0.896843\n",
      "--------------------------------------------------------------------------------\n",
      "steps 4600\n",
      "learning_rate: 0.00270843\n",
      "Training loss: 0.169213 , Training acc:  0.952845\n",
      "Test loss: 0.28914 , Test acc:  0.901353\n",
      "--------------------------------------------------------------------------------\n",
      "steps 4620\n",
      "learning_rate: 0.00270843\n",
      "Training loss: 0.183516 , Training acc:  0.94419\n",
      "Test loss: 0.305819 , Test acc:  0.896843\n",
      "--------------------------------------------------------------------------------\n",
      "steps 4640\n",
      "learning_rate: 0.00270843\n",
      "Training loss: 0.181464 , Training acc:  0.946379\n",
      "Test loss: 0.296785 , Test acc:  0.903044\n",
      "--------------------------------------------------------------------------------\n",
      "steps 4660\n",
      "learning_rate: 0.00268134\n",
      "Training loss: 0.166195 , Training acc:  0.948866\n",
      "Test loss: 0.28425 , Test acc:  0.900225\n",
      "--------------------------------------------------------------------------------\n",
      "steps 4680\n",
      "learning_rate: 0.00268134\n",
      "Training loss: 0.175344 , Training acc:  0.946379\n",
      "Test loss: 0.292588 , Test acc:  0.899098\n",
      "--------------------------------------------------------------------------------\n",
      "steps 4700\n",
      "learning_rate: 0.00268134\n",
      "Training loss: 0.171656 , Training acc:  0.949562\n",
      "Test loss: 0.286451 , Test acc:  0.901353\n",
      "--------------------------------------------------------------------------------\n",
      "steps 4720\n",
      "learning_rate: 0.00268134\n",
      "Training loss: 0.192395 , Training acc:  0.944688\n",
      "Test loss: 0.320214 , Test acc:  0.895152\n",
      "--------------------------------------------------------------------------------\n",
      "steps 4740\n",
      "learning_rate: 0.00265453\n",
      "Training loss: 0.192563 , Training acc:  0.93663\n",
      "Test loss: 0.316248 , Test acc:  0.887824\n",
      "--------------------------------------------------------------------------------\n",
      "steps 4760\n",
      "learning_rate: 0.00265453\n",
      "Training loss: 0.191606 , Training acc:  0.938321\n",
      "Test loss: 0.324799 , Test acc:  0.886697\n",
      "--------------------------------------------------------------------------------\n",
      "steps 4780\n",
      "learning_rate: 0.00265453\n",
      "Training loss: 0.204148 , Training acc:  0.942598\n",
      "Test loss: 0.326126 , Test acc:  0.884442\n",
      "--------------------------------------------------------------------------------\n",
      "steps 4800\n",
      "learning_rate: 0.00262798\n",
      "Training loss: 0.180435 , Training acc:  0.946578\n",
      "Test loss: 0.304026 , Test acc:  0.893461\n",
      "--------------------------------------------------------------------------------\n",
      "steps 4820\n",
      "learning_rate: 0.00262798\n",
      "Training loss: 0.186498 , Training acc:  0.9423\n",
      "Test loss: 0.300827 , Test acc:  0.900225\n",
      "--------------------------------------------------------------------------------\n",
      "steps 4840\n",
      "learning_rate: 0.00262798\n",
      "Training loss: 0.165707 , Training acc:  0.952447\n",
      "Test loss: 0.283481 , Test acc:  0.90699\n",
      "--------------------------------------------------------------------------------\n",
      "steps 4860\n",
      "learning_rate: 0.00262798\n",
      "Training loss: 0.158475 , Training acc:  0.951452\n",
      "Test loss: 0.279911 , Test acc:  0.905862\n",
      "--------------------------------------------------------------------------------\n",
      "steps 4880\n",
      "learning_rate: 0.0026017\n",
      "Training loss: 0.160049 , Training acc:  0.948766\n",
      "Test loss: 0.286184 , Test acc:  0.900789\n",
      "--------------------------------------------------------------------------------\n",
      "steps 4900\n",
      "learning_rate: 0.0026017\n",
      "Training loss: 0.171433 , Training acc:  0.950557\n",
      "Test loss: 0.300913 , Test acc:  0.895716\n",
      "--------------------------------------------------------------------------------\n",
      "steps 4920\n",
      "learning_rate: 0.0026017\n",
      "Training loss: 0.167019 , Training acc:  0.948567\n",
      "Test loss: 0.284068 , Test acc:  0.901353\n",
      "--------------------------------------------------------------------------------\n",
      "steps 4940\n",
      "learning_rate: 0.0026017\n",
      "Training loss: 0.162326 , Training acc:  0.947473\n",
      "Test loss: 0.278115 , Test acc:  0.903044\n",
      "--------------------------------------------------------------------------------\n",
      "steps 4960\n",
      "learning_rate: 0.00257569\n",
      "Training loss: 0.165905 , Training acc:  0.949562\n",
      "Test loss: 0.288572 , Test acc:  0.897407\n",
      "--------------------------------------------------------------------------------\n",
      "steps 4980\n",
      "learning_rate: 0.00257569\n",
      "Training loss: 0.193343 , Training acc:  0.939713\n",
      "Test loss: 0.315372 , Test acc:  0.885569\n",
      "--------------------------------------------------------------------------------\n",
      "steps 5000\n",
      "learning_rate: 0.00257569\n",
      "Training loss: 0.157313 , Training acc:  0.954934\n",
      "Test loss: 0.277189 , Test acc:  0.901353\n",
      "--------------------------------------------------------------------------------\n",
      "steps 5020\n",
      "learning_rate: 0.00257569\n",
      "Training loss: 0.163297 , Training acc:  0.952049\n",
      "Test loss: 0.287761 , Test acc:  0.899662\n",
      "--------------------------------------------------------------------------------\n",
      "steps 5040\n",
      "learning_rate: 0.00254993\n",
      "Training loss: 0.157757 , Training acc:  0.953641\n",
      "Test loss: 0.279137 , Test acc:  0.90248\n",
      "--------------------------------------------------------------------------------\n",
      "steps 5060\n",
      "learning_rate: 0.00254993\n",
      "Training loss: 0.181501 , Training acc:  0.947971\n",
      "Test loss: 0.297957 , Test acc:  0.895716\n",
      "--------------------------------------------------------------------------------\n",
      "steps 5080\n",
      "learning_rate: 0.00254993\n",
      "Training loss: 0.173879 , Training acc:  0.949562\n",
      "Test loss: 0.297681 , Test acc:  0.895152\n",
      "--------------------------------------------------------------------------------\n",
      "steps 5100\n",
      "learning_rate: 0.00252443\n",
      "Training loss: 0.182289 , Training acc:  0.945782\n",
      "Test loss: 0.304233 , Test acc:  0.895152\n",
      "--------------------------------------------------------------------------------\n",
      "steps 5120\n",
      "learning_rate: 0.00252443\n",
      "Training loss: 0.164766 , Training acc:  0.950159\n",
      "Test loss: 0.277806 , Test acc:  0.90248\n",
      "--------------------------------------------------------------------------------\n",
      "steps 5140\n",
      "learning_rate: 0.00252443\n",
      "Training loss: 0.157621 , Training acc:  0.952149\n",
      "Test loss: 0.275848 , Test acc:  0.898534\n",
      "--------------------------------------------------------------------------------\n",
      "steps 5160\n",
      "learning_rate: 0.00252443\n",
      "Training loss: 0.183613 , Training acc:  0.942002\n",
      "Test loss: 0.295714 , Test acc:  0.899098\n",
      "--------------------------------------------------------------------------------\n",
      "steps 5180\n",
      "learning_rate: 0.00249919\n",
      "Training loss: 0.185044 , Training acc:  0.944787\n",
      "Test loss: 0.29993 , Test acc:  0.901353\n",
      "--------------------------------------------------------------------------------\n",
      "steps 5200\n",
      "learning_rate: 0.00249919\n",
      "Training loss: 0.202552 , Training acc:  0.939216\n",
      "Test loss: 0.329749 , Test acc:  0.884442\n",
      "--------------------------------------------------------------------------------\n",
      "steps 5220\n",
      "learning_rate: 0.00249919\n",
      "Training loss: 0.166065 , Training acc:  0.953144\n",
      "Test loss: 0.288015 , Test acc:  0.906426\n",
      "--------------------------------------------------------------------------------\n",
      "steps 5240\n",
      "learning_rate: 0.00249919\n",
      "Training loss: 0.170107 , Training acc:  0.951452\n",
      "Test loss: 0.299183 , Test acc:  0.898534\n",
      "--------------------------------------------------------------------------------\n",
      "steps 5260\n",
      "learning_rate: 0.00247419\n",
      "Training loss: 0.166968 , Training acc:  0.952845\n",
      "Test loss: 0.28534 , Test acc:  0.905299\n",
      "--------------------------------------------------------------------------------\n",
      "steps 5280\n",
      "learning_rate: 0.00247419\n",
      "Training loss: 0.151104 , Training acc:  0.95573\n",
      "Test loss: 0.270186 , Test acc:  0.905299\n",
      "--------------------------------------------------------------------------------\n",
      "steps 5300\n",
      "learning_rate: 0.00247419\n",
      "Training loss: 0.152432 , Training acc:  0.956427\n",
      "Test loss: 0.276642 , Test acc:  0.90699\n",
      "--------------------------------------------------------------------------------\n",
      "steps 5320\n",
      "learning_rate: 0.00247419\n",
      "Training loss: 0.154773 , Training acc:  0.953641\n",
      "Test loss: 0.275551 , Test acc:  0.903044\n",
      "--------------------------------------------------------------------------------\n",
      "steps 5340\n",
      "learning_rate: 0.00244945\n",
      "Training loss: 0.155109 , Training acc:  0.951353\n",
      "Test loss: 0.275405 , Test acc:  0.90248\n",
      "--------------------------------------------------------------------------------\n",
      "steps 5360\n",
      "learning_rate: 0.00244945\n",
      "Training loss: 0.20717 , Training acc:  0.93842\n",
      "Test loss: 0.3387 , Test acc:  0.875986\n",
      "--------------------------------------------------------------------------------\n",
      "steps 5380\n",
      "learning_rate: 0.00244945\n",
      "Training loss: 0.184336 , Training acc:  0.940708\n",
      "Test loss: 0.309088 , Test acc:  0.887824\n",
      "--------------------------------------------------------------------------------\n",
      "steps 5400\n",
      "learning_rate: 0.00242496\n",
      "Training loss: 0.175575 , Training acc:  0.947473\n",
      "Test loss: 0.310477 , Test acc:  0.895716\n",
      "--------------------------------------------------------------------------------\n",
      "steps 5420\n",
      "learning_rate: 0.00242496\n",
      "Training loss: 0.152196 , Training acc:  0.958118\n",
      "Test loss: 0.274344 , Test acc:  0.905299\n",
      "--------------------------------------------------------------------------------\n",
      "steps 5440\n",
      "learning_rate: 0.00242496\n",
      "Training loss: 0.164935 , Training acc:  0.950557\n",
      "Test loss: 0.290026 , Test acc:  0.899098\n",
      "--------------------------------------------------------------------------------\n",
      "steps 5460\n",
      "learning_rate: 0.00242496\n",
      "Training loss: 0.140025 , Training acc:  0.958715\n",
      "Test loss: 0.257929 , Test acc:  0.909808\n",
      "--------------------------------------------------------------------------------\n",
      "steps 5480\n",
      "learning_rate: 0.00240071\n",
      "Training loss: 0.1447 , Training acc:  0.956029\n",
      "Test loss: 0.265212 , Test acc:  0.904735\n",
      "--------------------------------------------------------------------------------\n",
      "steps 5500\n",
      "learning_rate: 0.00240071\n",
      "Training loss: 0.149923 , Training acc:  0.957123\n",
      "Test loss: 0.277674 , Test acc:  0.911499\n",
      "--------------------------------------------------------------------------------\n",
      "steps 5520\n",
      "learning_rate: 0.00240071\n",
      "Training loss: 0.150207 , Training acc:  0.954934\n",
      "Test loss: 0.273063 , Test acc:  0.903608\n",
      "--------------------------------------------------------------------------------\n",
      "steps 5540\n",
      "learning_rate: 0.00240071\n",
      "Training loss: 0.140775 , Training acc:  0.957521\n",
      "Test loss: 0.263883 , Test acc:  0.910372\n",
      "--------------------------------------------------------------------------------\n",
      "steps 5560\n",
      "learning_rate: 0.0023767\n",
      "Training loss: 0.145781 , Training acc:  0.955432\n",
      "Test loss: 0.275795 , Test acc:  0.905299\n",
      "--------------------------------------------------------------------------------\n",
      "steps 5580\n",
      "learning_rate: 0.0023767\n",
      "Training loss: 0.146162 , Training acc:  0.954238\n",
      "Test loss: 0.277459 , Test acc:  0.906426\n",
      "--------------------------------------------------------------------------------\n",
      "steps 5600\n",
      "learning_rate: 0.0023767\n",
      "Training loss: 0.162134 , Training acc:  0.947374\n",
      "Test loss: 0.289755 , Test acc:  0.906426\n",
      "--------------------------------------------------------------------------------\n",
      "steps 5620\n",
      "learning_rate: 0.0023767\n",
      "Training loss: 0.137822 , Training acc:  0.960505\n",
      "Test loss: 0.263798 , Test acc:  0.911499\n",
      "--------------------------------------------------------------------------------\n",
      "steps 5640\n",
      "learning_rate: 0.00235293\n",
      "Training loss: 0.132161 , Training acc:  0.961202\n",
      "Test loss: 0.257813 , Test acc:  0.913191\n",
      "--------------------------------------------------------------------------------\n",
      "steps 5660\n",
      "learning_rate: 0.00235293\n",
      "Training loss: 0.132155 , Training acc:  0.961301\n",
      "Test loss: 0.252081 , Test acc:  0.916009\n",
      "--------------------------------------------------------------------------------\n",
      "steps 5680\n",
      "learning_rate: 0.00235293\n",
      "Training loss: 0.130909 , Training acc:  0.959411\n",
      "Test loss: 0.253577 , Test acc:  0.916573\n",
      "--------------------------------------------------------------------------------\n",
      "steps 5700\n",
      "learning_rate: 0.00232941\n",
      "Training loss: 0.122001 , Training acc:  0.963987\n",
      "Test loss: 0.252448 , Test acc:  0.913754\n",
      "--------------------------------------------------------------------------------\n",
      "steps 5720\n",
      "learning_rate: 0.00232941\n",
      "Training loss: 0.130339 , Training acc:  0.958416\n",
      "Test loss: 0.262334 , Test acc:  0.913754\n",
      "--------------------------------------------------------------------------------\n",
      "steps 5740\n",
      "learning_rate: 0.00232941\n",
      "Training loss: 0.141713 , Training acc:  0.955133\n",
      "Test loss: 0.270772 , Test acc:  0.903044\n",
      "--------------------------------------------------------------------------------\n",
      "steps 5760\n",
      "learning_rate: 0.00232941\n",
      "Training loss: 0.153032 , Training acc:  0.951651\n",
      "Test loss: 0.289714 , Test acc:  0.895152\n",
      "--------------------------------------------------------------------------------\n",
      "steps 5780\n",
      "learning_rate: 0.00230611\n",
      "Training loss: 0.128252 , Training acc:  0.960704\n",
      "Test loss: 0.262511 , Test acc:  0.908681\n",
      "--------------------------------------------------------------------------------\n",
      "steps 5800\n",
      "learning_rate: 0.00230611\n",
      "Training loss: 0.14063 , Training acc:  0.956526\n",
      "Test loss: 0.27224 , Test acc:  0.910372\n",
      "--------------------------------------------------------------------------------\n",
      "steps 5820\n",
      "learning_rate: 0.00230611\n",
      "Training loss: 0.130947 , Training acc:  0.962097\n",
      "Test loss: 0.254871 , Test acc:  0.914318\n",
      "--------------------------------------------------------------------------------\n",
      "steps 5840\n",
      "learning_rate: 0.00230611\n",
      "Training loss: 0.141477 , Training acc:  0.958416\n",
      "Test loss: 0.283666 , Test acc:  0.900789\n",
      "--------------------------------------------------------------------------------\n",
      "steps 5860\n",
      "learning_rate: 0.00228305\n",
      "Training loss: 0.130007 , Training acc:  0.962396\n",
      "Test loss: 0.26501 , Test acc:  0.90699\n",
      "--------------------------------------------------------------------------------\n",
      "steps 5880\n",
      "learning_rate: 0.00228305\n",
      "Training loss: 0.135986 , Training acc:  0.959908\n",
      "Test loss: 0.267396 , Test acc:  0.912063\n",
      "--------------------------------------------------------------------------------\n",
      "steps 5900\n",
      "learning_rate: 0.00228305\n",
      "Training loss: 0.140093 , Training acc:  0.961998\n",
      "Test loss: 0.277519 , Test acc:  0.90248\n",
      "--------------------------------------------------------------------------------\n",
      "steps 5920\n",
      "learning_rate: 0.00228305\n",
      "Training loss: 0.147205 , Training acc:  0.961202\n",
      "Test loss: 0.283271 , Test acc:  0.90248\n",
      "--------------------------------------------------------------------------------\n",
      "steps 5940\n",
      "learning_rate: 0.00226022\n",
      "Training loss: 0.136976 , Training acc:  0.962595\n",
      "Test loss: 0.271675 , Test acc:  0.90699\n",
      "--------------------------------------------------------------------------------\n",
      "steps 5960\n",
      "learning_rate: 0.00226022\n",
      "Training loss: 0.145794 , Training acc:  0.956128\n",
      "Test loss: 0.291104 , Test acc:  0.900225\n",
      "--------------------------------------------------------------------------------\n",
      "steps 5980\n",
      "learning_rate: 0.00226022\n",
      "Training loss: 0.133421 , Training acc:  0.963092\n",
      "Test loss: 0.269485 , Test acc:  0.908117\n",
      "--------------------------------------------------------------------------------\n",
      "steps 6000\n",
      "learning_rate: 0.00223762\n",
      "Training loss: 0.142587 , Training acc:  0.958118\n",
      "Test loss: 0.278167 , Test acc:  0.905862\n",
      "--------------------------------------------------------------------------------\n",
      "steps 6020\n",
      "learning_rate: 0.00223762\n",
      "Training loss: 0.158087 , Training acc:  0.949761\n",
      "Test loss: 0.304947 , Test acc:  0.888952\n",
      "--------------------------------------------------------------------------------\n",
      "steps 6040\n",
      "learning_rate: 0.00223762\n",
      "Training loss: 0.149406 , Training acc:  0.949562\n",
      "Test loss: 0.282088 , Test acc:  0.899662\n",
      "--------------------------------------------------------------------------------\n",
      "steps 6060\n",
      "learning_rate: 0.00223762\n",
      "Training loss: 0.135831 , Training acc:  0.960107\n",
      "Test loss: 0.266337 , Test acc:  0.908681\n",
      "--------------------------------------------------------------------------------\n",
      "steps 6080\n",
      "learning_rate: 0.00221524\n",
      "Training loss: 0.134124 , Training acc:  0.963291\n",
      "Test loss: 0.265705 , Test acc:  0.910372\n",
      "--------------------------------------------------------------------------------\n",
      "steps 6100\n",
      "learning_rate: 0.00221524\n",
      "Training loss: 0.135239 , Training acc:  0.963291\n",
      "Test loss: 0.27091 , Test acc:  0.90699\n",
      "--------------------------------------------------------------------------------\n",
      "steps 6120\n",
      "learning_rate: 0.00221524\n",
      "Training loss: 0.123734 , Training acc:  0.96727\n",
      "Test loss: 0.26354 , Test acc:  0.913754\n",
      "--------------------------------------------------------------------------------\n",
      "steps 6140\n",
      "learning_rate: 0.00221524\n",
      "Training loss: 0.129484 , Training acc:  0.964186\n",
      "Test loss: 0.274412 , Test acc:  0.908681\n",
      "--------------------------------------------------------------------------------\n",
      "steps 6160\n",
      "learning_rate: 0.00219309\n",
      "Training loss: 0.139905 , Training acc:  0.958715\n",
      "Test loss: 0.28373 , Test acc:  0.909245\n",
      "--------------------------------------------------------------------------------\n",
      "steps 6180\n",
      "learning_rate: 0.00219309\n",
      "Training loss: 0.13073 , Training acc:  0.9615\n",
      "Test loss: 0.274004 , Test acc:  0.903608\n",
      "--------------------------------------------------------------------------------\n",
      "steps 6200\n",
      "learning_rate: 0.00219309\n",
      "Training loss: 0.126288 , Training acc:  0.963987\n",
      "Test loss: 0.272233 , Test acc:  0.907554\n",
      "--------------------------------------------------------------------------------\n",
      "steps 6220\n",
      "learning_rate: 0.00219309\n",
      "Training loss: 0.133409 , Training acc:  0.961998\n",
      "Test loss: 0.286618 , Test acc:  0.906426\n",
      "--------------------------------------------------------------------------------\n",
      "steps 6240\n",
      "learning_rate: 0.00217116\n",
      "Training loss: 0.131571 , Training acc:  0.962992\n",
      "Test loss: 0.280622 , Test acc:  0.912063\n",
      "--------------------------------------------------------------------------------\n",
      "steps 6260\n",
      "learning_rate: 0.00217116\n",
      "Training loss: 0.128243 , Training acc:  0.964982\n",
      "Test loss: 0.270175 , Test acc:  0.913754\n",
      "--------------------------------------------------------------------------------\n",
      "steps 6280\n",
      "learning_rate: 0.00217116\n",
      "Training loss: 0.132152 , Training acc:  0.964286\n",
      "Test loss: 0.274346 , Test acc:  0.909245\n",
      "--------------------------------------------------------------------------------\n",
      "steps 6300\n",
      "learning_rate: 0.00214945\n",
      "Training loss: 0.129449 , Training acc:  0.965281\n",
      "Test loss: 0.261206 , Test acc:  0.910372\n",
      "--------------------------------------------------------------------------------\n",
      "steps 6320\n",
      "learning_rate: 0.00214945\n",
      "Training loss: 0.148424 , Training acc:  0.953243\n",
      "Test loss: 0.297326 , Test acc:  0.899662\n",
      "--------------------------------------------------------------------------------\n",
      "steps 6340\n",
      "learning_rate: 0.00214945\n",
      "Training loss: 0.143574 , Training acc:  0.954337\n",
      "Test loss: 0.297471 , Test acc:  0.893461\n",
      "--------------------------------------------------------------------------------\n",
      "steps 6360\n",
      "learning_rate: 0.00214945\n",
      "Training loss: 0.129196 , Training acc:  0.961401\n",
      "Test loss: 0.284612 , Test acc:  0.904735\n",
      "--------------------------------------------------------------------------------\n",
      "steps 6380\n",
      "learning_rate: 0.00212795\n",
      "Training loss: 0.122582 , Training acc:  0.964385\n",
      "Test loss: 0.267101 , Test acc:  0.909245\n",
      "--------------------------------------------------------------------------------\n",
      "steps 6400\n",
      "learning_rate: 0.00212795\n",
      "Training loss: 0.127127 , Training acc:  0.964286\n",
      "Test loss: 0.272631 , Test acc:  0.906426\n",
      "--------------------------------------------------------------------------------\n",
      "steps 6420\n",
      "learning_rate: 0.00212795\n",
      "Training loss: 0.123851 , Training acc:  0.965082\n",
      "Test loss: 0.266578 , Test acc:  0.904171\n",
      "--------------------------------------------------------------------------------\n",
      "steps 6440\n",
      "learning_rate: 0.00212795\n",
      "Training loss: 0.138382 , Training acc:  0.959113\n",
      "Test loss: 0.278344 , Test acc:  0.90248\n",
      "--------------------------------------------------------------------------------\n",
      "steps 6460\n",
      "learning_rate: 0.00210667\n",
      "Training loss: 0.124471 , Training acc:  0.965678\n",
      "Test loss: 0.269109 , Test acc:  0.912063\n",
      "--------------------------------------------------------------------------------\n",
      "steps 6480\n",
      "learning_rate: 0.00210667\n",
      "Training loss: 0.124911 , Training acc:  0.965678\n",
      "Test loss: 0.270826 , Test acc:  0.90248\n",
      "--------------------------------------------------------------------------------\n",
      "steps 6500\n",
      "learning_rate: 0.00210667\n",
      "Training loss: 0.124961 , Training acc:  0.964783\n",
      "Test loss: 0.266195 , Test acc:  0.909808\n",
      "--------------------------------------------------------------------------------\n",
      "steps 6520\n",
      "learning_rate: 0.00210667\n",
      "Training loss: 0.107839 , Training acc:  0.969459\n",
      "Test loss: 0.255744 , Test acc:  0.911499\n",
      "--------------------------------------------------------------------------------\n",
      "steps 6540\n",
      "learning_rate: 0.00208561\n",
      "Training loss: 0.108184 , Training acc:  0.968364\n",
      "Test loss: 0.255851 , Test acc:  0.916009\n",
      "--------------------------------------------------------------------------------\n",
      "steps 6560\n",
      "learning_rate: 0.00208561\n",
      "Training loss: 0.125815 , Training acc:  0.963689\n",
      "Test loss: 0.280281 , Test acc:  0.905299\n",
      "--------------------------------------------------------------------------------\n",
      "steps 6580\n",
      "learning_rate: 0.00208561\n",
      "Training loss: 0.118331 , Training acc:  0.966176\n",
      "Test loss: 0.261302 , Test acc:  0.913754\n",
      "--------------------------------------------------------------------------------\n",
      "steps 6600\n",
      "learning_rate: 0.00206475\n",
      "Training loss: 0.114626 , Training acc:  0.966375\n",
      "Test loss: 0.253336 , Test acc:  0.915445\n",
      "--------------------------------------------------------------------------------\n",
      "steps 6620\n",
      "learning_rate: 0.00206475\n",
      "Training loss: 0.121423 , Training acc:  0.963888\n",
      "Test loss: 0.261689 , Test acc:  0.912627\n",
      "--------------------------------------------------------------------------------\n",
      "steps 6640\n",
      "learning_rate: 0.00206475\n",
      "Training loss: 0.119204 , Training acc:  0.962694\n",
      "Test loss: 0.265038 , Test acc:  0.912627\n",
      "--------------------------------------------------------------------------------\n",
      "steps 6660\n",
      "learning_rate: 0.00206475\n",
      "Training loss: 0.124335 , Training acc:  0.965877\n",
      "Test loss: 0.26364 , Test acc:  0.913754\n",
      "--------------------------------------------------------------------------------\n",
      "steps 6680\n",
      "learning_rate: 0.0020441\n",
      "Training loss: 0.11879 , Training acc:  0.968166\n",
      "Test loss: 0.260268 , Test acc:  0.917136\n",
      "--------------------------------------------------------------------------------\n",
      "steps 6700\n",
      "learning_rate: 0.0020441\n",
      "Training loss: 0.119755 , Training acc:  0.965877\n",
      "Test loss: 0.268318 , Test acc:  0.912627\n",
      "--------------------------------------------------------------------------------\n",
      "steps 6720\n",
      "learning_rate: 0.0020441\n",
      "Training loss: 0.113807 , Training acc:  0.970553\n",
      "Test loss: 0.255259 , Test acc:  0.916009\n",
      "--------------------------------------------------------------------------------\n",
      "steps 6740\n",
      "learning_rate: 0.0020441\n",
      "Training loss: 0.120933 , Training acc:  0.965479\n",
      "Test loss: 0.261179 , Test acc:  0.913754\n",
      "--------------------------------------------------------------------------------\n",
      "steps 6760\n",
      "learning_rate: 0.00202366\n",
      "Training loss: 0.115846 , Training acc:  0.968265\n",
      "Test loss: 0.251441 , Test acc:  0.910372\n",
      "--------------------------------------------------------------------------------\n",
      "steps 6780\n",
      "learning_rate: 0.00202366\n",
      "Training loss: 0.112497 , Training acc:  0.966076\n",
      "Test loss: 0.265027 , Test acc:  0.908117\n",
      "--------------------------------------------------------------------------------\n",
      "steps 6800\n",
      "learning_rate: 0.00202366\n",
      "Training loss: 0.130819 , Training acc:  0.958317\n",
      "Test loss: 0.286542 , Test acc:  0.900789\n",
      "--------------------------------------------------------------------------------\n",
      "steps 6820\n",
      "learning_rate: 0.00202366\n",
      "Training loss: 0.111126 , Training acc:  0.968961\n",
      "Test loss: 0.256402 , Test acc:  0.908681\n",
      "--------------------------------------------------------------------------------\n",
      "steps 6840\n",
      "learning_rate: 0.00200343\n",
      "Training loss: 0.111681 , Training acc:  0.969061\n",
      "Test loss: 0.257578 , Test acc:  0.910936\n",
      "--------------------------------------------------------------------------------\n",
      "steps 6860\n",
      "learning_rate: 0.00200343\n",
      "Training loss: 0.12107 , Training acc:  0.966673\n",
      "Test loss: 0.268006 , Test acc:  0.903608\n",
      "--------------------------------------------------------------------------------\n",
      "steps 6880\n",
      "learning_rate: 0.00200343\n",
      "Training loss: 0.112824 , Training acc:  0.97115\n",
      "Test loss: 0.250541 , Test acc:  0.916573\n",
      "--------------------------------------------------------------------------------\n",
      "steps 6900\n",
      "learning_rate: 0.00198339\n",
      "Training loss: 0.121133 , Training acc:  0.967469\n",
      "Test loss: 0.262219 , Test acc:  0.910372\n",
      "--------------------------------------------------------------------------------\n",
      "steps 6920\n",
      "learning_rate: 0.00198339\n",
      "Training loss: 0.128536 , Training acc:  0.965281\n",
      "Test loss: 0.272323 , Test acc:  0.903044\n",
      "--------------------------------------------------------------------------------\n",
      "steps 6940\n",
      "learning_rate: 0.00198339\n",
      "Training loss: 0.116801 , Training acc:  0.966972\n",
      "Test loss: 0.257791 , Test acc:  0.907554\n",
      "--------------------------------------------------------------------------------\n",
      "steps 6960\n",
      "learning_rate: 0.00198339\n",
      "Training loss: 0.119787 , Training acc:  0.963092\n",
      "Test loss: 0.269123 , Test acc:  0.905862\n",
      "--------------------------------------------------------------------------------\n",
      "steps 6980\n",
      "learning_rate: 0.00196356\n",
      "Training loss: 0.112198 , Training acc:  0.96916\n",
      "Test loss: 0.258853 , Test acc:  0.914882\n",
      "--------------------------------------------------------------------------------\n",
      "steps 7000\n",
      "learning_rate: 0.00196356\n",
      "Training loss: 0.11135 , Training acc:  0.971051\n",
      "Test loss: 0.249242 , Test acc:  0.916573\n",
      "--------------------------------------------------------------------------------\n",
      "steps 7020\n",
      "learning_rate: 0.00196356\n",
      "Training loss: 0.118067 , Training acc:  0.969857\n",
      "Test loss: 0.260852 , Test acc:  0.913191\n",
      "--------------------------------------------------------------------------------\n",
      "steps 7040\n",
      "learning_rate: 0.00196356\n",
      "Training loss: 0.113923 , Training acc:  0.972543\n",
      "Test loss: 0.253 , Test acc:  0.916573\n",
      "--------------------------------------------------------------------------------\n",
      "steps 7060\n",
      "learning_rate: 0.00194392\n",
      "Training loss: 0.10581 , Training acc:  0.971946\n",
      "Test loss: 0.249799 , Test acc:  0.912627\n",
      "--------------------------------------------------------------------------------\n",
      "steps 7080\n",
      "learning_rate: 0.00194392\n",
      "Training loss: 0.106077 , Training acc:  0.970852\n",
      "Test loss: 0.250453 , Test acc:  0.920519\n",
      "--------------------------------------------------------------------------------\n",
      "steps 7100\n",
      "learning_rate: 0.00194392\n",
      "Training loss: 0.112411 , Training acc:  0.970155\n",
      "Test loss: 0.257299 , Test acc:  0.916573\n",
      "--------------------------------------------------------------------------------\n",
      "steps 7120\n",
      "learning_rate: 0.00194392\n",
      "Training loss: 0.105298 , Training acc:  0.975129\n",
      "Test loss: 0.256374 , Test acc:  0.911499\n",
      "--------------------------------------------------------------------------------\n",
      "steps 7140\n",
      "learning_rate: 0.00192448\n",
      "Training loss: 0.098552 , Training acc:  0.977318\n",
      "Test loss: 0.248806 , Test acc:  0.9177\n",
      "--------------------------------------------------------------------------------\n",
      "steps 7160\n",
      "learning_rate: 0.00192448\n",
      "Training loss: 0.101972 , Training acc:  0.975229\n",
      "Test loss: 0.249682 , Test acc:  0.919391\n",
      "--------------------------------------------------------------------------------\n",
      "steps 7180\n",
      "learning_rate: 0.00192448\n",
      "Training loss: 0.108059 , Training acc:  0.96916\n",
      "Test loss: 0.261655 , Test acc:  0.912063\n",
      "--------------------------------------------------------------------------------\n",
      "steps 7200\n",
      "learning_rate: 0.00190524\n",
      "Training loss: 0.101582 , Training acc:  0.975229\n",
      "Test loss: 0.252353 , Test acc:  0.916573\n",
      "--------------------------------------------------------------------------------\n",
      "steps 7220\n",
      "learning_rate: 0.00190524\n",
      "Training loss: 0.099476 , Training acc:  0.974831\n",
      "Test loss: 0.247365 , Test acc:  0.916573\n",
      "--------------------------------------------------------------------------------\n",
      "steps 7240\n",
      "learning_rate: 0.00190524\n",
      "Training loss: 0.102848 , Training acc:  0.973737\n",
      "Test loss: 0.247418 , Test acc:  0.914882\n",
      "--------------------------------------------------------------------------------\n",
      "steps 7260\n",
      "learning_rate: 0.00190524\n",
      "Training loss: 0.110823 , Training acc:  0.971448\n",
      "Test loss: 0.268536 , Test acc:  0.905299\n",
      "--------------------------------------------------------------------------------\n",
      "steps 7280\n",
      "learning_rate: 0.00188618\n",
      "Training loss: 0.119553 , Training acc:  0.966474\n",
      "Test loss: 0.27946 , Test acc:  0.901917\n",
      "--------------------------------------------------------------------------------\n",
      "steps 7300\n",
      "learning_rate: 0.00188618\n",
      "Training loss: 0.10535 , Training acc:  0.972145\n",
      "Test loss: 0.256692 , Test acc:  0.909245\n",
      "--------------------------------------------------------------------------------\n",
      "steps 7320\n",
      "learning_rate: 0.00188618\n",
      "Training loss: 0.106982 , Training acc:  0.970553\n",
      "Test loss: 0.25838 , Test acc:  0.911499\n",
      "--------------------------------------------------------------------------------\n",
      "steps 7340\n",
      "learning_rate: 0.00188618\n",
      "Training loss: 0.107658 , Training acc:  0.966574\n",
      "Test loss: 0.256869 , Test acc:  0.908117\n",
      "--------------------------------------------------------------------------------\n",
      "steps 7360\n",
      "learning_rate: 0.00186732\n",
      "Training loss: 0.097237 , Training acc:  0.974135\n",
      "Test loss: 0.241727 , Test acc:  0.916573\n",
      "--------------------------------------------------------------------------------\n",
      "steps 7380\n",
      "learning_rate: 0.00186732\n",
      "Training loss: 0.133261 , Training acc:  0.960306\n",
      "Test loss: 0.279042 , Test acc:  0.897971\n",
      "--------------------------------------------------------------------------------\n",
      "steps 7400\n",
      "learning_rate: 0.00186732\n",
      "Training loss: 0.108765 , Training acc:  0.969857\n",
      "Test loss: 0.257694 , Test acc:  0.912627\n",
      "--------------------------------------------------------------------------------\n",
      "steps 7420\n",
      "learning_rate: 0.00186732\n",
      "Training loss: 0.10543 , Training acc:  0.972344\n",
      "Test loss: 0.25411 , Test acc:  0.913191\n",
      "--------------------------------------------------------------------------------\n",
      "steps 7440\n",
      "learning_rate: 0.00184865\n",
      "Training loss: 0.101154 , Training acc:  0.97304\n",
      "Test loss: 0.247928 , Test acc:  0.914318\n",
      "--------------------------------------------------------------------------------\n",
      "steps 7460\n",
      "learning_rate: 0.00184865\n",
      "Training loss: 0.118964 , Training acc:  0.965877\n",
      "Test loss: 0.269156 , Test acc:  0.906426\n",
      "--------------------------------------------------------------------------------\n",
      "steps 7480\n",
      "learning_rate: 0.00184865\n",
      "Training loss: 0.115134 , Training acc:  0.970354\n",
      "Test loss: 0.269824 , Test acc:  0.905862\n",
      "--------------------------------------------------------------------------------\n",
      "steps 7500\n",
      "learning_rate: 0.00183016\n",
      "Training loss: 0.110013 , Training acc:  0.971051\n",
      "Test loss: 0.262215 , Test acc:  0.907554\n",
      "--------------------------------------------------------------------------------\n",
      "steps 7520\n",
      "learning_rate: 0.00183016\n",
      "Training loss: 0.105845 , Training acc:  0.972145\n",
      "Test loss: 0.265765 , Test acc:  0.90699\n",
      "--------------------------------------------------------------------------------\n",
      "steps 7540\n",
      "learning_rate: 0.00183016\n",
      "Training loss: 0.104118 , Training acc:  0.970553\n",
      "Test loss: 0.268567 , Test acc:  0.909245\n",
      "--------------------------------------------------------------------------------\n",
      "steps 7560\n",
      "learning_rate: 0.00183016\n",
      "Training loss: 0.0959677 , Training acc:  0.97503\n",
      "Test loss: 0.251577 , Test acc:  0.915445\n",
      "--------------------------------------------------------------------------------\n",
      "steps 7580\n",
      "learning_rate: 0.00181186\n",
      "Training loss: 0.0951579 , Training acc:  0.972841\n",
      "Test loss: 0.246825 , Test acc:  0.913754\n",
      "--------------------------------------------------------------------------------\n",
      "steps 7600\n",
      "learning_rate: 0.00181186\n",
      "Training loss: 0.0900843 , Training acc:  0.976423\n",
      "Test loss: 0.241036 , Test acc:  0.913754\n",
      "--------------------------------------------------------------------------------\n",
      "steps 7620\n",
      "learning_rate: 0.00181186\n",
      "Training loss: 0.0913037 , Training acc:  0.974831\n",
      "Test loss: 0.240856 , Test acc:  0.916009\n",
      "--------------------------------------------------------------------------------\n",
      "steps 7640\n",
      "learning_rate: 0.00181186\n",
      "Training loss: 0.100101 , Training acc:  0.972145\n",
      "Test loss: 0.253142 , Test acc:  0.913754\n",
      "--------------------------------------------------------------------------------\n",
      "steps 7660\n",
      "learning_rate: 0.00179374\n",
      "Training loss: 0.103122 , Training acc:  0.970653\n",
      "Test loss: 0.265277 , Test acc:  0.90699\n",
      "--------------------------------------------------------------------------------\n",
      "steps 7680\n",
      "learning_rate: 0.00179374\n",
      "Training loss: 0.0907088 , Training acc:  0.974532\n",
      "Test loss: 0.25397 , Test acc:  0.910372\n",
      "--------------------------------------------------------------------------------\n",
      "steps 7700\n",
      "learning_rate: 0.00179374\n",
      "Training loss: 0.0966237 , Training acc:  0.97304\n",
      "Test loss: 0.256865 , Test acc:  0.913191\n",
      "--------------------------------------------------------------------------------\n",
      "steps 7720\n",
      "learning_rate: 0.00179374\n",
      "Training loss: 0.105503 , Training acc:  0.97125\n",
      "Test loss: 0.265031 , Test acc:  0.914882\n",
      "--------------------------------------------------------------------------------\n",
      "steps 7740\n",
      "learning_rate: 0.00177581\n",
      "Training loss: 0.104981 , Training acc:  0.976721\n",
      "Test loss: 0.251328 , Test acc:  0.910936\n",
      "--------------------------------------------------------------------------------\n",
      "steps 7760\n",
      "learning_rate: 0.00177581\n",
      "Training loss: 0.10413 , Training acc:  0.972742\n",
      "Test loss: 0.257466 , Test acc:  0.915445\n",
      "--------------------------------------------------------------------------------\n",
      "steps 7780\n",
      "learning_rate: 0.00177581\n",
      "Training loss: 0.0969314 , Training acc:  0.977218\n",
      "Test loss: 0.245656 , Test acc:  0.912063\n",
      "--------------------------------------------------------------------------------\n",
      "steps 7800\n",
      "learning_rate: 0.00175805\n",
      "Training loss: 0.10311 , Training acc:  0.974433\n",
      "Test loss: 0.257892 , Test acc:  0.912627\n",
      "--------------------------------------------------------------------------------\n",
      "steps 7820\n",
      "learning_rate: 0.00175805\n",
      "Training loss: 0.0955631 , Training acc:  0.976025\n",
      "Test loss: 0.248753 , Test acc:  0.918264\n",
      "--------------------------------------------------------------------------------\n",
      "steps 7840\n",
      "learning_rate: 0.00175805\n",
      "Training loss: 0.102991 , Training acc:  0.969359\n",
      "Test loss: 0.259232 , Test acc:  0.913754\n",
      "--------------------------------------------------------------------------------\n",
      "steps 7860\n",
      "learning_rate: 0.00175805\n",
      "Training loss: 0.0936993 , Training acc:  0.975925\n",
      "Test loss: 0.246864 , Test acc:  0.907554\n",
      "--------------------------------------------------------------------------------\n",
      "steps 7880\n",
      "learning_rate: 0.00174047\n",
      "Training loss: 0.0881261 , Training acc:  0.977119\n",
      "Test loss: 0.238698 , Test acc:  0.918264\n",
      "--------------------------------------------------------------------------------\n",
      "steps 7900\n",
      "learning_rate: 0.00174047\n",
      "Training loss: 0.0923976 , Training acc:  0.976025\n",
      "Test loss: 0.252393 , Test acc:  0.910372\n",
      "--------------------------------------------------------------------------------\n",
      "steps 7920\n",
      "learning_rate: 0.00174047\n",
      "Training loss: 0.0843332 , Training acc:  0.978611\n",
      "Test loss: 0.243933 , Test acc:  0.912627\n",
      "--------------------------------------------------------------------------------\n",
      "steps 7940\n",
      "learning_rate: 0.00174047\n",
      "Training loss: 0.0801226 , Training acc:  0.979507\n",
      "Test loss: 0.239768 , Test acc:  0.916009\n",
      "--------------------------------------------------------------------------------\n",
      "steps 7960\n",
      "learning_rate: 0.00172306\n",
      "Training loss: 0.0933792 , Training acc:  0.973339\n",
      "Test loss: 0.266128 , Test acc:  0.903044\n",
      "--------------------------------------------------------------------------------\n",
      "steps 7980\n",
      "learning_rate: 0.00172306\n",
      "Training loss: 0.0949998 , Training acc:  0.977716\n",
      "Test loss: 0.253598 , Test acc:  0.907554\n",
      "--------------------------------------------------------------------------------\n",
      "steps 8000\n",
      "learning_rate: 0.00172306\n",
      "Training loss: 0.0939295 , Training acc:  0.975925\n",
      "Test loss: 0.246589 , Test acc:  0.909245\n",
      "--------------------------------------------------------------------------------\n",
      "steps 8020\n",
      "learning_rate: 0.00172306\n",
      "Training loss: 0.087525 , Training acc:  0.977716\n",
      "Test loss: 0.233705 , Test acc:  0.915445\n",
      "--------------------------------------------------------------------------------\n",
      "steps 8040\n",
      "learning_rate: 0.00170583\n",
      "Training loss: 0.0914733 , Training acc:  0.977815\n",
      "Test loss: 0.237781 , Test acc:  0.912627\n",
      "--------------------------------------------------------------------------------\n",
      "steps 8060\n",
      "learning_rate: 0.00170583\n",
      "Training loss: 0.0923382 , Training acc:  0.97891\n",
      "Test loss: 0.247751 , Test acc:  0.911499\n",
      "--------------------------------------------------------------------------------\n",
      "steps 8080\n",
      "learning_rate: 0.00170583\n",
      "Training loss: 0.0815905 , Training acc:  0.980103\n",
      "Test loss: 0.23291 , Test acc:  0.917136\n",
      "--------------------------------------------------------------------------------\n",
      "steps 8100\n",
      "learning_rate: 0.00168877\n",
      "Training loss: 0.0924691 , Training acc:  0.977417\n",
      "Test loss: 0.249374 , Test acc:  0.910372\n",
      "--------------------------------------------------------------------------------\n",
      "steps 8120\n",
      "learning_rate: 0.00168877\n",
      "Training loss: 0.0959659 , Training acc:  0.973538\n",
      "Test loss: 0.255444 , Test acc:  0.909808\n",
      "--------------------------------------------------------------------------------\n",
      "steps 8140\n",
      "learning_rate: 0.00168877\n",
      "Training loss: 0.103269 , Training acc:  0.971051\n",
      "Test loss: 0.262853 , Test acc:  0.908117\n",
      "--------------------------------------------------------------------------------\n",
      "steps 8160\n",
      "learning_rate: 0.00168877\n",
      "Training loss: 0.0855331 , Training acc:  0.980601\n",
      "Test loss: 0.230929 , Test acc:  0.920519\n",
      "--------------------------------------------------------------------------------\n",
      "steps 8180\n",
      "learning_rate: 0.00167189\n",
      "Training loss: 0.0873785 , Training acc:  0.980004\n",
      "Test loss: 0.240093 , Test acc:  0.922773\n",
      "--------------------------------------------------------------------------------\n",
      "steps 8200\n",
      "learning_rate: 0.00167189\n",
      "Training loss: 0.0951333 , Training acc:  0.974632\n",
      "Test loss: 0.246465 , Test acc:  0.914882\n",
      "--------------------------------------------------------------------------------\n",
      "steps 8220\n",
      "learning_rate: 0.00167189\n",
      "Training loss: 0.0838625 , Training acc:  0.979606\n",
      "Test loss: 0.234676 , Test acc:  0.920519\n",
      "--------------------------------------------------------------------------------\n",
      "steps 8240\n",
      "learning_rate: 0.00167189\n",
      "Training loss: 0.0818658 , Training acc:  0.97881\n",
      "Test loss: 0.240166 , Test acc:  0.918828\n",
      "--------------------------------------------------------------------------------\n",
      "steps 8260\n",
      "learning_rate: 0.00165517\n",
      "Training loss: 0.0772474 , Training acc:  0.981596\n",
      "Test loss: 0.238107 , Test acc:  0.925028\n",
      "--------------------------------------------------------------------------------\n",
      "steps 8280\n",
      "learning_rate: 0.00165517\n",
      "Training loss: 0.0863412 , Training acc:  0.977815\n",
      "Test loss: 0.249433 , Test acc:  0.914318\n",
      "--------------------------------------------------------------------------------\n",
      "steps 8300\n",
      "learning_rate: 0.00165517\n",
      "Training loss: 0.0865128 , Training acc:  0.97881\n",
      "Test loss: 0.246114 , Test acc:  0.914318\n",
      "--------------------------------------------------------------------------------\n",
      "steps 8320\n",
      "learning_rate: 0.00165517\n",
      "Training loss: 0.0821845 , Training acc:  0.979208\n",
      "Test loss: 0.232895 , Test acc:  0.92221\n",
      "--------------------------------------------------------------------------------\n",
      "steps 8340\n",
      "learning_rate: 0.00163862\n",
      "Training loss: 0.0793774 , Training acc:  0.980899\n",
      "Test loss: 0.231036 , Test acc:  0.919955\n",
      "--------------------------------------------------------------------------------\n",
      "steps 8360\n",
      "learning_rate: 0.00163862\n",
      "Training loss: 0.0928512 , Training acc:  0.976721\n",
      "Test loss: 0.246455 , Test acc:  0.9177\n",
      "--------------------------------------------------------------------------------\n",
      "steps 8380\n",
      "learning_rate: 0.00163862\n",
      "Training loss: 0.0882517 , Training acc:  0.979706\n",
      "Test loss: 0.233356 , Test acc:  0.9177\n",
      "--------------------------------------------------------------------------------\n",
      "steps 8400\n",
      "learning_rate: 0.00162223\n",
      "Training loss: 0.0874784 , Training acc:  0.979904\n",
      "Test loss: 0.236258 , Test acc:  0.914882\n",
      "--------------------------------------------------------------------------------\n",
      "steps 8420\n",
      "learning_rate: 0.00162223\n",
      "Training loss: 0.0875152 , Training acc:  0.979706\n",
      "Test loss: 0.235493 , Test acc:  0.914882\n",
      "--------------------------------------------------------------------------------\n",
      "steps 8440\n",
      "learning_rate: 0.00162223\n",
      "Training loss: 0.0857184 , Training acc:  0.979706\n",
      "Test loss: 0.235194 , Test acc:  0.918828\n",
      "--------------------------------------------------------------------------------\n",
      "steps 8460\n",
      "learning_rate: 0.00162223\n",
      "Training loss: 0.0919453 , Training acc:  0.974135\n",
      "Test loss: 0.260112 , Test acc:  0.909808\n",
      "--------------------------------------------------------------------------------\n",
      "steps 8480\n",
      "learning_rate: 0.00160601\n",
      "Training loss: 0.0855572 , Training acc:  0.976721\n",
      "Test loss: 0.243821 , Test acc:  0.917136\n",
      "--------------------------------------------------------------------------------\n",
      "steps 8500\n",
      "learning_rate: 0.00160601\n",
      "Training loss: 0.0803552 , Training acc:  0.980203\n",
      "Test loss: 0.232522 , Test acc:  0.920519\n",
      "--------------------------------------------------------------------------------\n",
      "steps 8520\n",
      "learning_rate: 0.00160601\n",
      "Training loss: 0.0877814 , Training acc:  0.977616\n",
      "Test loss: 0.244581 , Test acc:  0.921646\n",
      "--------------------------------------------------------------------------------\n",
      "steps 8540\n",
      "learning_rate: 0.00160601\n",
      "Training loss: 0.0882665 , Training acc:  0.976622\n",
      "Test loss: 0.248757 , Test acc:  0.916009\n",
      "--------------------------------------------------------------------------------\n",
      "steps 8560\n",
      "learning_rate: 0.00158995\n",
      "Training loss: 0.0768377 , Training acc:  0.980103\n",
      "Test loss: 0.230428 , Test acc:  0.923901\n",
      "--------------------------------------------------------------------------------\n",
      "steps 8580\n",
      "learning_rate: 0.00158995\n",
      "Training loss: 0.0771904 , Training acc:  0.979507\n",
      "Test loss: 0.232857 , Test acc:  0.9177\n",
      "--------------------------------------------------------------------------------\n",
      "steps 8600\n",
      "learning_rate: 0.00158995\n",
      "Training loss: 0.0832485 , Training acc:  0.978611\n",
      "Test loss: 0.236793 , Test acc:  0.919391\n",
      "--------------------------------------------------------------------------------\n",
      "steps 8620\n",
      "learning_rate: 0.00158995\n",
      "Training loss: 0.0844355 , Training acc:  0.981397\n",
      "Test loss: 0.230016 , Test acc:  0.917136\n",
      "--------------------------------------------------------------------------------\n",
      "steps 8640\n",
      "learning_rate: 0.00157405\n",
      "Training loss: 0.0853012 , Training acc:  0.980999\n",
      "Test loss: 0.235128 , Test acc:  0.918264\n",
      "--------------------------------------------------------------------------------\n",
      "steps 8660\n",
      "learning_rate: 0.00157405\n",
      "Training loss: 0.0850093 , Training acc:  0.9808\n",
      "Test loss: 0.235003 , Test acc:  0.915445\n",
      "--------------------------------------------------------------------------------\n",
      "steps 8680\n",
      "learning_rate: 0.00157405\n",
      "Training loss: 0.0860075 , Training acc:  0.980203\n",
      "Test loss: 0.242993 , Test acc:  0.916009\n",
      "--------------------------------------------------------------------------------\n",
      "steps 8700\n",
      "learning_rate: 0.00155831\n",
      "Training loss: 0.0830767 , Training acc:  0.981496\n",
      "Test loss: 0.238759 , Test acc:  0.918264\n",
      "--------------------------------------------------------------------------------\n",
      "steps 8720\n",
      "learning_rate: 0.00155831\n",
      "Training loss: 0.0785376 , Training acc:  0.981695\n",
      "Test loss: 0.235746 , Test acc:  0.917136\n",
      "--------------------------------------------------------------------------------\n",
      "steps 8740\n",
      "learning_rate: 0.00155831\n",
      "Training loss: 0.0982333 , Training acc:  0.970553\n",
      "Test loss: 0.260605 , Test acc:  0.913191\n",
      "--------------------------------------------------------------------------------\n",
      "steps 8760\n",
      "learning_rate: 0.00155831\n",
      "Training loss: 0.081967 , Training acc:  0.9808\n",
      "Test loss: 0.23279 , Test acc:  0.918264\n",
      "--------------------------------------------------------------------------------\n",
      "steps 8780\n",
      "learning_rate: 0.00154272\n",
      "Training loss: 0.0851723 , Training acc:  0.980203\n",
      "Test loss: 0.235829 , Test acc:  0.918264\n",
      "--------------------------------------------------------------------------------\n",
      "steps 8800\n",
      "learning_rate: 0.00154272\n",
      "Training loss: 0.0875802 , Training acc:  0.979208\n",
      "Test loss: 0.241854 , Test acc:  0.920519\n",
      "--------------------------------------------------------------------------------\n",
      "steps 8820\n",
      "learning_rate: 0.00154272\n",
      "Training loss: 0.0810759 , Training acc:  0.981496\n",
      "Test loss: 0.239012 , Test acc:  0.914882\n",
      "--------------------------------------------------------------------------------\n",
      "steps 8840\n",
      "learning_rate: 0.00154272\n",
      "Training loss: 0.0840051 , Training acc:  0.980899\n",
      "Test loss: 0.24231 , Test acc:  0.916009\n",
      "--------------------------------------------------------------------------------\n",
      "steps 8860\n",
      "learning_rate: 0.0015273\n",
      "Training loss: 0.0796763 , Training acc:  0.981198\n",
      "Test loss: 0.236598 , Test acc:  0.922773\n",
      "--------------------------------------------------------------------------------\n",
      "steps 8880\n",
      "learning_rate: 0.0015273\n",
      "Training loss: 0.0804729 , Training acc:  0.98279\n",
      "Test loss: 0.227594 , Test acc:  0.924464\n",
      "--------------------------------------------------------------------------------\n",
      "steps 8900\n",
      "learning_rate: 0.0015273\n",
      "Training loss: 0.0807936 , Training acc:  0.980899\n",
      "Test loss: 0.233933 , Test acc:  0.923901\n",
      "--------------------------------------------------------------------------------\n",
      "steps 8920\n",
      "learning_rate: 0.0015273\n",
      "Training loss: 0.0810892 , Training acc:  0.980899\n",
      "Test loss: 0.238101 , Test acc:  0.917136\n",
      "--------------------------------------------------------------------------------\n",
      "steps 8940\n",
      "learning_rate: 0.00151202\n",
      "Training loss: 0.0803661 , Training acc:  0.981098\n",
      "Test loss: 0.241382 , Test acc:  0.914318\n",
      "--------------------------------------------------------------------------------\n",
      "steps 8960\n",
      "learning_rate: 0.00151202\n",
      "Training loss: 0.0849579 , Training acc:  0.975925\n",
      "Test loss: 0.240729 , Test acc:  0.916573\n",
      "--------------------------------------------------------------------------------\n",
      "steps 8980\n",
      "learning_rate: 0.00151202\n",
      "Training loss: 0.0791048 , Training acc:  0.981596\n",
      "Test loss: 0.236597 , Test acc:  0.921646\n",
      "--------------------------------------------------------------------------------\n",
      "steps 9000\n",
      "learning_rate: 0.0014969\n",
      "Training loss: 0.0814665 , Training acc:  0.981297\n",
      "Test loss: 0.241562 , Test acc:  0.919391\n",
      "--------------------------------------------------------------------------------\n",
      "steps 9020\n",
      "learning_rate: 0.0014969\n",
      "Training loss: 0.0722388 , Training acc:  0.983486\n",
      "Test loss: 0.233128 , Test acc:  0.920519\n",
      "--------------------------------------------------------------------------------\n",
      "steps 9040\n",
      "learning_rate: 0.0014969\n",
      "Training loss: 0.0786743 , Training acc:  0.981297\n",
      "Test loss: 0.241788 , Test acc:  0.914882\n",
      "--------------------------------------------------------------------------------\n",
      "steps 9060\n",
      "learning_rate: 0.0014969\n",
      "Training loss: 0.079888 , Training acc:  0.980103\n",
      "Test loss: 0.24334 , Test acc:  0.915445\n",
      "--------------------------------------------------------------------------------\n",
      "steps 9080\n",
      "learning_rate: 0.00148193\n",
      "Training loss: 0.0709438 , Training acc:  0.98279\n",
      "Test loss: 0.235989 , Test acc:  0.9177\n",
      "--------------------------------------------------------------------------------\n",
      "steps 9100\n",
      "learning_rate: 0.00148193\n",
      "Training loss: 0.0712737 , Training acc:  0.983685\n",
      "Test loss: 0.235296 , Test acc:  0.918828\n",
      "--------------------------------------------------------------------------------\n",
      "steps 9120\n",
      "learning_rate: 0.00148193\n",
      "Training loss: 0.072581 , Training acc:  0.983088\n",
      "Test loss: 0.234218 , Test acc:  0.919391\n",
      "--------------------------------------------------------------------------------\n",
      "steps 9140\n",
      "learning_rate: 0.00148193\n",
      "Training loss: 0.0747175 , Training acc:  0.983884\n",
      "Test loss: 0.231282 , Test acc:  0.919391\n",
      "--------------------------------------------------------------------------------\n",
      "steps 9160\n",
      "learning_rate: 0.00146712\n",
      "Training loss: 0.0731363 , Training acc:  0.984083\n",
      "Test loss: 0.230778 , Test acc:  0.92221\n",
      "--------------------------------------------------------------------------------\n",
      "steps 9180\n",
      "learning_rate: 0.00146712\n",
      "Training loss: 0.0770614 , Training acc:  0.981894\n",
      "Test loss: 0.238998 , Test acc:  0.919955\n",
      "--------------------------------------------------------------------------------\n",
      "steps 9200\n",
      "learning_rate: 0.00146712\n",
      "Training loss: 0.0733334 , Training acc:  0.983486\n",
      "Test loss: 0.231918 , Test acc:  0.9177\n",
      "--------------------------------------------------------------------------------\n",
      "steps 9220\n",
      "learning_rate: 0.00146712\n",
      "Training loss: 0.0712429 , Training acc:  0.984978\n",
      "Test loss: 0.233279 , Test acc:  0.918264\n",
      "--------------------------------------------------------------------------------\n",
      "steps 9240\n",
      "learning_rate: 0.00145244\n",
      "Training loss: 0.0734874 , Training acc:  0.982093\n",
      "Test loss: 0.24312 , Test acc:  0.916573\n",
      "--------------------------------------------------------------------------------\n",
      "steps 9260\n",
      "learning_rate: 0.00145244\n",
      "Training loss: 0.0713142 , Training acc:  0.982292\n",
      "Test loss: 0.242092 , Test acc:  0.918828\n",
      "--------------------------------------------------------------------------------\n",
      "steps 9280\n",
      "learning_rate: 0.00145244\n",
      "Training loss: 0.0755925 , Training acc:  0.980999\n",
      "Test loss: 0.240271 , Test acc:  0.920519\n",
      "--------------------------------------------------------------------------------\n",
      "steps 9300\n",
      "learning_rate: 0.00143792\n",
      "Training loss: 0.0720568 , Training acc:  0.982292\n",
      "Test loss: 0.240883 , Test acc:  0.9177\n",
      "--------------------------------------------------------------------------------\n",
      "steps 9320\n",
      "learning_rate: 0.00143792\n",
      "Training loss: 0.0673789 , Training acc:  0.984978\n",
      "Test loss: 0.227955 , Test acc:  0.919391\n",
      "--------------------------------------------------------------------------------\n",
      "steps 9340\n",
      "learning_rate: 0.00143792\n",
      "Training loss: 0.0688127 , Training acc:  0.98468\n",
      "Test loss: 0.229743 , Test acc:  0.923901\n",
      "--------------------------------------------------------------------------------\n",
      "steps 9360\n",
      "learning_rate: 0.00143792\n",
      "Training loss: 0.0699557 , Training acc:  0.984182\n",
      "Test loss: 0.235061 , Test acc:  0.919955\n",
      "--------------------------------------------------------------------------------\n",
      "steps 9380\n",
      "learning_rate: 0.00142354\n",
      "Training loss: 0.0671168 , Training acc:  0.985277\n",
      "Test loss: 0.225583 , Test acc:  0.927283\n",
      "--------------------------------------------------------------------------------\n",
      "steps 9400\n",
      "learning_rate: 0.00142354\n",
      "Training loss: 0.0717215 , Training acc:  0.985277\n",
      "Test loss: 0.233796 , Test acc:  0.921646\n",
      "--------------------------------------------------------------------------------\n",
      "steps 9420\n",
      "learning_rate: 0.00142354\n",
      "Training loss: 0.0763854 , Training acc:  0.982988\n",
      "Test loss: 0.230251 , Test acc:  0.922773\n",
      "--------------------------------------------------------------------------------\n",
      "steps 9440\n",
      "learning_rate: 0.00142354\n",
      "Training loss: 0.0744999 , Training acc:  0.98458\n",
      "Test loss: 0.22897 , Test acc:  0.919955\n",
      "--------------------------------------------------------------------------------\n",
      "steps 9460\n",
      "learning_rate: 0.00140931\n",
      "Training loss: 0.0775473 , Training acc:  0.983585\n",
      "Test loss: 0.236444 , Test acc:  0.919955\n",
      "--------------------------------------------------------------------------------\n",
      "steps 9480\n",
      "learning_rate: 0.00140931\n",
      "Training loss: 0.0787246 , Training acc:  0.982889\n",
      "Test loss: 0.242565 , Test acc:  0.916573\n",
      "--------------------------------------------------------------------------------\n",
      "steps 9500\n",
      "learning_rate: 0.00140931\n",
      "Training loss: 0.0784847 , Training acc:  0.981198\n",
      "Test loss: 0.243496 , Test acc:  0.916009\n",
      "--------------------------------------------------------------------------------\n",
      "steps 9520\n",
      "learning_rate: 0.00140931\n",
      "Training loss: 0.0713766 , Training acc:  0.985873\n",
      "Test loss: 0.221875 , Test acc:  0.924464\n",
      "--------------------------------------------------------------------------------\n",
      "steps 9540\n",
      "learning_rate: 0.00139521\n",
      "Training loss: 0.07245 , Training acc:  0.984779\n",
      "Test loss: 0.231283 , Test acc:  0.922773\n",
      "--------------------------------------------------------------------------------\n",
      "steps 9560\n",
      "learning_rate: 0.00139521\n",
      "Training loss: 0.0719155 , Training acc:  0.983386\n",
      "Test loss: 0.229872 , Test acc:  0.918264\n",
      "--------------------------------------------------------------------------------\n",
      "steps 9580\n",
      "learning_rate: 0.00139521\n",
      "Training loss: 0.0696948 , Training acc:  0.984481\n",
      "Test loss: 0.231131 , Test acc:  0.919955\n",
      "--------------------------------------------------------------------------------\n",
      "steps 9600\n",
      "learning_rate: 0.00138126\n",
      "Training loss: 0.0686349 , Training acc:  0.984879\n",
      "Test loss: 0.232141 , Test acc:  0.921646\n",
      "--------------------------------------------------------------------------------\n",
      "steps 9620\n",
      "learning_rate: 0.00138126\n",
      "Training loss: 0.0694498 , Training acc:  0.983784\n",
      "Test loss: 0.236729 , Test acc:  0.919955\n",
      "--------------------------------------------------------------------------------\n",
      "steps 9640\n",
      "learning_rate: 0.00138126\n",
      "Training loss: 0.0739416 , Training acc:  0.983386\n",
      "Test loss: 0.233883 , Test acc:  0.922773\n",
      "--------------------------------------------------------------------------------\n",
      "steps 9660\n",
      "learning_rate: 0.00138126\n",
      "Training loss: 0.0678215 , Training acc:  0.984779\n",
      "Test loss: 0.226858 , Test acc:  0.921646\n",
      "--------------------------------------------------------------------------------\n",
      "steps 9680\n",
      "learning_rate: 0.00136745\n",
      "Training loss: 0.0698068 , Training acc:  0.983287\n",
      "Test loss: 0.235312 , Test acc:  0.915445\n",
      "--------------------------------------------------------------------------------\n",
      "steps 9700\n",
      "learning_rate: 0.00136745\n",
      "Training loss: 0.0737853 , Training acc:  0.981098\n",
      "Test loss: 0.236562 , Test acc:  0.919955\n",
      "--------------------------------------------------------------------------------\n",
      "steps 9720\n",
      "learning_rate: 0.00136745\n",
      "Training loss: 0.0757936 , Training acc:  0.981695\n",
      "Test loss: 0.236181 , Test acc:  0.921082\n",
      "--------------------------------------------------------------------------------\n",
      "steps 9740\n",
      "learning_rate: 0.00136745\n",
      "Training loss: 0.0703823 , Training acc:  0.985973\n",
      "Test loss: 0.225089 , Test acc:  0.921646\n",
      "--------------------------------------------------------------------------------\n",
      "steps 9760\n",
      "learning_rate: 0.00135377\n",
      "Training loss: 0.078485 , Training acc:  0.983187\n",
      "Test loss: 0.2368 , Test acc:  0.9177\n",
      "--------------------------------------------------------------------------------\n",
      "steps 9780\n",
      "learning_rate: 0.00135377\n",
      "Training loss: 0.0733496 , Training acc:  0.985078\n",
      "Test loss: 0.226921 , Test acc:  0.921082\n",
      "--------------------------------------------------------------------------------\n",
      "steps 9800\n",
      "learning_rate: 0.00135377\n",
      "Training loss: 0.0732747 , Training acc:  0.984083\n",
      "Test loss: 0.23377 , Test acc:  0.919955\n",
      "--------------------------------------------------------------------------------\n",
      "steps 9820\n",
      "learning_rate: 0.00135377\n",
      "Training loss: 0.0711891 , Training acc:  0.983088\n",
      "Test loss: 0.235741 , Test acc:  0.921082\n",
      "--------------------------------------------------------------------------------\n",
      "steps 9840\n",
      "learning_rate: 0.00134024\n",
      "Training loss: 0.0637174 , Training acc:  0.98657\n",
      "Test loss: 0.230698 , Test acc:  0.921082\n",
      "--------------------------------------------------------------------------------\n",
      "steps 9860\n",
      "learning_rate: 0.00134024\n",
      "Training loss: 0.0667842 , Training acc:  0.985376\n",
      "Test loss: 0.23412 , Test acc:  0.9177\n",
      "--------------------------------------------------------------------------------\n",
      "steps 9880\n",
      "learning_rate: 0.00134024\n",
      "Training loss: 0.0777955 , Training acc:  0.981297\n",
      "Test loss: 0.249807 , Test acc:  0.915445\n",
      "--------------------------------------------------------------------------------\n",
      "steps 9900\n",
      "learning_rate: 0.00132683\n",
      "Training loss: 0.0672712 , Training acc:  0.985376\n",
      "Test loss: 0.235412 , Test acc:  0.919391\n",
      "--------------------------------------------------------------------------------\n",
      "steps 9920\n",
      "learning_rate: 0.00132683\n",
      "Training loss: 0.0696765 , Training acc:  0.983784\n",
      "Test loss: 0.237978 , Test acc:  0.918828\n",
      "--------------------------------------------------------------------------------\n",
      "steps 9940\n",
      "learning_rate: 0.00132683\n",
      "Training loss: 0.0636461 , Training acc:  0.986371\n",
      "Test loss: 0.224577 , Test acc:  0.925592\n",
      "--------------------------------------------------------------------------------\n",
      "steps 9960\n",
      "learning_rate: 0.00132683\n",
      "Training loss: 0.0640187 , Training acc:  0.987366\n",
      "Test loss: 0.226572 , Test acc:  0.921082\n",
      "--------------------------------------------------------------------------------\n",
      "steps 9980\n",
      "learning_rate: 0.00131356\n",
      "Training loss: 0.0596187 , Training acc:  0.987664\n",
      "Test loss: 0.217885 , Test acc:  0.926156\n",
      "--------------------------------------------------------------------------------\n",
      "steps 10000\n",
      "learning_rate: 0.00131356\n",
      "Training loss: 0.0637994 , Training acc:  0.986968\n",
      "Test loss: 0.226322 , Test acc:  0.923337\n",
      "--------------------------------------------------------------------------------\n",
      "steps 10020\n",
      "learning_rate: 0.00131356\n",
      "Training loss: 0.0648331 , Training acc:  0.987266\n",
      "Test loss: 0.231197 , Test acc:  0.919391\n",
      "--------------------------------------------------------------------------------\n",
      "steps 10040\n",
      "learning_rate: 0.00131356\n",
      "Training loss: 0.0596058 , Training acc:  0.988162\n",
      "Test loss: 0.219832 , Test acc:  0.926719\n",
      "--------------------------------------------------------------------------------\n",
      "steps 10060\n",
      "learning_rate: 0.00130043\n",
      "Training loss: 0.0629285 , Training acc:  0.986769\n",
      "Test loss: 0.223398 , Test acc:  0.919955\n",
      "--------------------------------------------------------------------------------\n",
      "steps 10080\n",
      "learning_rate: 0.00130043\n",
      "Training loss: 0.0616535 , Training acc:  0.986968\n",
      "Test loss: 0.225101 , Test acc:  0.920519\n",
      "--------------------------------------------------------------------------------\n",
      "steps 10100\n",
      "learning_rate: 0.00130043\n",
      "Training loss: 0.0650331 , Training acc:  0.985177\n",
      "Test loss: 0.228654 , Test acc:  0.923901\n",
      "--------------------------------------------------------------------------------\n",
      "steps 10120\n",
      "learning_rate: 0.00130043\n",
      "Training loss: 0.0589362 , Training acc:  0.988162\n",
      "Test loss: 0.22221 , Test acc:  0.926156\n",
      "--------------------------------------------------------------------------------\n",
      "steps 10140\n",
      "learning_rate: 0.00128742\n",
      "Training loss: 0.0606361 , Training acc:  0.987266\n",
      "Test loss: 0.227813 , Test acc:  0.926719\n",
      "--------------------------------------------------------------------------------\n",
      "steps 10160\n",
      "learning_rate: 0.00128742\n",
      "Training loss: 0.0560166 , Training acc:  0.988261\n",
      "Test loss: 0.222245 , Test acc:  0.925028\n",
      "--------------------------------------------------------------------------------\n",
      "steps 10180\n",
      "learning_rate: 0.00128742\n",
      "Training loss: 0.0590261 , Training acc:  0.987863\n",
      "Test loss: 0.224177 , Test acc:  0.919391\n",
      "--------------------------------------------------------------------------------\n",
      "steps 10200\n",
      "learning_rate: 0.00127455\n",
      "Training loss: 0.0622785 , Training acc:  0.986868\n",
      "Test loss: 0.237403 , Test acc:  0.9177\n",
      "--------------------------------------------------------------------------------\n",
      "steps 10220\n",
      "learning_rate: 0.00127455\n",
      "Training loss: 0.0579388 , Training acc:  0.986868\n",
      "Test loss: 0.224442 , Test acc:  0.923901\n",
      "--------------------------------------------------------------------------------\n",
      "steps 10240\n",
      "learning_rate: 0.00127455\n",
      "Training loss: 0.0582676 , Training acc:  0.988361\n",
      "Test loss: 0.224915 , Test acc:  0.921646\n",
      "--------------------------------------------------------------------------------\n",
      "steps 10260\n",
      "learning_rate: 0.00127455\n",
      "Training loss: 0.0642777 , Training acc:  0.985774\n",
      "Test loss: 0.235255 , Test acc:  0.919955\n",
      "--------------------------------------------------------------------------------\n",
      "steps 10280\n",
      "learning_rate: 0.0012618\n",
      "Training loss: 0.0599615 , Training acc:  0.986072\n",
      "Test loss: 0.226994 , Test acc:  0.921646\n",
      "--------------------------------------------------------------------------------\n",
      "steps 10300\n",
      "learning_rate: 0.0012618\n",
      "Training loss: 0.0566037 , Training acc:  0.987167\n",
      "Test loss: 0.226291 , Test acc:  0.920519\n",
      "--------------------------------------------------------------------------------\n",
      "steps 10320\n",
      "learning_rate: 0.0012618\n",
      "Training loss: 0.0659673 , Training acc:  0.983287\n",
      "Test loss: 0.2374 , Test acc:  0.920519\n",
      "--------------------------------------------------------------------------------\n",
      "steps 10340\n",
      "learning_rate: 0.0012618\n",
      "Training loss: 0.05825 , Training acc:  0.987366\n",
      "Test loss: 0.223149 , Test acc:  0.923901\n",
      "--------------------------------------------------------------------------------\n",
      "steps 10360\n",
      "learning_rate: 0.00124919\n",
      "Training loss: 0.0595867 , Training acc:  0.986968\n",
      "Test loss: 0.218349 , Test acc:  0.923901\n",
      "--------------------------------------------------------------------------------\n",
      "steps 10380\n",
      "learning_rate: 0.00124919\n",
      "Training loss: 0.0604743 , Training acc:  0.988261\n",
      "Test loss: 0.22226 , Test acc:  0.924464\n",
      "--------------------------------------------------------------------------------\n",
      "steps 10400\n",
      "learning_rate: 0.00124919\n",
      "Training loss: 0.0549625 , Training acc:  0.989256\n",
      "Test loss: 0.219281 , Test acc:  0.923337\n",
      "--------------------------------------------------------------------------------\n",
      "steps 10420\n",
      "learning_rate: 0.00124919\n",
      "Training loss: 0.0681323 , Training acc:  0.983386\n",
      "Test loss: 0.247543 , Test acc:  0.915445\n",
      "--------------------------------------------------------------------------------\n",
      "steps 10440\n",
      "learning_rate: 0.00123669\n",
      "Training loss: 0.0567866 , Training acc:  0.989156\n",
      "Test loss: 0.220363 , Test acc:  0.922773\n",
      "--------------------------------------------------------------------------------\n",
      "steps 10460\n",
      "learning_rate: 0.00123669\n",
      "Training loss: 0.0526853 , Training acc:  0.989256\n",
      "Test loss: 0.218751 , Test acc:  0.923901\n",
      "--------------------------------------------------------------------------------\n",
      "steps 10480\n",
      "learning_rate: 0.00123669\n",
      "Training loss: 0.0542018 , Training acc:  0.988957\n",
      "Test loss: 0.22463 , Test acc:  0.920519\n",
      "--------------------------------------------------------------------------------\n",
      "steps 10500\n",
      "learning_rate: 0.00122433\n",
      "Training loss: 0.0562741 , Training acc:  0.987366\n",
      "Test loss: 0.217819 , Test acc:  0.923337\n",
      "--------------------------------------------------------------------------------\n",
      "steps 10520\n",
      "learning_rate: 0.00122433\n",
      "Training loss: 0.0595189 , Training acc:  0.986172\n",
      "Test loss: 0.224008 , Test acc:  0.92221\n",
      "--------------------------------------------------------------------------------\n",
      "steps 10540\n",
      "learning_rate: 0.00122433\n",
      "Training loss: 0.0649648 , Training acc:  0.985973\n",
      "Test loss: 0.232123 , Test acc:  0.921646\n",
      "--------------------------------------------------------------------------------\n",
      "steps 10560\n",
      "learning_rate: 0.00122433\n",
      "Training loss: 0.0585089 , Training acc:  0.988957\n",
      "Test loss: 0.217717 , Test acc:  0.925592\n",
      "--------------------------------------------------------------------------------\n",
      "steps 10580\n",
      "learning_rate: 0.00121208\n",
      "Training loss: 0.060659 , Training acc:  0.987067\n",
      "Test loss: 0.227861 , Test acc:  0.919955\n",
      "--------------------------------------------------------------------------------\n",
      "steps 10600\n",
      "learning_rate: 0.00121208\n",
      "Training loss: 0.0602487 , Training acc:  0.986769\n",
      "Test loss: 0.221912 , Test acc:  0.921082\n",
      "--------------------------------------------------------------------------------\n",
      "steps 10620\n",
      "learning_rate: 0.00121208\n",
      "Training loss: 0.0666541 , Training acc:  0.985873\n",
      "Test loss: 0.231431 , Test acc:  0.920519\n",
      "--------------------------------------------------------------------------------\n",
      "steps 10640\n",
      "learning_rate: 0.00121208\n",
      "Training loss: 0.058159 , Training acc:  0.989753\n",
      "Test loss: 0.214389 , Test acc:  0.926719\n",
      "--------------------------------------------------------------------------------\n",
      "steps 10660\n",
      "learning_rate: 0.00119996\n",
      "Training loss: 0.058408 , Training acc:  0.988758\n",
      "Test loss: 0.217334 , Test acc:  0.929538\n",
      "--------------------------------------------------------------------------------\n",
      "steps 10680\n",
      "learning_rate: 0.00119996\n",
      "Training loss: 0.055383 , Training acc:  0.987863\n",
      "Test loss: 0.215754 , Test acc:  0.926156\n",
      "--------------------------------------------------------------------------------\n",
      "steps 10700\n",
      "learning_rate: 0.00119996\n",
      "Training loss: 0.0572973 , Training acc:  0.986868\n",
      "Test loss: 0.226831 , Test acc:  0.921082\n",
      "--------------------------------------------------------------------------------\n",
      "steps 10720\n",
      "learning_rate: 0.00119996\n",
      "Training loss: 0.0556488 , Training acc:  0.988361\n",
      "Test loss: 0.224884 , Test acc:  0.920519\n",
      "--------------------------------------------------------------------------------\n",
      "steps 10740\n",
      "learning_rate: 0.00118796\n",
      "Training loss: 0.058067 , Training acc:  0.988758\n",
      "Test loss: 0.232263 , Test acc:  0.917136\n",
      "--------------------------------------------------------------------------------\n",
      "steps 10760\n",
      "learning_rate: 0.00118796\n",
      "Training loss: 0.0520432 , Training acc:  0.989455\n",
      "Test loss: 0.222247 , Test acc:  0.922773\n",
      "--------------------------------------------------------------------------------\n",
      "steps 10780\n",
      "learning_rate: 0.00118796\n",
      "Training loss: 0.0690058 , Training acc:  0.985177\n",
      "Test loss: 0.259098 , Test acc:  0.913754\n",
      "--------------------------------------------------------------------------------\n",
      "steps 10800\n",
      "learning_rate: 0.00117608\n",
      "Training loss: 0.0598044 , Training acc:  0.986868\n",
      "Test loss: 0.230477 , Test acc:  0.915445\n",
      "--------------------------------------------------------------------------------\n",
      "steps 10820\n",
      "learning_rate: 0.00117608\n",
      "Training loss: 0.0555553 , Training acc:  0.988858\n",
      "Test loss: 0.221104 , Test acc:  0.920519\n",
      "--------------------------------------------------------------------------------\n",
      "steps 10840\n",
      "learning_rate: 0.00117608\n",
      "Training loss: 0.0561777 , Training acc:  0.988758\n",
      "Test loss: 0.224919 , Test acc:  0.924464\n",
      "--------------------------------------------------------------------------------\n",
      "steps 10860\n",
      "learning_rate: 0.00117608\n",
      "Training loss: 0.0572419 , Training acc:  0.98846\n",
      "Test loss: 0.227083 , Test acc:  0.92221\n",
      "--------------------------------------------------------------------------------\n",
      "steps 10880\n",
      "learning_rate: 0.00116432\n",
      "Training loss: 0.0529452 , Training acc:  0.989355\n",
      "Test loss: 0.224225 , Test acc:  0.923337\n",
      "--------------------------------------------------------------------------------\n",
      "steps 10900\n",
      "learning_rate: 0.00116432\n",
      "Training loss: 0.0530129 , Training acc:  0.987067\n",
      "Test loss: 0.227476 , Test acc:  0.925028\n",
      "--------------------------------------------------------------------------------\n",
      "steps 10920\n",
      "learning_rate: 0.00116432\n",
      "Training loss: 0.0498744 , Training acc:  0.989256\n",
      "Test loss: 0.224069 , Test acc:  0.921646\n",
      "--------------------------------------------------------------------------------\n",
      "steps 10940\n",
      "learning_rate: 0.00116432\n",
      "Training loss: 0.0541924 , Training acc:  0.987764\n",
      "Test loss: 0.233205 , Test acc:  0.917136\n",
      "--------------------------------------------------------------------------------\n",
      "steps 10960\n",
      "learning_rate: 0.00115268\n",
      "Training loss: 0.0544582 , Training acc:  0.988659\n",
      "Test loss: 0.226498 , Test acc:  0.919391\n",
      "--------------------------------------------------------------------------------\n",
      "steps 10980\n",
      "learning_rate: 0.00115268\n",
      "Training loss: 0.055692 , Training acc:  0.989853\n",
      "Test loss: 0.222687 , Test acc:  0.917136\n",
      "--------------------------------------------------------------------------------\n",
      "steps 11000\n",
      "learning_rate: 0.00115268\n",
      "Training loss: 0.0594787 , Training acc:  0.987963\n",
      "Test loss: 0.229595 , Test acc:  0.921646\n",
      "--------------------------------------------------------------------------------\n",
      "steps 11020\n",
      "learning_rate: 0.00115268\n",
      "Training loss: 0.0579436 , Training acc:  0.989057\n",
      "Test loss: 0.226645 , Test acc:  0.919955\n",
      "--------------------------------------------------------------------------------\n",
      "steps 11040\n",
      "learning_rate: 0.00114115\n",
      "Training loss: 0.0628101 , Training acc:  0.988659\n",
      "Test loss: 0.226253 , Test acc:  0.921082\n",
      "--------------------------------------------------------------------------------\n",
      "steps 11060\n",
      "learning_rate: 0.00114115\n",
      "Training loss: 0.0624927 , Training acc:  0.988858\n",
      "Test loss: 0.223886 , Test acc:  0.922773\n",
      "--------------------------------------------------------------------------------\n",
      "steps 11080\n",
      "learning_rate: 0.00114115\n",
      "Training loss: 0.0609117 , Training acc:  0.988858\n",
      "Test loss: 0.221772 , Test acc:  0.923901\n",
      "--------------------------------------------------------------------------------\n",
      "steps 11100\n",
      "learning_rate: 0.00112974\n",
      "Training loss: 0.0560636 , Training acc:  0.990549\n",
      "Test loss: 0.217307 , Test acc:  0.927847\n",
      "--------------------------------------------------------------------------------\n",
      "steps 11120\n",
      "learning_rate: 0.00112974\n",
      "Training loss: 0.0557719 , Training acc:  0.99035\n",
      "Test loss: 0.223172 , Test acc:  0.923337\n",
      "--------------------------------------------------------------------------------\n",
      "steps 11140\n",
      "learning_rate: 0.00112974\n",
      "Training loss: 0.0556165 , Training acc:  0.989753\n",
      "Test loss: 0.223833 , Test acc:  0.921082\n",
      "--------------------------------------------------------------------------------\n",
      "steps 11160\n",
      "learning_rate: 0.00112974\n",
      "Training loss: 0.0538188 , Training acc:  0.990947\n",
      "Test loss: 0.221662 , Test acc:  0.923337\n",
      "--------------------------------------------------------------------------------\n",
      "steps 11180\n",
      "learning_rate: 0.00111844\n",
      "Training loss: 0.0548257 , Training acc:  0.990748\n",
      "Test loss: 0.228594 , Test acc:  0.919955\n",
      "--------------------------------------------------------------------------------\n",
      "steps 11200\n",
      "learning_rate: 0.00111844\n",
      "Training loss: 0.0520529 , Training acc:  0.990649\n",
      "Test loss: 0.224955 , Test acc:  0.923901\n",
      "--------------------------------------------------------------------------------\n",
      "steps 11220\n",
      "learning_rate: 0.00111844\n",
      "Training loss: 0.0571406 , Training acc:  0.989256\n",
      "Test loss: 0.232729 , Test acc:  0.919955\n",
      "--------------------------------------------------------------------------------\n",
      "steps 11240\n",
      "learning_rate: 0.00111844\n",
      "Training loss: 0.0533871 , Training acc:  0.989256\n",
      "Test loss: 0.23534 , Test acc:  0.917136\n",
      "--------------------------------------------------------------------------------\n",
      "steps 11260\n",
      "learning_rate: 0.00110726\n",
      "Training loss: 0.053811 , Training acc:  0.989355\n",
      "Test loss: 0.229756 , Test acc:  0.920519\n",
      "--------------------------------------------------------------------------------\n",
      "steps 11280\n",
      "learning_rate: 0.00110726\n",
      "Training loss: 0.0677968 , Training acc:  0.98468\n",
      "Test loss: 0.253418 , Test acc:  0.917136\n",
      "--------------------------------------------------------------------------------\n",
      "steps 11300\n",
      "learning_rate: 0.00110726\n",
      "Training loss: 0.0591509 , Training acc:  0.988858\n",
      "Test loss: 0.229504 , Test acc:  0.919391\n",
      "--------------------------------------------------------------------------------\n",
      "steps 11320\n",
      "learning_rate: 0.00110726\n",
      "Training loss: 0.058986 , Training acc:  0.988758\n",
      "Test loss: 0.230352 , Test acc:  0.919955\n",
      "--------------------------------------------------------------------------------\n",
      "steps 11340\n",
      "learning_rate: 0.00109619\n",
      "Training loss: 0.0523883 , Training acc:  0.989156\n",
      "Test loss: 0.221512 , Test acc:  0.926156\n",
      "--------------------------------------------------------------------------------\n",
      "steps 11360\n",
      "learning_rate: 0.00109619\n",
      "Training loss: 0.0570132 , Training acc:  0.987465\n",
      "Test loss: 0.223843 , Test acc:  0.925028\n",
      "--------------------------------------------------------------------------------\n",
      "steps 11380\n",
      "learning_rate: 0.00109619\n",
      "Training loss: 0.0576809 , Training acc:  0.988758\n",
      "Test loss: 0.229355 , Test acc:  0.920519\n",
      "--------------------------------------------------------------------------------\n",
      "steps 11400\n",
      "learning_rate: 0.00108523\n",
      "Training loss: 0.0573905 , Training acc:  0.988261\n",
      "Test loss: 0.236445 , Test acc:  0.915445\n",
      "--------------------------------------------------------------------------------\n",
      "steps 11420\n",
      "learning_rate: 0.00108523\n",
      "Training loss: 0.0548884 , Training acc:  0.989853\n",
      "Test loss: 0.229355 , Test acc:  0.918828\n",
      "--------------------------------------------------------------------------------\n",
      "steps 11440\n",
      "learning_rate: 0.00108523\n",
      "Training loss: 0.0518038 , Training acc:  0.989753\n",
      "Test loss: 0.219768 , Test acc:  0.922773\n",
      "--------------------------------------------------------------------------------\n",
      "steps 11460\n",
      "learning_rate: 0.00108523\n",
      "Training loss: 0.0510633 , Training acc:  0.991047\n",
      "Test loss: 0.222138 , Test acc:  0.916009\n",
      "--------------------------------------------------------------------------------\n",
      "steps 11480\n",
      "learning_rate: 0.00107437\n",
      "Training loss: 0.0504145 , Training acc:  0.990549\n",
      "Test loss: 0.226924 , Test acc:  0.917136\n",
      "--------------------------------------------------------------------------------\n",
      "steps 11500\n",
      "learning_rate: 0.00107437\n",
      "Training loss: 0.0527444 , Training acc:  0.988858\n",
      "Test loss: 0.234524 , Test acc:  0.918828\n",
      "--------------------------------------------------------------------------------\n",
      "steps 11520\n",
      "learning_rate: 0.00107437\n",
      "Training loss: 0.0511826 , Training acc:  0.990649\n",
      "Test loss: 0.234457 , Test acc:  0.921646\n",
      "--------------------------------------------------------------------------------\n",
      "steps 11540\n",
      "learning_rate: 0.00107437\n",
      "Training loss: 0.0502646 , Training acc:  0.990549\n",
      "Test loss: 0.227811 , Test acc:  0.921082\n",
      "--------------------------------------------------------------------------------\n",
      "steps 11560\n",
      "learning_rate: 0.00106363\n",
      "Training loss: 0.0518185 , Training acc:  0.989753\n",
      "Test loss: 0.225828 , Test acc:  0.921646\n",
      "--------------------------------------------------------------------------------\n",
      "steps 11580\n",
      "learning_rate: 0.00106363\n",
      "Training loss: 0.0488189 , Training acc:  0.990549\n",
      "Test loss: 0.218 , Test acc:  0.927283\n",
      "--------------------------------------------------------------------------------\n",
      "steps 11600\n",
      "learning_rate: 0.00106363\n",
      "Training loss: 0.0472444 , Training acc:  0.991444\n",
      "Test loss: 0.219426 , Test acc:  0.925028\n",
      "--------------------------------------------------------------------------------\n",
      "steps 11620\n",
      "learning_rate: 0.00106363\n",
      "Training loss: 0.0497934 , Training acc:  0.990549\n",
      "Test loss: 0.226755 , Test acc:  0.922773\n",
      "--------------------------------------------------------------------------------\n",
      "steps 11640\n",
      "learning_rate: 0.00105299\n",
      "Training loss: 0.0504767 , Training acc:  0.991246\n",
      "Test loss: 0.23138 , Test acc:  0.920519\n",
      "--------------------------------------------------------------------------------\n",
      "steps 11660\n",
      "learning_rate: 0.00105299\n",
      "Training loss: 0.0474192 , Training acc:  0.991544\n",
      "Test loss: 0.226114 , Test acc:  0.922773\n",
      "--------------------------------------------------------------------------------\n",
      "steps 11680\n",
      "learning_rate: 0.00105299\n",
      "Training loss: 0.0468314 , Training acc:  0.990848\n",
      "Test loss: 0.222974 , Test acc:  0.926719\n",
      "--------------------------------------------------------------------------------\n",
      "steps 11700\n",
      "learning_rate: 0.00104246\n",
      "Training loss: 0.0478949 , Training acc:  0.991047\n",
      "Test loss: 0.226992 , Test acc:  0.92221\n",
      "--------------------------------------------------------------------------------\n",
      "steps 11720\n",
      "learning_rate: 0.00104246\n",
      "Training loss: 0.0531192 , Training acc:  0.990748\n",
      "Test loss: 0.238795 , Test acc:  0.918828\n",
      "--------------------------------------------------------------------------------\n",
      "steps 11740\n",
      "learning_rate: 0.00104246\n",
      "Training loss: 0.0561911 , Training acc:  0.98846\n",
      "Test loss: 0.235179 , Test acc:  0.918264\n",
      "--------------------------------------------------------------------------------\n",
      "steps 11760\n",
      "learning_rate: 0.00104246\n",
      "Training loss: 0.0554824 , Training acc:  0.989753\n",
      "Test loss: 0.237792 , Test acc:  0.919955\n",
      "--------------------------------------------------------------------------------\n",
      "steps 11780\n",
      "learning_rate: 0.00103204\n",
      "Training loss: 0.0518724 , Training acc:  0.990649\n",
      "Test loss: 0.230052 , Test acc:  0.921646\n",
      "--------------------------------------------------------------------------------\n",
      "steps 11800\n",
      "learning_rate: 0.00103204\n",
      "Training loss: 0.0516455 , Training acc:  0.989654\n",
      "Test loss: 0.233519 , Test acc:  0.921646\n",
      "--------------------------------------------------------------------------------\n",
      "steps 11820\n",
      "learning_rate: 0.00103204\n",
      "Training loss: 0.0541524 , Training acc:  0.989256\n",
      "Test loss: 0.237416 , Test acc:  0.918264\n",
      "--------------------------------------------------------------------------------\n",
      "steps 11840\n",
      "learning_rate: 0.00103204\n",
      "Training loss: 0.0522056 , Training acc:  0.988957\n",
      "Test loss: 0.230679 , Test acc:  0.922773\n",
      "--------------------------------------------------------------------------------\n",
      "steps 11860\n",
      "learning_rate: 0.00102172\n",
      "Training loss: 0.0485031 , Training acc:  0.990052\n",
      "Test loss: 0.227362 , Test acc:  0.923337\n",
      "--------------------------------------------------------------------------------\n",
      "steps 11880\n",
      "learning_rate: 0.00102172\n",
      "Training loss: 0.0522536 , Training acc:  0.989355\n",
      "Test loss: 0.234047 , Test acc:  0.918264\n",
      "--------------------------------------------------------------------------------\n",
      "steps 11900\n",
      "learning_rate: 0.00102172\n",
      "Training loss: 0.0476269 , Training acc:  0.989455\n",
      "Test loss: 0.229715 , Test acc:  0.921646\n",
      "--------------------------------------------------------------------------------\n",
      "steps 11920\n",
      "learning_rate: 0.00102172\n",
      "Training loss: 0.045397 , Training acc:  0.990649\n",
      "Test loss: 0.226051 , Test acc:  0.923901\n",
      "--------------------------------------------------------------------------------\n",
      "steps 11940\n",
      "learning_rate: 0.0010115\n",
      "Training loss: 0.0483739 , Training acc:  0.990549\n",
      "Test loss: 0.230186 , Test acc:  0.921082\n",
      "--------------------------------------------------------------------------------\n",
      "steps 11960\n",
      "learning_rate: 0.0010115\n",
      "Training loss: 0.0547042 , Training acc:  0.989057\n",
      "Test loss: 0.231981 , Test acc:  0.921082\n",
      "--------------------------------------------------------------------------------\n",
      "steps 11980\n",
      "learning_rate: 0.0010115\n",
      "Training loss: 0.0645086 , Training acc:  0.985078\n",
      "Test loss: 0.248315 , Test acc:  0.913191\n",
      "--------------------------------------------------------------------------------\n",
      "steps 12000\n",
      "learning_rate: 0.00100139\n",
      "Training loss: 0.0552109 , Training acc:  0.988559\n",
      "Test loss: 0.238617 , Test acc:  0.9177\n",
      "--------------------------------------------------------------------------------\n",
      "steps 12020\n",
      "learning_rate: 0.00100139\n",
      "Training loss: 0.0484852 , Training acc:  0.991345\n",
      "Test loss: 0.229185 , Test acc:  0.922773\n",
      "--------------------------------------------------------------------------------\n",
      "steps 12040\n",
      "learning_rate: 0.00100139\n",
      "Training loss: 0.0448618 , Training acc:  0.991544\n",
      "Test loss: 0.219626 , Test acc:  0.926719\n",
      "--------------------------------------------------------------------------------\n",
      "steps 12060\n",
      "learning_rate: 0.00100139\n",
      "Training loss: 0.0467365 , Training acc:  0.991146\n",
      "Test loss: 0.223769 , Test acc:  0.927283\n",
      "--------------------------------------------------------------------------------\n",
      "steps 12080\n",
      "learning_rate: 0.000991373\n",
      "Training loss: 0.0523235 , Training acc:  0.99045\n",
      "Test loss: 0.230508 , Test acc:  0.918828\n",
      "--------------------------------------------------------------------------------\n",
      "steps 12100\n",
      "learning_rate: 0.000991373\n",
      "Training loss: 0.0529023 , Training acc:  0.989256\n",
      "Test loss: 0.225356 , Test acc:  0.92221\n",
      "--------------------------------------------------------------------------------\n",
      "steps 12120\n",
      "learning_rate: 0.000991373\n",
      "Training loss: 0.0484212 , Training acc:  0.991246\n",
      "Test loss: 0.221803 , Test acc:  0.925028\n",
      "--------------------------------------------------------------------------------\n",
      "steps 12140\n",
      "learning_rate: 0.000991373\n",
      "Training loss: 0.0491187 , Training acc:  0.990947\n",
      "Test loss: 0.224515 , Test acc:  0.927283\n",
      "--------------------------------------------------------------------------------\n",
      "steps 12160\n",
      "learning_rate: 0.000981459\n",
      "Training loss: 0.0487445 , Training acc:  0.991544\n",
      "Test loss: 0.225165 , Test acc:  0.923337\n",
      "--------------------------------------------------------------------------------\n",
      "steps 12180\n",
      "learning_rate: 0.000981459\n",
      "Training loss: 0.0503517 , Training acc:  0.990052\n",
      "Test loss: 0.223246 , Test acc:  0.923337\n",
      "--------------------------------------------------------------------------------\n",
      "steps 12200\n",
      "learning_rate: 0.000981459\n",
      "Training loss: 0.0470886 , Training acc:  0.992141\n",
      "Test loss: 0.216741 , Test acc:  0.925592\n",
      "--------------------------------------------------------------------------------\n",
      "steps 12220\n",
      "learning_rate: 0.000981459\n",
      "Training loss: 0.0449489 , Training acc:  0.993136\n",
      "Test loss: 0.217505 , Test acc:  0.923901\n",
      "--------------------------------------------------------------------------------\n",
      "steps 12240\n",
      "learning_rate: 0.000971644\n",
      "Training loss: 0.0446094 , Training acc:  0.99224\n",
      "Test loss: 0.221601 , Test acc:  0.922773\n",
      "--------------------------------------------------------------------------------\n",
      "steps 12260\n",
      "learning_rate: 0.000971644\n",
      "Training loss: 0.0458985 , Training acc:  0.992141\n",
      "Test loss: 0.227641 , Test acc:  0.921646\n",
      "--------------------------------------------------------------------------------\n",
      "steps 12280\n",
      "learning_rate: 0.000971644\n",
      "Training loss: 0.0446163 , Training acc:  0.99224\n",
      "Test loss: 0.218249 , Test acc:  0.921646\n",
      "--------------------------------------------------------------------------------\n",
      "steps 12300\n",
      "learning_rate: 0.000961928\n",
      "Training loss: 0.0448558 , Training acc:  0.991544\n",
      "Test loss: 0.22129 , Test acc:  0.927847\n",
      "--------------------------------------------------------------------------------\n",
      "steps 12320\n",
      "learning_rate: 0.000961928\n",
      "Training loss: 0.0435955 , Training acc:  0.991146\n",
      "Test loss: 0.219443 , Test acc:  0.92841\n",
      "--------------------------------------------------------------------------------\n",
      "steps 12340\n",
      "learning_rate: 0.000961928\n",
      "Training loss: 0.0424938 , Training acc:  0.991743\n",
      "Test loss: 0.220502 , Test acc:  0.924464\n",
      "--------------------------------------------------------------------------------\n",
      "steps 12360\n",
      "learning_rate: 0.000961928\n",
      "Training loss: 0.0472307 , Training acc:  0.990649\n",
      "Test loss: 0.232932 , Test acc:  0.921082\n",
      "--------------------------------------------------------------------------------\n",
      "steps 12380\n",
      "learning_rate: 0.000952309\n",
      "Training loss: 0.0449445 , Training acc:  0.992638\n",
      "Test loss: 0.22539 , Test acc:  0.925028\n",
      "--------------------------------------------------------------------------------\n",
      "steps 12400\n",
      "learning_rate: 0.000952309\n",
      "Training loss: 0.0451884 , Training acc:  0.991643\n",
      "Test loss: 0.229186 , Test acc:  0.925592\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "RUN_NAME = 'batch_size_32'\n",
    "writer_train = tf.summary.FileWriter('./log/' + RUN_NAME + '/train', graph=sess.graph)\n",
    "writer_test = tf.summary.FileWriter('./log/' + RUN_NAME + '/test', graph=sess.graph)\n",
    "\n",
    "steps = 0\n",
    "# Keep training until reach max iterations\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    indices = np.arange(len(y_train))\n",
    "    np.random.shuffle(indices)\n",
    "    X_train, y_train =  X_train[indices], y_train[indices]\n",
    "\n",
    "    for start, end in feed_next_batch(len(X_train), batch_size=batch_size):\n",
    "        # Run optimization op (backprop)\n",
    "        batch_x, batch_y = X_train[start:end], y_train[start:end]\n",
    "        sess.run(optimizer, feed_dict={x: batch_x, y: batch_y, keep_prob: dropout})\n",
    "        \n",
    "        steps += 1\n",
    "        \n",
    "        if steps % 20 == 0:\n",
    "\n",
    "            # Calculate batch loss and accuracy\n",
    "            train_loss, train_acc, train_lr, summary_train = sess.run([loss, accuracy, learning_rate, summary], \n",
    "                                                   feed_dict={x: X_train, y: y_train, keep_prob: 1.0})\n",
    "            writer_train.add_summary(summary_train, steps)\n",
    "            \n",
    "            print('steps %d' % (steps ))\n",
    "            print('learning_rate:', train_lr)\n",
    "            print (\"Training loss:\", train_loss, ', Training acc: ', train_acc)\n",
    "\n",
    "            val_loss, val_acc, summary_test = sess.run([loss, accuracy, summary], feed_dict={x: X_test, \n",
    "                                                                        y: y_test,\n",
    "                                                                       keep_prob: 1.0})\n",
    "            writer_test.add_summary(summary_test, steps)\n",
    "            print (\"Test loss:\", val_loss, ', Test acc: ', val_acc)\n",
    "            print('-' * 80)\n",
    "\n",
    "print (\"Optimization Finished!\")\n",
    "\n",
    "# Calculate accuracy for all test samples\n",
    "print (\"Training Accuracy:\", \\\n",
    "    sess.run(accuracy, feed_dict={x: X_train,\n",
    "                                  y: y_train,\n",
    "                                 keep_prob: 1.0}))\n",
    "print (\"Test Accuracy:\", \\\n",
    "    sess.run(accuracy, feed_dict={x: X_test,\n",
    "                                  y: y_test,\n",
    "                                 keep_prob: 1.0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sess.close()\n",
    "\n",
    "arr5 = np.arange(0, 3600)\n",
    "arr5 = 0.0075 * 0.99 ** (arr5/75)\n",
    "plt.plot(arr5, '--'),\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
