{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "# import librosa\n",
    "# from librosa import display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from matplotlib.pyplot import specgram\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "plt.rcParams['font.serif'] = 'Ubuntu'\n",
    "plt.rcParams['font.monospace'] = 'Ubuntu Mono'\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.rcParams['axes.labelsize'] = 11\n",
    "plt.rcParams['axes.labelweight'] = 'bold'\n",
    "plt.rcParams['axes.titlesize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 10\n",
    "plt.rcParams['ytick.labelsize'] = 10\n",
    "plt.rcParams['legend.fontsize'] = 11\n",
    "plt.rcParams['figure.titlesize'] = 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.loadtxt('nn_simple_features.csv', delimiter=',')\n",
    "labels = np.array(np.loadtxt('nn_simple_labels.csv', delimiter=','), dtype=np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "X_all = features\n",
    "y_all = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9460, 1280)\n",
      "(9460, 5)\n",
      "(2366, 1280)\n",
      "(2366, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hitmann/.local/lib/python3.5/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_all, y_all, stratify=y_all, train_size=.8, random_state=round(time.time()))\n",
    "\n",
    "# X_train, X_val, y_train, y_val = train_test_split(\n",
    "#     X_not_test, y_not_rest, stratify=y_not_rest, train_size=.85, random_state=round(time.time()))\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "# print(X_val.shape)\n",
    "# print(y_val.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "# learning_rate = 0.005\n",
    "\n",
    "with tf.name_scope(\"learning_rate\"):\n",
    "    global_step = tf.Variable(0, trainable=False)\n",
    "    starter_learning_rate = 0.005\n",
    "    learning_rate = tf.train.exponential_decay(starter_learning_rate, global_step,\n",
    "                                               75, 0.99, staircase=True)\n",
    "    tf.summary.scalar(\"learning_rate\", learning_rate)\n",
    "\n",
    "epochs = 40\n",
    "batch_size = 32\n",
    "\n",
    "# Network Parameters\n",
    "n_input = 40 * 32\n",
    "n_classes = 5\n",
    "dropout = .8 # Dropout, probability to keep units\n",
    "\n",
    "# 1. Define Variables and Placeholders\n",
    "x = tf.placeholder(tf.float32, [None, n_input])\n",
    "y = tf.placeholder(tf.float32, [None, n_classes])\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32) #dropout (keep probability)\n",
    "\n",
    "def build_model(x, dropout, activation):\n",
    "    \n",
    "    x = tf.reshape(x, shape=[-1, 40, 32, 1])\n",
    "    \n",
    "    conv1 = tf.layers.conv2d(x, 4, 5, activation=activation)\n",
    "    conv1 = tf.layers.batch_normalization(conv1)\n",
    "    conv1 = tf.layers.max_pooling2d(conv1, 2, 2)\n",
    "    conv1 = tf.nn.dropout(conv1, dropout)\n",
    "    \n",
    "    conv2 = tf.layers.conv2d(conv1, 8, 3, activation=activation)\n",
    "    conv2 = tf.layers.batch_normalization(conv2)\n",
    "    conv2 = tf.layers.max_pooling2d(conv2, 2, 2)\n",
    "    conv2 = tf.nn.dropout(conv2, dropout)\n",
    "    \n",
    "    fc1 = tf.contrib.layers.flatten(conv2)\n",
    "\n",
    "    fc1 = tf.layers.dense(fc1, 128, activation=activation)\n",
    "    fc1 = tf.layers.batch_normalization(fc1)\n",
    "    fc1 = tf.nn.dropout(fc1, dropout)\n",
    "\n",
    "    fc2 = tf.layers.dense(fc1, 64, activation=activation)\n",
    "    fc2 = tf.layers.batch_normalization(fc2)\n",
    "    fc2 = tf.nn.dropout(fc2, dropout)\n",
    "    \n",
    "    out = tf.layers.dense(fc2, n_classes)\n",
    "\n",
    "    return out\n",
    "\n",
    "predictions = build_model(x, keep_prob, activation=tf.nn.relu)\n",
    "# 3. Define the loss function\n",
    "with tf.name_scope(\"loss\"):\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=predictions, labels=y), name='loss')\n",
    "    tf.summary.scalar(\"loss\", loss)\n",
    "    \n",
    "\n",
    "# 4. Define the accuracy \n",
    "with tf.name_scope(\"accuracy\"):\n",
    "    correct_pred = tf.equal(tf.argmax(predictions, 1), tf.argmax(y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "    tf.summary.scalar(\"accuracy\", accuracy)\n",
    "\n",
    "summary = tf.summary.merge_all()\n",
    "# 5. Define an optimizer\n",
    "# optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss, global_step=global_step)\n",
    "\n",
    "def feed_next_batch(train_size, batch_size=64):\n",
    "    \n",
    "    start = 0\n",
    "    while start < train_size:\n",
    "        yield start, start + batch_size\n",
    "        start += batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 20\n",
      "learning_rate: 0.005\n",
      "Training loss: 1.63625 , Training acc:  0.216702\n",
      "Test loss: 1.63692 , Test acc:  0.20541\n",
      "--------------------------------------------------------------------------------\n",
      "Step 40\n",
      "learning_rate: 0.005\n",
      "Training loss: 1.6236 , Training acc:  0.202537\n",
      "Test loss: 1.62126 , Test acc:  0.194844\n",
      "--------------------------------------------------------------------------------\n",
      "Step 60\n",
      "learning_rate: 0.005\n",
      "Training loss: 1.61146 , Training acc:  0.204228\n",
      "Test loss: 1.61195 , Test acc:  0.201183\n",
      "--------------------------------------------------------------------------------\n",
      "Step 80\n",
      "learning_rate: 0.00495\n",
      "Training loss: 1.6085 , Training acc:  0.206554\n",
      "Test loss: 1.60909 , Test acc:  0.20541\n",
      "--------------------------------------------------------------------------------\n",
      "Step 100\n",
      "learning_rate: 0.00495\n",
      "Training loss: 1.6021 , Training acc:  0.237949\n",
      "Test loss: 1.60263 , Test acc:  0.228233\n",
      "--------------------------------------------------------------------------------\n",
      "Step 120\n",
      "learning_rate: 0.00495\n",
      "Training loss: 1.59529 , Training acc:  0.243657\n",
      "Test loss: 1.59546 , Test acc:  0.237109\n",
      "--------------------------------------------------------------------------------\n",
      "Step 140\n",
      "learning_rate: 0.00495\n",
      "Training loss: 1.5778 , Training acc:  0.271247\n",
      "Test loss: 1.57736 , Test acc:  0.26754\n",
      "--------------------------------------------------------------------------------\n",
      "Step 160\n",
      "learning_rate: 0.0049005\n",
      "Training loss: 1.55747 , Training acc:  0.324524\n",
      "Test loss: 1.55603 , Test acc:  0.301775\n",
      "--------------------------------------------------------------------------------\n",
      "Step 180\n",
      "learning_rate: 0.0049005\n",
      "Training loss: 1.53305 , Training acc:  0.323679\n",
      "Test loss: 1.53174 , Test acc:  0.320372\n",
      "--------------------------------------------------------------------------------\n",
      "Step 200\n",
      "learning_rate: 0.0049005\n",
      "Training loss: 1.49867 , Training acc:  0.338689\n",
      "Test loss: 1.49116 , Test acc:  0.343195\n",
      "--------------------------------------------------------------------------------\n",
      "Step 220\n",
      "learning_rate: 0.0049005\n",
      "Training loss: 1.5242 , Training acc:  0.331607\n",
      "Test loss: 1.51571 , Test acc:  0.341927\n",
      "--------------------------------------------------------------------------------\n",
      "Step 240\n",
      "learning_rate: 0.00485149\n",
      "Training loss: 1.46756 , Training acc:  0.3574\n",
      "Test loss: 1.46085 , Test acc:  0.353339\n",
      "--------------------------------------------------------------------------------\n",
      "Step 260\n",
      "learning_rate: 0.00485149\n",
      "Training loss: 1.39683 , Training acc:  0.417653\n",
      "Test loss: 1.39179 , Test acc:  0.41082\n",
      "--------------------------------------------------------------------------------\n",
      "Step 280\n",
      "learning_rate: 0.00485149\n",
      "Training loss: 1.29944 , Training acc:  0.476321\n",
      "Test loss: 1.29827 , Test acc:  0.473373\n",
      "--------------------------------------------------------------------------------\n",
      "Step 300\n",
      "learning_rate: 0.00480298\n",
      "Training loss: 1.31764 , Training acc:  0.469345\n",
      "Test loss: 1.31281 , Test acc:  0.46492\n",
      "--------------------------------------------------------------------------------\n",
      "Step 320\n",
      "learning_rate: 0.00480298\n",
      "Training loss: 1.23841 , Training acc:  0.500317\n",
      "Test loss: 1.23902 , Test acc:  0.499577\n",
      "--------------------------------------------------------------------------------\n",
      "Step 340\n",
      "learning_rate: 0.00480298\n",
      "Training loss: 1.25565 , Training acc:  0.490698\n",
      "Test loss: 1.25677 , Test acc:  0.495351\n",
      "--------------------------------------------------------------------------------\n",
      "Step 360\n",
      "learning_rate: 0.00480298\n",
      "Training loss: 1.22068 , Training acc:  0.507082\n",
      "Test loss: 1.21612 , Test acc:  0.519865\n",
      "--------------------------------------------------------------------------------\n",
      "Step 380\n",
      "learning_rate: 0.00475495\n",
      "Training loss: 1.12445 , Training acc:  0.525264\n",
      "Test loss: 1.12832 , Test acc:  0.519442\n",
      "--------------------------------------------------------------------------------\n",
      "Step 400\n",
      "learning_rate: 0.00475495\n",
      "Training loss: 1.06989 , Training acc:  0.595137\n",
      "Test loss: 1.07677 , Test acc:  0.579459\n",
      "--------------------------------------------------------------------------------\n",
      "Step 420\n",
      "learning_rate: 0.00475495\n",
      "Training loss: 1.04202 , Training acc:  0.576744\n",
      "Test loss: 1.04512 , Test acc:  0.565089\n",
      "--------------------------------------------------------------------------------\n",
      "Step 440\n",
      "learning_rate: 0.00475495\n",
      "Training loss: 1.07876 , Training acc:  0.569767\n",
      "Test loss: 1.0823 , Test acc:  0.571851\n",
      "--------------------------------------------------------------------------------\n",
      "Step 460\n",
      "learning_rate: 0.0047074\n",
      "Training loss: 1.00461 , Training acc:  0.640169\n",
      "Test loss: 1.0105 , Test acc:  0.625106\n",
      "--------------------------------------------------------------------------------\n",
      "Step 480\n",
      "learning_rate: 0.0047074\n",
      "Training loss: 1.0211 , Training acc:  0.604757\n",
      "Test loss: 1.02754 , Test acc:  0.610313\n",
      "--------------------------------------------------------------------------------\n",
      "Step 500\n",
      "learning_rate: 0.0047074\n",
      "Training loss: 0.965681 , Training acc:  0.60666\n",
      "Test loss: 0.96738 , Test acc:  0.610313\n",
      "--------------------------------------------------------------------------------\n",
      "Step 520\n",
      "learning_rate: 0.0047074\n",
      "Training loss: 1.02133 , Training acc:  0.607928\n",
      "Test loss: 1.02962 , Test acc:  0.619188\n",
      "--------------------------------------------------------------------------------\n",
      "Step 540\n",
      "learning_rate: 0.00466033\n",
      "Training loss: 0.997324 , Training acc:  0.62315\n",
      "Test loss: 1.00005 , Test acc:  0.62426\n",
      "--------------------------------------------------------------------------------\n",
      "Step 560\n",
      "learning_rate: 0.00466033\n",
      "Training loss: 0.898114 , Training acc:  0.659408\n",
      "Test loss: 0.90788 , Test acc:  0.667371\n",
      "--------------------------------------------------------------------------------\n",
      "Step 580\n",
      "learning_rate: 0.00466033\n",
      "Training loss: 0.834757 , Training acc:  0.654968\n",
      "Test loss: 0.846521 , Test acc:  0.643702\n",
      "--------------------------------------------------------------------------------\n",
      "Step 600\n",
      "learning_rate: 0.00461372\n",
      "Training loss: 0.859178 , Training acc:  0.683192\n",
      "Test loss: 0.864454 , Test acc:  0.677092\n",
      "--------------------------------------------------------------------------------\n",
      "Step 620\n",
      "learning_rate: 0.00461372\n",
      "Training loss: 0.855379 , Training acc:  0.662791\n",
      "Test loss: 0.860829 , Test acc:  0.656805\n",
      "--------------------------------------------------------------------------------\n",
      "Step 640\n",
      "learning_rate: 0.00461372\n",
      "Training loss: 0.852399 , Training acc:  0.669345\n",
      "Test loss: 0.8569 , Test acc:  0.677092\n",
      "--------------------------------------------------------------------------------\n",
      "Step 660\n",
      "learning_rate: 0.00461372\n",
      "Training loss: 0.803615 , Training acc:  0.69408\n",
      "Test loss: 0.819483 , Test acc:  0.6847\n",
      "--------------------------------------------------------------------------------\n",
      "Step 680\n",
      "learning_rate: 0.00456759\n",
      "Training loss: 0.862691 , Training acc:  0.662156\n",
      "Test loss: 0.874188 , Test acc:  0.657227\n",
      "--------------------------------------------------------------------------------\n",
      "Step 700\n",
      "learning_rate: 0.00456759\n",
      "Training loss: 0.894215 , Training acc:  0.632981\n",
      "Test loss: 0.89924 , Test acc:  0.632291\n",
      "--------------------------------------------------------------------------------\n",
      "Step 720\n",
      "learning_rate: 0.00456759\n",
      "Training loss: 0.778629 , Training acc:  0.709408\n",
      "Test loss: 0.792772 , Test acc:  0.704142\n",
      "--------------------------------------------------------------------------------\n",
      "Step 740\n",
      "learning_rate: 0.00456759\n",
      "Training loss: 1.00768 , Training acc:  0.594397\n",
      "Test loss: 1.00588 , Test acc:  0.60186\n",
      "--------------------------------------------------------------------------------\n",
      "Step 760\n",
      "learning_rate: 0.00452191\n",
      "Training loss: 0.761344 , Training acc:  0.691649\n",
      "Test loss: 0.764855 , Test acc:  0.687236\n",
      "--------------------------------------------------------------------------------\n",
      "Step 780\n",
      "learning_rate: 0.00452191\n",
      "Training loss: 0.929568 , Training acc:  0.614165\n",
      "Test loss: 0.916555 , Test acc:  0.627219\n",
      "--------------------------------------------------------------------------------\n",
      "Step 800\n",
      "learning_rate: 0.00452191\n",
      "Training loss: 0.936072 , Training acc:  0.603066\n",
      "Test loss: 0.944862 , Test acc:  0.605664\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 820\n",
      "learning_rate: 0.00452191\n",
      "Training loss: 0.806072 , Training acc:  0.702114\n",
      "Test loss: 0.821162 , Test acc:  0.688504\n",
      "--------------------------------------------------------------------------------\n",
      "Step 840\n",
      "learning_rate: 0.00447669\n",
      "Training loss: 0.746561 , Training acc:  0.732135\n",
      "Test loss: 0.761175 , Test acc:  0.726965\n",
      "--------------------------------------------------------------------------------\n",
      "Step 860\n",
      "learning_rate: 0.00447669\n",
      "Training loss: 0.738066 , Training acc:  0.735412\n",
      "Test loss: 0.759937 , Test acc:  0.729924\n",
      "--------------------------------------------------------------------------------\n",
      "Step 880\n",
      "learning_rate: 0.00447669\n",
      "Training loss: 0.782335 , Training acc:  0.713002\n",
      "Test loss: 0.789441 , Test acc:  0.701606\n",
      "--------------------------------------------------------------------------------\n",
      "Step 900\n",
      "learning_rate: 0.00443192\n",
      "Training loss: 0.709617 , Training acc:  0.741015\n",
      "Test loss: 0.728568 , Test acc:  0.732882\n",
      "--------------------------------------------------------------------------------\n",
      "Step 920\n",
      "learning_rate: 0.00443192\n",
      "Training loss: 0.855286 , Training acc:  0.670825\n",
      "Test loss: 0.867154 , Test acc:  0.677092\n",
      "--------------------------------------------------------------------------------\n",
      "Step 940\n",
      "learning_rate: 0.00443192\n",
      "Training loss: 0.786026 , Training acc:  0.690698\n",
      "Test loss: 0.808125 , Test acc:  0.683009\n",
      "--------------------------------------------------------------------------------\n",
      "Step 960\n",
      "learning_rate: 0.00443192\n",
      "Training loss: 0.80342 , Training acc:  0.689112\n",
      "Test loss: 0.814566 , Test acc:  0.683855\n",
      "--------------------------------------------------------------------------------\n",
      "Step 980\n",
      "learning_rate: 0.00438761\n",
      "Training loss: 0.745726 , Training acc:  0.712262\n",
      "Test loss: 0.775414 , Test acc:  0.694421\n",
      "--------------------------------------------------------------------------------\n",
      "Step 1000\n",
      "learning_rate: 0.00438761\n",
      "Training loss: 0.731382 , Training acc:  0.719133\n",
      "Test loss: 0.74072 , Test acc:  0.724852\n",
      "--------------------------------------------------------------------------------\n",
      "Step 1020\n",
      "learning_rate: 0.00438761\n",
      "Training loss: 0.740835 , Training acc:  0.726638\n",
      "Test loss: 0.748509 , Test acc:  0.725697\n",
      "--------------------------------------------------------------------------------\n",
      "Step 1040\n",
      "learning_rate: 0.00438761\n",
      "Training loss: 0.669248 , Training acc:  0.745666\n",
      "Test loss: 0.68807 , Test acc:  0.735418\n",
      "--------------------------------------------------------------------------------\n",
      "Step 1060\n",
      "learning_rate: 0.00434373\n",
      "Training loss: 0.671336 , Training acc:  0.745349\n",
      "Test loss: 0.694365 , Test acc:  0.734996\n",
      "--------------------------------------------------------------------------------\n",
      "Step 1080\n",
      "learning_rate: 0.00434373\n",
      "Training loss: 0.725041 , Training acc:  0.718393\n",
      "Test loss: 0.72366 , Test acc:  0.722316\n",
      "--------------------------------------------------------------------------------\n",
      "Step 1100\n",
      "learning_rate: 0.00434373\n",
      "Training loss: 0.7296 , Training acc:  0.736892\n",
      "Test loss: 0.733583 , Test acc:  0.743872\n",
      "--------------------------------------------------------------------------------\n",
      "Step 1120\n",
      "learning_rate: 0.00434373\n",
      "Training loss: 0.675699 , Training acc:  0.745877\n",
      "Test loss: 0.686058 , Test acc:  0.748098\n",
      "--------------------------------------------------------------------------------\n",
      "Step 1140\n",
      "learning_rate: 0.00430029\n",
      "Training loss: 0.689133 , Training acc:  0.745455\n",
      "Test loss: 0.706916 , Test acc:  0.730347\n",
      "--------------------------------------------------------------------------------\n",
      "Step 1160\n",
      "learning_rate: 0.00430029\n",
      "Training loss: 0.603469 , Training acc:  0.792918\n",
      "Test loss: 0.623665 , Test acc:  0.789096\n",
      "--------------------------------------------------------------------------------\n",
      "Step 1180\n",
      "learning_rate: 0.00430029\n",
      "Training loss: 0.640673 , Training acc:  0.768393\n",
      "Test loss: 0.656205 , Test acc:  0.761623\n",
      "--------------------------------------------------------------------------------\n",
      "Step 1200\n",
      "learning_rate: 0.00425729\n",
      "Training loss: 0.657028 , Training acc:  0.758562\n",
      "Test loss: 0.667817 , Test acc:  0.755706\n",
      "--------------------------------------------------------------------------------\n",
      "Step 1220\n",
      "learning_rate: 0.00425729\n",
      "Training loss: 0.622009 , Training acc:  0.772833\n",
      "Test loss: 0.643007 , Test acc:  0.775571\n",
      "--------------------------------------------------------------------------------\n",
      "Step 1240\n",
      "learning_rate: 0.00425729\n",
      "Training loss: 0.655258 , Training acc:  0.756765\n",
      "Test loss: 0.670423 , Test acc:  0.750211\n",
      "--------------------------------------------------------------------------------\n",
      "Step 1260\n",
      "learning_rate: 0.00425729\n",
      "Training loss: 0.672047 , Training acc:  0.746089\n",
      "Test loss: 0.684516 , Test acc:  0.740068\n",
      "--------------------------------------------------------------------------------\n",
      "Step 1280\n",
      "learning_rate: 0.00421472\n",
      "Training loss: 0.737578 , Training acc:  0.724947\n",
      "Test loss: 0.748932 , Test acc:  0.729924\n",
      "--------------------------------------------------------------------------------\n",
      "Step 1300\n",
      "learning_rate: 0.00421472\n",
      "Training loss: 0.60477 , Training acc:  0.776533\n",
      "Test loss: 0.645185 , Test acc:  0.758664\n",
      "--------------------------------------------------------------------------------\n",
      "Step 1320\n",
      "learning_rate: 0.00421472\n",
      "Training loss: 0.61438 , Training acc:  0.77907\n",
      "Test loss: 0.647229 , Test acc:  0.768808\n",
      "--------------------------------------------------------------------------------\n",
      "Step 1340\n",
      "learning_rate: 0.00421472\n",
      "Training loss: 0.671095 , Training acc:  0.749683\n",
      "Test loss: 0.704012 , Test acc:  0.745139\n",
      "--------------------------------------------------------------------------------\n",
      "Step 1360\n",
      "learning_rate: 0.00417257\n",
      "Training loss: 0.630986 , Training acc:  0.771882\n",
      "Test loss: 0.656849 , Test acc:  0.764582\n",
      "--------------------------------------------------------------------------------\n",
      "Step 1380\n",
      "learning_rate: 0.00417257\n",
      "Training loss: 0.724843 , Training acc:  0.724524\n",
      "Test loss: 0.738921 , Test acc:  0.730769\n",
      "--------------------------------------------------------------------------------\n",
      "Step 1400\n",
      "learning_rate: 0.00417257\n",
      "Training loss: 0.593035 , Training acc:  0.794186\n",
      "Test loss: 0.617419 , Test acc:  0.790786\n",
      "--------------------------------------------------------------------------------\n",
      "Step 1420\n",
      "learning_rate: 0.00417257\n",
      "Training loss: 0.601809 , Training acc:  0.774207\n",
      "Test loss: 0.636904 , Test acc:  0.762891\n",
      "--------------------------------------------------------------------------------\n",
      "Step 1440\n",
      "learning_rate: 0.00413084\n",
      "Training loss: 0.590142 , Training acc:  0.786575\n",
      "Test loss: 0.62472 , Test acc:  0.779797\n",
      "--------------------------------------------------------------------------------\n",
      "Step 1460\n",
      "learning_rate: 0.00413084\n",
      "Training loss: 0.564796 , Training acc:  0.803594\n",
      "Test loss: 0.588333 , Test acc:  0.798817\n",
      "--------------------------------------------------------------------------------\n",
      "Step 1480\n",
      "learning_rate: 0.00413084\n",
      "Training loss: 0.600585 , Training acc:  0.780761\n",
      "Test loss: 0.636468 , Test acc:  0.762891\n",
      "--------------------------------------------------------------------------------\n",
      "Step 1500\n",
      "learning_rate: 0.00408954\n",
      "Training loss: 0.585436 , Training acc:  0.783932\n",
      "Test loss: 0.629707 , Test acc:  0.763314\n",
      "--------------------------------------------------------------------------------\n",
      "Step 1520\n",
      "learning_rate: 0.00408954\n",
      "Training loss: 0.601913 , Training acc:  0.77463\n",
      "Test loss: 0.637922 , Test acc:  0.758664\n",
      "--------------------------------------------------------------------------------\n",
      "Step 1540\n",
      "learning_rate: 0.00408954\n",
      "Training loss: 0.540186 , Training acc:  0.817336\n",
      "Test loss: 0.571534 , Test acc:  0.795013\n",
      "--------------------------------------------------------------------------------\n",
      "Step 1560\n",
      "learning_rate: 0.00408954\n",
      "Training loss: 0.532737 , Training acc:  0.811099\n",
      "Test loss: 0.575073 , Test acc:  0.787828\n",
      "--------------------------------------------------------------------------------\n",
      "Step 1580\n",
      "learning_rate: 0.00404864\n",
      "Training loss: 0.580801 , Training acc:  0.783827\n",
      "Test loss: 0.619656 , Test acc:  0.768808\n",
      "--------------------------------------------------------------------------------\n",
      "Step 1600\n",
      "learning_rate: 0.00404864\n",
      "Training loss: 0.525715 , Training acc:  0.810254\n",
      "Test loss: 0.566281 , Test acc:  0.798394\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1620\n",
      "learning_rate: 0.00404864\n",
      "Training loss: 0.557934 , Training acc:  0.790381\n",
      "Test loss: 0.605187 , Test acc:  0.764582\n",
      "--------------------------------------------------------------------------------\n",
      "Step 1640\n",
      "learning_rate: 0.00404864\n",
      "Training loss: 0.520223 , Training acc:  0.812685\n",
      "Test loss: 0.570538 , Test acc:  0.800085\n",
      "--------------------------------------------------------------------------------\n",
      "Step 1660\n",
      "learning_rate: 0.00400815\n",
      "Training loss: 0.50759 , Training acc:  0.826427\n",
      "Test loss: 0.547289 , Test acc:  0.814455\n",
      "--------------------------------------------------------------------------------\n",
      "Step 1680\n",
      "learning_rate: 0.00400815\n",
      "Training loss: 0.644831 , Training acc:  0.763636\n",
      "Test loss: 0.687979 , Test acc:  0.745985\n",
      "--------------------------------------------------------------------------------\n",
      "Step 1700\n",
      "learning_rate: 0.00400815\n",
      "Training loss: 0.510923 , Training acc:  0.819027\n",
      "Test loss: 0.553426 , Test acc:  0.804734\n",
      "--------------------------------------------------------------------------------\n",
      "Step 1720\n",
      "learning_rate: 0.00400815\n",
      "Training loss: 0.510549 , Training acc:  0.815433\n",
      "Test loss: 0.562062 , Test acc:  0.786982\n",
      "--------------------------------------------------------------------------------\n",
      "Step 1740\n",
      "learning_rate: 0.00396807\n",
      "Training loss: 0.629789 , Training acc:  0.765433\n",
      "Test loss: 0.665784 , Test acc:  0.747675\n",
      "--------------------------------------------------------------------------------\n",
      "Step 1760\n",
      "learning_rate: 0.00396807\n",
      "Training loss: 0.519932 , Training acc:  0.821564\n",
      "Test loss: 0.562713 , Test acc:  0.806424\n",
      "--------------------------------------------------------------------------------\n",
      "Step 1780\n",
      "learning_rate: 0.00396807\n",
      "Training loss: 0.474313 , Training acc:  0.837738\n",
      "Test loss: 0.526787 , Test acc:  0.819949\n",
      "--------------------------------------------------------------------------------\n",
      "Step 1800\n",
      "learning_rate: 0.00392839\n",
      "Training loss: 0.507433 , Training acc:  0.825476\n",
      "Test loss: 0.555475 , Test acc:  0.811496\n",
      "--------------------------------------------------------------------------------\n",
      "Step 1820\n",
      "learning_rate: 0.00392839\n",
      "Training loss: 0.482219 , Training acc:  0.826004\n",
      "Test loss: 0.524777 , Test acc:  0.795435\n",
      "--------------------------------------------------------------------------------\n",
      "Step 1840\n",
      "learning_rate: 0.00392839\n",
      "Training loss: 0.533376 , Training acc:  0.806977\n",
      "Test loss: 0.588111 , Test acc:  0.790786\n",
      "--------------------------------------------------------------------------------\n",
      "Step 1860\n",
      "learning_rate: 0.00392839\n",
      "Training loss: 0.457822 , Training acc:  0.845666\n",
      "Test loss: 0.519089 , Test acc:  0.817836\n",
      "--------------------------------------------------------------------------------\n",
      "Step 1880\n",
      "learning_rate: 0.00388911\n",
      "Training loss: 0.521182 , Training acc:  0.812474\n",
      "Test loss: 0.57597 , Test acc:  0.797126\n",
      "--------------------------------------------------------------------------------\n",
      "Step 1900\n",
      "learning_rate: 0.00388911\n",
      "Training loss: 0.452971 , Training acc:  0.844715\n",
      "Test loss: 0.506147 , Test acc:  0.822908\n",
      "--------------------------------------------------------------------------------\n",
      "Step 1920\n",
      "learning_rate: 0.00388911\n",
      "Training loss: 0.457432 , Training acc:  0.850634\n",
      "Test loss: 0.503679 , Test acc:  0.819949\n",
      "--------------------------------------------------------------------------------\n",
      "Step 1940\n",
      "learning_rate: 0.00388911\n",
      "Training loss: 0.450431 , Training acc:  0.845032\n",
      "Test loss: 0.500225 , Test acc:  0.824176\n",
      "--------------------------------------------------------------------------------\n",
      "Step 1960\n",
      "learning_rate: 0.00385022\n",
      "Training loss: 0.464995 , Training acc:  0.840698\n",
      "Test loss: 0.51567 , Test acc:  0.814032\n",
      "--------------------------------------------------------------------------------\n",
      "Step 1980\n",
      "learning_rate: 0.00385022\n",
      "Training loss: 0.473204 , Training acc:  0.823996\n",
      "Test loss: 0.524622 , Test acc:  0.80262\n",
      "--------------------------------------------------------------------------------\n",
      "Step 2000\n",
      "learning_rate: 0.00385022\n",
      "Training loss: 0.495197 , Training acc:  0.83351\n",
      "Test loss: 0.551065 , Test acc:  0.816145\n",
      "--------------------------------------------------------------------------------\n",
      "Step 2020\n",
      "learning_rate: 0.00385022\n",
      "Training loss: 0.439597 , Training acc:  0.853594\n",
      "Test loss: 0.500395 , Test acc:  0.823753\n",
      "--------------------------------------------------------------------------------\n",
      "Step 2040\n",
      "learning_rate: 0.00381171\n",
      "Training loss: 0.492549 , Training acc:  0.825793\n",
      "Test loss: 0.533132 , Test acc:  0.812764\n",
      "--------------------------------------------------------------------------------\n",
      "Step 2060\n",
      "learning_rate: 0.00381171\n",
      "Training loss: 0.495202 , Training acc:  0.83055\n",
      "Test loss: 0.559827 , Test acc:  0.803043\n",
      "--------------------------------------------------------------------------------\n",
      "Step 2080\n",
      "learning_rate: 0.00381171\n",
      "Training loss: 0.443294 , Training acc:  0.832135\n",
      "Test loss: 0.491973 , Test acc:  0.806002\n",
      "--------------------------------------------------------------------------------\n",
      "Step 2100\n",
      "learning_rate: 0.0037736\n",
      "Training loss: 0.431996 , Training acc:  0.854334\n",
      "Test loss: 0.479541 , Test acc:  0.836433\n",
      "--------------------------------------------------------------------------------\n",
      "Step 2120\n",
      "learning_rate: 0.0037736\n",
      "Training loss: 0.536322 , Training acc:  0.80296\n",
      "Test loss: 0.582483 , Test acc:  0.789518\n",
      "--------------------------------------------------------------------------------\n",
      "Step 2140\n",
      "learning_rate: 0.0037736\n",
      "Training loss: 0.431281 , Training acc:  0.854863\n",
      "Test loss: 0.472331 , Test acc:  0.841505\n",
      "--------------------------------------------------------------------------------\n",
      "Step 2160\n",
      "learning_rate: 0.0037736\n",
      "Training loss: 0.457126 , Training acc:  0.844609\n",
      "Test loss: 0.498497 , Test acc:  0.827557\n",
      "--------------------------------------------------------------------------------\n",
      "Step 2180\n",
      "learning_rate: 0.00373586\n",
      "Training loss: 0.414776 , Training acc:  0.855497\n",
      "Test loss: 0.467721 , Test acc:  0.831361\n",
      "--------------------------------------------------------------------------------\n",
      "Step 2200\n",
      "learning_rate: 0.00373586\n",
      "Training loss: 0.436313 , Training acc:  0.845772\n",
      "Test loss: 0.500686 , Test acc:  0.8153\n",
      "--------------------------------------------------------------------------------\n",
      "Step 2220\n",
      "learning_rate: 0.00373586\n",
      "Training loss: 0.400282 , Training acc:  0.862368\n",
      "Test loss: 0.458392 , Test acc:  0.836855\n",
      "--------------------------------------------------------------------------------\n",
      "Step 2240\n",
      "learning_rate: 0.00373586\n",
      "Training loss: 0.406452 , Training acc:  0.856025\n",
      "Test loss: 0.461038 , Test acc:  0.830093\n",
      "--------------------------------------------------------------------------------\n",
      "Step 2260\n",
      "learning_rate: 0.0036985\n",
      "Training loss: 0.51428 , Training acc:  0.819345\n",
      "Test loss: 0.556767 , Test acc:  0.804734\n",
      "--------------------------------------------------------------------------------\n",
      "Step 2280\n",
      "learning_rate: 0.0036985\n",
      "Training loss: 0.44652 , Training acc:  0.847357\n",
      "Test loss: 0.504858 , Test acc:  0.827557\n",
      "--------------------------------------------------------------------------------\n",
      "Step 2300\n",
      "learning_rate: 0.0036985\n",
      "Training loss: 0.477598 , Training acc:  0.833932\n",
      "Test loss: 0.530517 , Test acc:  0.807692\n",
      "--------------------------------------------------------------------------------\n",
      "Step 2320\n",
      "learning_rate: 0.0036985\n",
      "Training loss: 0.427836 , Training acc:  0.85666\n",
      "Test loss: 0.467378 , Test acc:  0.842773\n",
      "--------------------------------------------------------------------------------\n",
      "Step 2340\n",
      "learning_rate: 0.00366152\n",
      "Training loss: 0.416775 , Training acc:  0.871565\n",
      "Test loss: 0.464133 , Test acc:  0.85038\n",
      "--------------------------------------------------------------------------------\n",
      "Step 2360\n",
      "learning_rate: 0.00366152\n",
      "Training loss: 0.389306 , Training acc:  0.868182\n",
      "Test loss: 0.433025 , Test acc:  0.849112\n",
      "--------------------------------------------------------------------------------\n",
      "Step 2380\n",
      "learning_rate: 0.00366152\n",
      "Training loss: 0.405859 , Training acc:  0.864905\n",
      "Test loss: 0.458877 , Test acc:  0.83601\n",
      "--------------------------------------------------------------------------------\n",
      "Step 2400\n",
      "learning_rate: 0.0036249\n",
      "Training loss: 0.394814 , Training acc:  0.858668\n",
      "Test loss: 0.446003 , Test acc:  0.838123\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2420\n",
      "learning_rate: 0.0036249\n",
      "Training loss: 0.400433 , Training acc:  0.86945\n",
      "Test loss: 0.454099 , Test acc:  0.844463\n",
      "--------------------------------------------------------------------------------\n",
      "Step 2440\n",
      "learning_rate: 0.0036249\n",
      "Training loss: 0.420239 , Training acc:  0.859514\n",
      "Test loss: 0.479157 , Test acc:  0.83432\n",
      "--------------------------------------------------------------------------------\n",
      "Step 2460\n",
      "learning_rate: 0.0036249\n",
      "Training loss: 0.43552 , Training acc:  0.842178\n",
      "Test loss: 0.481919 , Test acc:  0.828825\n",
      "--------------------------------------------------------------------------------\n",
      "Step 2480\n",
      "learning_rate: 0.00358865\n",
      "Training loss: 0.386599 , Training acc:  0.866173\n",
      "Test loss: 0.441375 , Test acc:  0.844463\n",
      "--------------------------------------------------------------------------------\n",
      "Step 2500\n",
      "learning_rate: 0.00358865\n",
      "Training loss: 0.400215 , Training acc:  0.863636\n",
      "Test loss: 0.459854 , Test acc:  0.838546\n",
      "--------------------------------------------------------------------------------\n",
      "Step 2520\n",
      "learning_rate: 0.00358865\n",
      "Training loss: 0.368483 , Training acc:  0.879598\n",
      "Test loss: 0.429582 , Test acc:  0.852916\n",
      "--------------------------------------------------------------------------------\n",
      "Step 2540\n",
      "learning_rate: 0.00358865\n",
      "Training loss: 0.420253 , Training acc:  0.861839\n",
      "Test loss: 0.48295 , Test acc:  0.835588\n",
      "--------------------------------------------------------------------------------\n",
      "Step 2560\n",
      "learning_rate: 0.00355277\n",
      "Training loss: 0.408029 , Training acc:  0.863636\n",
      "Test loss: 0.473278 , Test acc:  0.838546\n",
      "--------------------------------------------------------------------------------\n",
      "Step 2580\n",
      "learning_rate: 0.00355277\n",
      "Training loss: 0.432678 , Training acc:  0.852008\n",
      "Test loss: 0.495405 , Test acc:  0.822908\n",
      "--------------------------------------------------------------------------------\n",
      "Step 2600\n",
      "learning_rate: 0.00355277\n",
      "Training loss: 0.339813 , Training acc:  0.886047\n",
      "Test loss: 0.404674 , Test acc:  0.857988\n",
      "--------------------------------------------------------------------------------\n",
      "Step 2620\n",
      "learning_rate: 0.00355277\n",
      "Training loss: 0.364788 , Training acc:  0.881078\n",
      "Test loss: 0.427826 , Test acc:  0.850803\n",
      "--------------------------------------------------------------------------------\n",
      "Step 2640\n",
      "learning_rate: 0.00351724\n",
      "Training loss: 0.348645 , Training acc:  0.880233\n",
      "Test loss: 0.412567 , Test acc:  0.845309\n",
      "--------------------------------------------------------------------------------\n",
      "Step 2660\n",
      "learning_rate: 0.00351724\n",
      "Training loss: 0.382547 , Training acc:  0.87389\n",
      "Test loss: 0.435645 , Test acc:  0.846577\n",
      "--------------------------------------------------------------------------------\n",
      "Step 2680\n",
      "learning_rate: 0.00351724\n",
      "Training loss: 0.344895 , Training acc:  0.885729\n",
      "Test loss: 0.396801 , Test acc:  0.860524\n",
      "--------------------------------------------------------------------------------\n",
      "Step 2700\n",
      "learning_rate: 0.00348207\n",
      "Training loss: 0.374165 , Training acc:  0.871776\n",
      "Test loss: 0.432529 , Test acc:  0.847422\n",
      "--------------------------------------------------------------------------------\n",
      "Step 2720\n",
      "learning_rate: 0.00348207\n",
      "Training loss: 0.351252 , Training acc:  0.882558\n",
      "Test loss: 0.413062 , Test acc:  0.850803\n",
      "--------------------------------------------------------------------------------\n",
      "Step 2740\n",
      "learning_rate: 0.00348207\n",
      "Training loss: 0.336391 , Training acc:  0.892389\n",
      "Test loss: 0.392238 , Test acc:  0.865173\n",
      "--------------------------------------------------------------------------------\n",
      "Step 2760\n",
      "learning_rate: 0.00348207\n",
      "Training loss: 0.355041 , Training acc:  0.880444\n",
      "Test loss: 0.415413 , Test acc:  0.855875\n",
      "--------------------------------------------------------------------------------\n",
      "Step 2780\n",
      "learning_rate: 0.00344725\n",
      "Training loss: 0.364123 , Training acc:  0.877273\n",
      "Test loss: 0.426899 , Test acc:  0.857988\n",
      "--------------------------------------------------------------------------------\n",
      "Step 2800\n",
      "learning_rate: 0.00344725\n",
      "Training loss: 0.396132 , Training acc:  0.866068\n",
      "Test loss: 0.46336 , Test acc:  0.836855\n",
      "--------------------------------------------------------------------------------\n",
      "Step 2820\n",
      "learning_rate: 0.00344725\n",
      "Training loss: 0.388135 , Training acc:  0.869767\n",
      "Test loss: 0.44953 , Test acc:  0.843195\n",
      "--------------------------------------------------------------------------------\n",
      "Step 2840\n",
      "learning_rate: 0.00344725\n",
      "Training loss: 0.356677 , Training acc:  0.879387\n",
      "Test loss: 0.419958 , Test acc:  0.852494\n",
      "--------------------------------------------------------------------------------\n",
      "Step 2860\n",
      "learning_rate: 0.00341277\n",
      "Training loss: 0.367218 , Training acc:  0.869767\n",
      "Test loss: 0.428568 , Test acc:  0.846154\n",
      "--------------------------------------------------------------------------------\n",
      "Step 2880\n",
      "learning_rate: 0.00341277\n",
      "Training loss: 0.405524 , Training acc:  0.862474\n",
      "Test loss: 0.466653 , Test acc:  0.833052\n",
      "--------------------------------------------------------------------------------\n",
      "Step 2900\n",
      "learning_rate: 0.00341277\n",
      "Training loss: 0.373779 , Training acc:  0.879598\n",
      "Test loss: 0.43442 , Test acc:  0.85038\n",
      "--------------------------------------------------------------------------------\n",
      "Step 2920\n",
      "learning_rate: 0.00341277\n",
      "Training loss: 0.340225 , Training acc:  0.881184\n",
      "Test loss: 0.393562 , Test acc:  0.857143\n",
      "--------------------------------------------------------------------------------\n",
      "Step 2940\n",
      "learning_rate: 0.00337865\n",
      "Training loss: 0.358064 , Training acc:  0.879915\n",
      "Test loss: 0.41911 , Test acc:  0.848267\n",
      "--------------------------------------------------------------------------------\n",
      "Step 2960\n",
      "learning_rate: 0.00337865\n",
      "Training loss: 0.321619 , Training acc:  0.893129\n",
      "Test loss: 0.389125 , Test acc:  0.857143\n",
      "--------------------------------------------------------------------------------\n",
      "Step 2980\n",
      "learning_rate: 0.00337865\n",
      "Training loss: 0.320402 , Training acc:  0.89704\n",
      "Test loss: 0.387292 , Test acc:  0.870245\n",
      "--------------------------------------------------------------------------------\n",
      "Step 3000\n",
      "learning_rate: 0.00334486\n",
      "Training loss: 0.31775 , Training acc:  0.892706\n",
      "Test loss: 0.383432 , Test acc:  0.865596\n",
      "--------------------------------------------------------------------------------\n",
      "Step 3020\n",
      "learning_rate: 0.00334486\n",
      "Training loss: 0.36249 , Training acc:  0.874101\n",
      "Test loss: 0.42006 , Test acc:  0.851226\n",
      "--------------------------------------------------------------------------------\n",
      "Step 3040\n",
      "learning_rate: 0.00334486\n",
      "Training loss: 0.317689 , Training acc:  0.895772\n",
      "Test loss: 0.381419 , Test acc:  0.865173\n",
      "--------------------------------------------------------------------------------\n",
      "Step 3060\n",
      "learning_rate: 0.00334486\n",
      "Training loss: 0.345207 , Training acc:  0.893658\n",
      "Test loss: 0.398643 , Test acc:  0.866864\n",
      "--------------------------------------------------------------------------------\n",
      "Step 3080\n",
      "learning_rate: 0.00331141\n",
      "Training loss: 0.309589 , Training acc:  0.899577\n",
      "Test loss: 0.380941 , Test acc:  0.871936\n",
      "--------------------------------------------------------------------------------\n",
      "Step 3100\n",
      "learning_rate: 0.00331141\n",
      "Training loss: 0.295674 , Training acc:  0.903171\n",
      "Test loss: 0.366091 , Test acc:  0.874894\n",
      "--------------------------------------------------------------------------------\n",
      "Step 3120\n",
      "learning_rate: 0.00331141\n",
      "Training loss: 0.282631 , Training acc:  0.908351\n",
      "Test loss: 0.347782 , Test acc:  0.878698\n",
      "--------------------------------------------------------------------------------\n",
      "Step 3140\n",
      "learning_rate: 0.00331141\n",
      "Training loss: 0.311723 , Training acc:  0.898414\n",
      "Test loss: 0.374877 , Test acc:  0.867287\n",
      "--------------------------------------------------------------------------------\n",
      "Step 3160\n",
      "learning_rate: 0.0032783\n",
      "Training loss: 0.336264 , Training acc:  0.889218\n",
      "Test loss: 0.40723 , Test acc:  0.857143\n",
      "--------------------------------------------------------------------------------\n",
      "Step 3180\n",
      "learning_rate: 0.0032783\n",
      "Training loss: 0.398148 , Training acc:  0.862579\n",
      "Test loss: 0.465753 , Test acc:  0.833474\n",
      "--------------------------------------------------------------------------------\n",
      "Step 3200\n",
      "learning_rate: 0.0032783\n",
      "Training loss: 0.319514 , Training acc:  0.898203\n",
      "Test loss: 0.384306 , Test acc:  0.87109\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3220\n",
      "learning_rate: 0.0032783\n",
      "Training loss: 0.337421 , Training acc:  0.891226\n",
      "Test loss: 0.411143 , Test acc:  0.85672\n",
      "--------------------------------------------------------------------------------\n",
      "Step 3240\n",
      "learning_rate: 0.00324551\n",
      "Training loss: 0.286892 , Training acc:  0.905497\n",
      "Test loss: 0.349123 , Test acc:  0.87109\n",
      "--------------------------------------------------------------------------------\n",
      "Step 3260\n",
      "learning_rate: 0.00324551\n",
      "Training loss: 0.329975 , Training acc:  0.8963\n",
      "Test loss: 0.401588 , Test acc:  0.863483\n",
      "--------------------------------------------------------------------------------\n",
      "Step 3280\n",
      "learning_rate: 0.00324551\n",
      "Training loss: 0.332315 , Training acc:  0.884567\n",
      "Test loss: 0.399381 , Test acc:  0.857143\n",
      "--------------------------------------------------------------------------------\n",
      "Step 3300\n",
      "learning_rate: 0.00321306\n",
      "Training loss: 0.310175 , Training acc:  0.893235\n",
      "Test loss: 0.385774 , Test acc:  0.864328\n",
      "--------------------------------------------------------------------------------\n",
      "Step 3320\n",
      "learning_rate: 0.00321306\n",
      "Training loss: 0.304776 , Training acc:  0.894292\n",
      "Test loss: 0.378757 , Test acc:  0.862215\n",
      "--------------------------------------------------------------------------------\n",
      "Step 3340\n",
      "learning_rate: 0.00321306\n",
      "Training loss: 0.285969 , Training acc:  0.901797\n",
      "Test loss: 0.354077 , Test acc:  0.868555\n",
      "--------------------------------------------------------------------------------\n",
      "Step 3360\n",
      "learning_rate: 0.00321306\n",
      "Training loss: 0.285242 , Training acc:  0.901057\n",
      "Test loss: 0.354435 , Test acc:  0.87109\n",
      "--------------------------------------------------------------------------------\n",
      "Step 3380\n",
      "learning_rate: 0.00318093\n",
      "Training loss: 0.281754 , Training acc:  0.907822\n",
      "Test loss: 0.342637 , Test acc:  0.87743\n",
      "--------------------------------------------------------------------------------\n",
      "Step 3400\n",
      "learning_rate: 0.00318093\n",
      "Training loss: 0.338464 , Training acc:  0.883404\n",
      "Test loss: 0.40495 , Test acc:  0.860947\n",
      "--------------------------------------------------------------------------------\n",
      "Step 3420\n",
      "learning_rate: 0.00318093\n",
      "Training loss: 0.292902 , Training acc:  0.897463\n",
      "Test loss: 0.36945 , Test acc:  0.866441\n",
      "--------------------------------------------------------------------------------\n",
      "Step 3440\n",
      "learning_rate: 0.00318093\n",
      "Training loss: 0.314428 , Training acc:  0.894186\n",
      "Test loss: 0.390273 , Test acc:  0.861792\n",
      "--------------------------------------------------------------------------------\n",
      "Step 3460\n",
      "learning_rate: 0.00314912\n",
      "Training loss: 0.269467 , Training acc:  0.913742\n",
      "Test loss: 0.343837 , Test acc:  0.879121\n",
      "--------------------------------------------------------------------------------\n",
      "Step 3480\n",
      "learning_rate: 0.00314912\n",
      "Training loss: 0.283693 , Training acc:  0.906871\n",
      "Test loss: 0.346167 , Test acc:  0.877008\n",
      "--------------------------------------------------------------------------------\n",
      "Step 3500\n",
      "learning_rate: 0.00314912\n",
      "Training loss: 0.278084 , Training acc:  0.909091\n",
      "Test loss: 0.352857 , Test acc:  0.868555\n",
      "--------------------------------------------------------------------------------\n",
      "Step 3520\n",
      "learning_rate: 0.00314912\n",
      "Training loss: 0.261482 , Training acc:  0.915011\n",
      "Test loss: 0.337016 , Test acc:  0.878698\n",
      "--------------------------------------------------------------------------------\n",
      "Step 3540\n",
      "learning_rate: 0.00311763\n",
      "Training loss: 0.285718 , Training acc:  0.908774\n",
      "Test loss: 0.363487 , Test acc:  0.87109\n",
      "--------------------------------------------------------------------------------\n",
      "Step 3560\n",
      "learning_rate: 0.00311763\n",
      "Training loss: 0.289088 , Training acc:  0.904651\n",
      "Test loss: 0.367005 , Test acc:  0.868132\n",
      "--------------------------------------------------------------------------------\n",
      "Step 3580\n",
      "learning_rate: 0.00311763\n",
      "Training loss: 0.284638 , Training acc:  0.898309\n",
      "Test loss: 0.360036 , Test acc:  0.871936\n",
      "--------------------------------------------------------------------------------\n",
      "Step 3600\n",
      "learning_rate: 0.00308645\n",
      "Training loss: 0.273078 , Training acc:  0.902008\n",
      "Test loss: 0.349667 , Test acc:  0.87109\n",
      "--------------------------------------------------------------------------------\n",
      "Step 3620\n",
      "learning_rate: 0.00308645\n",
      "Training loss: 0.250895 , Training acc:  0.918499\n",
      "Test loss: 0.32108 , Test acc:  0.883347\n",
      "--------------------------------------------------------------------------------\n",
      "Step 3640\n",
      "learning_rate: 0.00308645\n",
      "Training loss: 0.240291 , Training acc:  0.924207\n",
      "Test loss: 0.312827 , Test acc:  0.885883\n",
      "--------------------------------------------------------------------------------\n",
      "Step 3660\n",
      "learning_rate: 0.00308645\n",
      "Training loss: 0.263654 , Training acc:  0.908457\n",
      "Test loss: 0.343329 , Test acc:  0.874472\n",
      "--------------------------------------------------------------------------------\n",
      "Step 3680\n",
      "learning_rate: 0.00305559\n",
      "Training loss: 0.253675 , Training acc:  0.91723\n",
      "Test loss: 0.332468 , Test acc:  0.886306\n",
      "--------------------------------------------------------------------------------\n",
      "Step 3700\n",
      "learning_rate: 0.00305559\n",
      "Training loss: 0.265001 , Training acc:  0.915222\n",
      "Test loss: 0.339338 , Test acc:  0.886729\n",
      "--------------------------------------------------------------------------------\n",
      "Step 3720\n",
      "learning_rate: 0.00305559\n",
      "Training loss: 0.301497 , Training acc:  0.896089\n",
      "Test loss: 0.37213 , Test acc:  0.866441\n",
      "--------------------------------------------------------------------------------\n",
      "Step 3740\n",
      "learning_rate: 0.00305559\n",
      "Training loss: 0.26533 , Training acc:  0.910465\n",
      "Test loss: 0.341446 , Test acc:  0.873204\n",
      "--------------------------------------------------------------------------------\n",
      "Step 3760\n",
      "learning_rate: 0.00302503\n",
      "Training loss: 0.246681 , Training acc:  0.91723\n",
      "Test loss: 0.321511 , Test acc:  0.881657\n",
      "--------------------------------------------------------------------------------\n",
      "Step 3780\n",
      "learning_rate: 0.00302503\n",
      "Training loss: 0.266961 , Training acc:  0.908034\n",
      "Test loss: 0.345809 , Test acc:  0.869823\n",
      "--------------------------------------------------------------------------------\n",
      "Step 3800\n",
      "learning_rate: 0.00302503\n",
      "Training loss: 0.2672 , Training acc:  0.912896\n",
      "Test loss: 0.338223 , Test acc:  0.876162\n",
      "--------------------------------------------------------------------------------\n",
      "Step 3820\n",
      "learning_rate: 0.00302503\n",
      "Training loss: 0.264426 , Training acc:  0.915011\n",
      "Test loss: 0.334942 , Test acc:  0.878698\n",
      "--------------------------------------------------------------------------------\n",
      "Step 3840\n",
      "learning_rate: 0.00299478\n",
      "Training loss: 0.264491 , Training acc:  0.913636\n",
      "Test loss: 0.338961 , Test acc:  0.876585\n",
      "--------------------------------------------------------------------------------\n",
      "Step 3860\n",
      "learning_rate: 0.00299478\n",
      "Training loss: 0.229703 , Training acc:  0.928013\n",
      "Test loss: 0.305229 , Test acc:  0.89011\n",
      "--------------------------------------------------------------------------------\n",
      "Step 3880\n",
      "learning_rate: 0.00299478\n",
      "Training loss: 0.218592 , Training acc:  0.92685\n",
      "Test loss: 0.294806 , Test acc:  0.89011\n",
      "--------------------------------------------------------------------------------\n",
      "Step 3900\n",
      "learning_rate: 0.00296483\n",
      "Training loss: 0.221602 , Training acc:  0.92389\n",
      "Test loss: 0.298652 , Test acc:  0.891801\n",
      "--------------------------------------------------------------------------------\n",
      "Step 3920\n",
      "learning_rate: 0.00296483\n",
      "Training loss: 0.225132 , Training acc:  0.924841\n",
      "Test loss: 0.309056 , Test acc:  0.896027\n",
      "--------------------------------------------------------------------------------\n",
      "Step 3940\n",
      "learning_rate: 0.00296483\n",
      "Training loss: 0.230133 , Training acc:  0.923467\n",
      "Test loss: 0.319617 , Test acc:  0.885461\n",
      "--------------------------------------------------------------------------------\n",
      "Step 3960\n",
      "learning_rate: 0.00296483\n",
      "Training loss: 0.248121 , Training acc:  0.920085\n",
      "Test loss: 0.325331 , Test acc:  0.887574\n",
      "--------------------------------------------------------------------------------\n",
      "Step 3980\n",
      "learning_rate: 0.00293519\n",
      "Training loss: 0.249058 , Training acc:  0.914799\n",
      "Test loss: 0.340485 , Test acc:  0.874472\n",
      "--------------------------------------------------------------------------------\n",
      "Step 4000\n",
      "learning_rate: 0.00293519\n",
      "Training loss: 0.223424 , Training acc:  0.925264\n",
      "Test loss: 0.298682 , Test acc:  0.889265\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4020\n",
      "learning_rate: 0.00293519\n",
      "Training loss: 0.244103 , Training acc:  0.919028\n",
      "Test loss: 0.326432 , Test acc:  0.881234\n",
      "--------------------------------------------------------------------------------\n",
      "Step 4040\n",
      "learning_rate: 0.00293519\n",
      "Training loss: 0.242637 , Training acc:  0.917019\n",
      "Test loss: 0.321173 , Test acc:  0.881234\n",
      "--------------------------------------------------------------------------------\n",
      "Step 4060\n",
      "learning_rate: 0.00290583\n",
      "Training loss: 0.235542 , Training acc:  0.923256\n",
      "Test loss: 0.308768 , Test acc:  0.896027\n",
      "--------------------------------------------------------------------------------\n",
      "Step 4080\n",
      "learning_rate: 0.00290583\n",
      "Training loss: 0.224404 , Training acc:  0.929175\n",
      "Test loss: 0.310572 , Test acc:  0.888842\n",
      "--------------------------------------------------------------------------------\n",
      "Step 4100\n",
      "learning_rate: 0.00290583\n",
      "Training loss: 0.26929 , Training acc:  0.909725\n",
      "Test loss: 0.351801 , Test acc:  0.880812\n",
      "--------------------------------------------------------------------------------\n",
      "Step 4120\n",
      "learning_rate: 0.00290583\n",
      "Training loss: 0.243901 , Training acc:  0.921564\n",
      "Test loss: 0.32814 , Test acc:  0.883347\n",
      "--------------------------------------------------------------------------------\n",
      "Step 4140\n",
      "learning_rate: 0.00287678\n",
      "Training loss: 0.230526 , Training acc:  0.924947\n",
      "Test loss: 0.31125 , Test acc:  0.888842\n",
      "--------------------------------------------------------------------------------\n",
      "Step 4160\n",
      "learning_rate: 0.00287678\n",
      "Training loss: 0.222483 , Training acc:  0.925159\n",
      "Test loss: 0.309484 , Test acc:  0.887997\n",
      "--------------------------------------------------------------------------------\n",
      "Step 4180\n",
      "learning_rate: 0.00287678\n",
      "Training loss: 0.216114 , Training acc:  0.929704\n",
      "Test loss: 0.301841 , Test acc:  0.893068\n",
      "--------------------------------------------------------------------------------\n",
      "Step 4200\n",
      "learning_rate: 0.00284801\n",
      "Training loss: 0.222855 , Training acc:  0.925476\n",
      "Test loss: 0.309371 , Test acc:  0.890955\n",
      "--------------------------------------------------------------------------------\n",
      "Step 4220\n",
      "learning_rate: 0.00284801\n",
      "Training loss: 0.209053 , Training acc:  0.92759\n",
      "Test loss: 0.298639 , Test acc:  0.895604\n",
      "--------------------------------------------------------------------------------\n",
      "Step 4240\n",
      "learning_rate: 0.00284801\n",
      "Training loss: 0.195727 , Training acc:  0.936786\n",
      "Test loss: 0.278314 , Test acc:  0.905325\n",
      "--------------------------------------------------------------------------------\n",
      "Step 4260\n",
      "learning_rate: 0.00284801\n",
      "Training loss: 0.212543 , Training acc:  0.933827\n",
      "Test loss: 0.294492 , Test acc:  0.903635\n",
      "--------------------------------------------------------------------------------\n",
      "Step 4280\n",
      "learning_rate: 0.00281953\n",
      "Training loss: 0.197764 , Training acc:  0.933192\n",
      "Test loss: 0.289588 , Test acc:  0.898986\n",
      "--------------------------------------------------------------------------------\n",
      "Step 4300\n",
      "learning_rate: 0.00281953\n",
      "Training loss: 0.221924 , Training acc:  0.927273\n",
      "Test loss: 0.309604 , Test acc:  0.894336\n",
      "--------------------------------------------------------------------------------\n",
      "Step 4320\n",
      "learning_rate: 0.00281953\n",
      "Training loss: 0.222772 , Training acc:  0.922622\n",
      "Test loss: 0.318708 , Test acc:  0.886729\n",
      "--------------------------------------------------------------------------------\n",
      "Step 4340\n",
      "learning_rate: 0.00281953\n",
      "Training loss: 0.209196 , Training acc:  0.933192\n",
      "Test loss: 0.296033 , Test acc:  0.892223\n",
      "--------------------------------------------------------------------------------\n",
      "Step 4360\n",
      "learning_rate: 0.00279133\n",
      "Training loss: 0.253374 , Training acc:  0.91649\n",
      "Test loss: 0.34732 , Test acc:  0.876162\n",
      "--------------------------------------------------------------------------------\n",
      "Step 4380\n",
      "learning_rate: 0.00279133\n",
      "Training loss: 0.227029 , Training acc:  0.929493\n",
      "Test loss: 0.311209 , Test acc:  0.892223\n",
      "--------------------------------------------------------------------------------\n",
      "Step 4400\n",
      "learning_rate: 0.00279133\n",
      "Training loss: 0.209726 , Training acc:  0.938478\n",
      "Test loss: 0.30471 , Test acc:  0.894759\n",
      "--------------------------------------------------------------------------------\n",
      "Step 4420\n",
      "learning_rate: 0.00279133\n",
      "Training loss: 0.217313 , Training acc:  0.931395\n",
      "Test loss: 0.314419 , Test acc:  0.888419\n",
      "--------------------------------------------------------------------------------\n",
      "Step 4440\n",
      "learning_rate: 0.00276342\n",
      "Training loss: 0.207241 , Training acc:  0.933192\n",
      "Test loss: 0.297813 , Test acc:  0.892646\n",
      "--------------------------------------------------------------------------------\n",
      "Step 4460\n",
      "learning_rate: 0.00276342\n",
      "Training loss: 0.220641 , Training acc:  0.927378\n",
      "Test loss: 0.317578 , Test acc:  0.882502\n",
      "--------------------------------------------------------------------------------\n",
      "Step 4480\n",
      "learning_rate: 0.00276342\n",
      "Training loss: 0.210639 , Training acc:  0.935201\n",
      "Test loss: 0.298459 , Test acc:  0.891801\n",
      "--------------------------------------------------------------------------------\n",
      "Step 4500\n",
      "learning_rate: 0.00273578\n",
      "Training loss: 0.198578 , Training acc:  0.939429\n",
      "Test loss: 0.288725 , Test acc:  0.89645\n",
      "--------------------------------------------------------------------------------\n",
      "Step 4520\n",
      "learning_rate: 0.00273578\n",
      "Training loss: 0.2044 , Training acc:  0.932135\n",
      "Test loss: 0.294336 , Test acc:  0.893491\n",
      "--------------------------------------------------------------------------------\n",
      "Step 4540\n",
      "learning_rate: 0.00273578\n",
      "Training loss: 0.215265 , Training acc:  0.933192\n",
      "Test loss: 0.304807 , Test acc:  0.895604\n",
      "--------------------------------------------------------------------------------\n",
      "Step 4560\n",
      "learning_rate: 0.00273578\n",
      "Training loss: 0.211488 , Training acc:  0.935518\n",
      "Test loss: 0.300473 , Test acc:  0.893914\n",
      "--------------------------------------------------------------------------------\n",
      "Step 4580\n",
      "learning_rate: 0.00270843\n",
      "Training loss: 0.203827 , Training acc:  0.934355\n",
      "Test loss: 0.302037 , Test acc:  0.887151\n",
      "--------------------------------------------------------------------------------\n",
      "Step 4600\n",
      "learning_rate: 0.00270843\n",
      "Training loss: 0.221162 , Training acc:  0.924524\n",
      "Test loss: 0.311089 , Test acc:  0.892223\n",
      "--------------------------------------------------------------------------------\n",
      "Step 4620\n",
      "learning_rate: 0.00270843\n",
      "Training loss: 0.225741 , Training acc:  0.927378\n",
      "Test loss: 0.32394 , Test acc:  0.888842\n",
      "--------------------------------------------------------------------------------\n",
      "Step 4640\n",
      "learning_rate: 0.00270843\n",
      "Training loss: 0.211121 , Training acc:  0.926216\n",
      "Test loss: 0.302092 , Test acc:  0.893491\n",
      "--------------------------------------------------------------------------------\n",
      "Step 4660\n",
      "learning_rate: 0.00268134\n",
      "Training loss: 0.199238 , Training acc:  0.937949\n",
      "Test loss: 0.293716 , Test acc:  0.896872\n",
      "--------------------------------------------------------------------------------\n",
      "Step 4680\n",
      "learning_rate: 0.00268134\n",
      "Training loss: 0.181545 , Training acc:  0.938372\n",
      "Test loss: 0.28113 , Test acc:  0.894759\n",
      "--------------------------------------------------------------------------------\n",
      "Step 4700\n",
      "learning_rate: 0.00268134\n",
      "Training loss: 0.206218 , Training acc:  0.934461\n",
      "Test loss: 0.302183 , Test acc:  0.891378\n",
      "--------------------------------------------------------------------------------\n",
      "Step 4720\n",
      "learning_rate: 0.00268134\n",
      "Training loss: 0.226253 , Training acc:  0.927378\n",
      "Test loss: 0.309758 , Test acc:  0.899408\n",
      "--------------------------------------------------------------------------------\n",
      "Step 4740\n",
      "learning_rate: 0.00265453\n",
      "Training loss: 0.175788 , Training acc:  0.947252\n",
      "Test loss: 0.271864 , Test acc:  0.906593\n",
      "--------------------------------------------------------------------------------\n",
      "Step 4760\n",
      "learning_rate: 0.00265453\n",
      "Training loss: 0.176911 , Training acc:  0.943658\n",
      "Test loss: 0.275915 , Test acc:  0.904903\n",
      "--------------------------------------------------------------------------------\n",
      "Step 4780\n",
      "learning_rate: 0.00265453\n",
      "Training loss: 0.169836 , Training acc:  0.945666\n",
      "Test loss: 0.263585 , Test acc:  0.904058\n",
      "--------------------------------------------------------------------------------\n",
      "Step 4800\n",
      "learning_rate: 0.00262798\n",
      "Training loss: 0.174796 , Training acc:  0.94334\n",
      "Test loss: 0.27287 , Test acc:  0.900676\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4820\n",
      "learning_rate: 0.00262798\n",
      "Training loss: 0.173963 , Training acc:  0.944609\n",
      "Test loss: 0.269779 , Test acc:  0.902367\n",
      "--------------------------------------------------------------------------------\n",
      "Step 4840\n",
      "learning_rate: 0.00262798\n",
      "Training loss: 0.208332 , Training acc:  0.932981\n",
      "Test loss: 0.298573 , Test acc:  0.897295\n",
      "--------------------------------------------------------------------------------\n",
      "Step 4860\n",
      "learning_rate: 0.00262798\n",
      "Training loss: 0.179093 , Training acc:  0.944715\n",
      "Test loss: 0.277249 , Test acc:  0.907439\n",
      "--------------------------------------------------------------------------------\n",
      "Step 4880\n",
      "learning_rate: 0.0026017\n",
      "Training loss: 0.175089 , Training acc:  0.944503\n",
      "Test loss: 0.271665 , Test acc:  0.906171\n",
      "--------------------------------------------------------------------------------\n",
      "Step 4900\n",
      "learning_rate: 0.0026017\n",
      "Training loss: 0.190102 , Training acc:  0.939112\n",
      "Test loss: 0.278614 , Test acc:  0.900254\n",
      "--------------------------------------------------------------------------------\n",
      "Step 4920\n",
      "learning_rate: 0.0026017\n",
      "Training loss: 0.207459 , Training acc:  0.934672\n",
      "Test loss: 0.294629 , Test acc:  0.901099\n",
      "--------------------------------------------------------------------------------\n",
      "Step 4940\n",
      "learning_rate: 0.0026017\n",
      "Training loss: 0.18821 , Training acc:  0.943552\n",
      "Test loss: 0.283987 , Test acc:  0.906593\n",
      "--------------------------------------------------------------------------------\n",
      "Step 4960\n",
      "learning_rate: 0.00257569\n",
      "Training loss: 0.179681 , Training acc:  0.941332\n",
      "Test loss: 0.271157 , Test acc:  0.907439\n",
      "--------------------------------------------------------------------------------\n",
      "Step 4980\n",
      "learning_rate: 0.00257569\n",
      "Training loss: 0.204578 , Training acc:  0.939112\n",
      "Test loss: 0.299152 , Test acc:  0.900676\n",
      "--------------------------------------------------------------------------------\n",
      "Step 5000\n",
      "learning_rate: 0.00257569\n",
      "Training loss: 0.194176 , Training acc:  0.945455\n",
      "Test loss: 0.297373 , Test acc:  0.896872\n",
      "--------------------------------------------------------------------------------\n",
      "Step 5020\n",
      "learning_rate: 0.00257569\n",
      "Training loss: 0.205574 , Training acc:  0.93055\n",
      "Test loss: 0.308992 , Test acc:  0.890533\n",
      "--------------------------------------------------------------------------------\n",
      "Step 5040\n",
      "learning_rate: 0.00254993\n",
      "Training loss: 0.170052 , Training acc:  0.941543\n",
      "Test loss: 0.272822 , Test acc:  0.89814\n",
      "--------------------------------------------------------------------------------\n",
      "Step 5060\n",
      "learning_rate: 0.00254993\n",
      "Training loss: 0.16307 , Training acc:  0.946617\n",
      "Test loss: 0.267742 , Test acc:  0.904903\n",
      "--------------------------------------------------------------------------------\n",
      "Step 5080\n",
      "learning_rate: 0.00254993\n",
      "Training loss: 0.181914 , Training acc:  0.942706\n",
      "Test loss: 0.284445 , Test acc:  0.899408\n",
      "--------------------------------------------------------------------------------\n",
      "Step 5100\n",
      "learning_rate: 0.00252443\n",
      "Training loss: 0.170238 , Training acc:  0.951268\n",
      "Test loss: 0.271453 , Test acc:  0.901944\n",
      "--------------------------------------------------------------------------------\n",
      "Step 5120\n",
      "learning_rate: 0.00252443\n",
      "Training loss: 0.16847 , Training acc:  0.94852\n",
      "Test loss: 0.267618 , Test acc:  0.908284\n",
      "--------------------------------------------------------------------------------\n",
      "Step 5140\n",
      "learning_rate: 0.00252443\n",
      "Training loss: 0.183976 , Training acc:  0.942495\n",
      "Test loss: 0.281765 , Test acc:  0.899831\n",
      "--------------------------------------------------------------------------------\n",
      "Step 5160\n",
      "learning_rate: 0.00252443\n",
      "Training loss: 0.166584 , Training acc:  0.949683\n",
      "Test loss: 0.270321 , Test acc:  0.904903\n",
      "--------------------------------------------------------------------------------\n",
      "Step 5180\n",
      "learning_rate: 0.00249919\n",
      "Training loss: 0.162982 , Training acc:  0.949154\n",
      "Test loss: 0.263652 , Test acc:  0.904903\n",
      "--------------------------------------------------------------------------------\n",
      "Step 5200\n",
      "learning_rate: 0.00249919\n",
      "Training loss: 0.171538 , Training acc:  0.94704\n",
      "Test loss: 0.276468 , Test acc:  0.903212\n",
      "--------------------------------------------------------------------------------\n",
      "Step 5220\n",
      "learning_rate: 0.00249919\n",
      "Training loss: 0.17293 , Training acc:  0.942283\n",
      "Test loss: 0.274012 , Test acc:  0.902367\n",
      "--------------------------------------------------------------------------------\n",
      "Step 5240\n",
      "learning_rate: 0.00249919\n",
      "Training loss: 0.157539 , Training acc:  0.953488\n",
      "Test loss: 0.259076 , Test acc:  0.911243\n",
      "--------------------------------------------------------------------------------\n",
      "Step 5260\n",
      "learning_rate: 0.00247419\n",
      "Training loss: 0.161944 , Training acc:  0.951586\n",
      "Test loss: 0.265557 , Test acc:  0.903635\n",
      "--------------------------------------------------------------------------------\n",
      "Step 5280\n",
      "learning_rate: 0.00247419\n",
      "Training loss: 0.190844 , Training acc:  0.935201\n",
      "Test loss: 0.297807 , Test acc:  0.894759\n",
      "--------------------------------------------------------------------------------\n",
      "Step 5300\n",
      "learning_rate: 0.00247419\n",
      "Training loss: 0.180579 , Training acc:  0.939641\n",
      "Test loss: 0.292448 , Test acc:  0.894759\n",
      "--------------------------------------------------------------------------------\n",
      "Step 5320\n",
      "learning_rate: 0.00247419\n",
      "Training loss: 0.150171 , Training acc:  0.95222\n",
      "Test loss: 0.256722 , Test acc:  0.910397\n",
      "--------------------------------------------------------------------------------\n",
      "Step 5340\n",
      "learning_rate: 0.00244945\n",
      "Training loss: 0.146071 , Training acc:  0.953911\n",
      "Test loss: 0.253553 , Test acc:  0.907439\n",
      "--------------------------------------------------------------------------------\n",
      "Step 5360\n",
      "learning_rate: 0.00244945\n",
      "Training loss: 0.16389 , Training acc:  0.943129\n",
      "Test loss: 0.277587 , Test acc:  0.906593\n",
      "--------------------------------------------------------------------------------\n",
      "Step 5380\n",
      "learning_rate: 0.00244945\n",
      "Training loss: 0.190284 , Training acc:  0.933827\n",
      "Test loss: 0.310188 , Test acc:  0.887151\n",
      "--------------------------------------------------------------------------------\n",
      "Step 5400\n",
      "learning_rate: 0.00242496\n",
      "Training loss: 0.158551 , Training acc:  0.948203\n",
      "Test loss: 0.272195 , Test acc:  0.903212\n",
      "--------------------------------------------------------------------------------\n",
      "Step 5420\n",
      "learning_rate: 0.00242496\n",
      "Training loss: 0.169112 , Training acc:  0.946934\n",
      "Test loss: 0.286294 , Test acc:  0.897718\n",
      "--------------------------------------------------------------------------------\n",
      "Step 5440\n",
      "learning_rate: 0.00242496\n",
      "Training loss: 0.150869 , Training acc:  0.951586\n",
      "Test loss: 0.270376 , Test acc:  0.897295\n",
      "--------------------------------------------------------------------------------\n",
      "Step 5460\n",
      "learning_rate: 0.00242496\n",
      "Training loss: 0.158487 , Training acc:  0.95074\n",
      "Test loss: 0.270144 , Test acc:  0.904903\n",
      "--------------------------------------------------------------------------------\n",
      "Step 5480\n",
      "learning_rate: 0.00240071\n",
      "Training loss: 0.161195 , Training acc:  0.95592\n",
      "Test loss: 0.272865 , Test acc:  0.903212\n",
      "--------------------------------------------------------------------------------\n",
      "Step 5500\n",
      "learning_rate: 0.00240071\n",
      "Training loss: 0.172617 , Training acc:  0.945877\n",
      "Test loss: 0.286006 , Test acc:  0.904903\n",
      "--------------------------------------------------------------------------------\n",
      "Step 5520\n",
      "learning_rate: 0.00240071\n",
      "Training loss: 0.15229 , Training acc:  0.951163\n",
      "Test loss: 0.26169 , Test acc:  0.908284\n",
      "--------------------------------------------------------------------------------\n",
      "Step 5540\n",
      "learning_rate: 0.00240071\n",
      "Training loss: 0.170596 , Training acc:  0.941649\n",
      "Test loss: 0.284786 , Test acc:  0.901522\n",
      "--------------------------------------------------------------------------------\n",
      "Step 5560\n",
      "learning_rate: 0.0023767\n",
      "Training loss: 0.164144 , Training acc:  0.945032\n",
      "Test loss: 0.272872 , Test acc:  0.901099\n",
      "--------------------------------------------------------------------------------\n",
      "Step 5580\n",
      "learning_rate: 0.0023767\n",
      "Training loss: 0.158461 , Training acc:  0.952643\n",
      "Test loss: 0.266792 , Test acc:  0.90448\n",
      "--------------------------------------------------------------------------------\n",
      "Step 5600\n",
      "learning_rate: 0.0023767\n",
      "Training loss: 0.145931 , Training acc:  0.955497\n",
      "Test loss: 0.264724 , Test acc:  0.905325\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5620\n",
      "learning_rate: 0.0023767\n",
      "Training loss: 0.155643 , Training acc:  0.950846\n",
      "Test loss: 0.265489 , Test acc:  0.902367\n",
      "--------------------------------------------------------------------------------\n",
      "Step 5640\n",
      "learning_rate: 0.00235293\n",
      "Training loss: 0.178187 , Training acc:  0.943658\n",
      "Test loss: 0.29639 , Test acc:  0.895182\n",
      "--------------------------------------------------------------------------------\n",
      "Step 5660\n",
      "learning_rate: 0.00235293\n",
      "Training loss: 0.161007 , Training acc:  0.950634\n",
      "Test loss: 0.283073 , Test acc:  0.890955\n",
      "--------------------------------------------------------------------------------\n",
      "Step 5680\n",
      "learning_rate: 0.00235293\n",
      "Training loss: 0.14927 , Training acc:  0.959091\n",
      "Test loss: 0.261668 , Test acc:  0.906593\n",
      "--------------------------------------------------------------------------------\n",
      "Step 5700\n",
      "learning_rate: 0.00232941\n",
      "Training loss: 0.160539 , Training acc:  0.948097\n",
      "Test loss: 0.280528 , Test acc:  0.894336\n",
      "--------------------------------------------------------------------------------\n",
      "Step 5720\n",
      "learning_rate: 0.00232941\n",
      "Training loss: 0.148471 , Training acc:  0.95296\n",
      "Test loss: 0.268075 , Test acc:  0.905325\n",
      "--------------------------------------------------------------------------------\n",
      "Step 5740\n",
      "learning_rate: 0.00232941\n",
      "Training loss: 0.140805 , Training acc:  0.957822\n",
      "Test loss: 0.258225 , Test acc:  0.907016\n",
      "--------------------------------------------------------------------------------\n",
      "Step 5760\n",
      "learning_rate: 0.00232941\n",
      "Training loss: 0.162828 , Training acc:  0.948731\n",
      "Test loss: 0.283912 , Test acc:  0.900254\n",
      "--------------------------------------------------------------------------------\n",
      "Step 5780\n",
      "learning_rate: 0.00230611\n",
      "Training loss: 0.139702 , Training acc:  0.956343\n",
      "Test loss: 0.258659 , Test acc:  0.908284\n",
      "--------------------------------------------------------------------------------\n",
      "Step 5800\n",
      "learning_rate: 0.00230611\n",
      "Training loss: 0.149855 , Training acc:  0.9537\n",
      "Test loss: 0.266639 , Test acc:  0.909975\n",
      "--------------------------------------------------------------------------------\n",
      "Step 5820\n",
      "learning_rate: 0.00230611\n",
      "Training loss: 0.139515 , Training acc:  0.956977\n",
      "Test loss: 0.25887 , Test acc:  0.908707\n",
      "--------------------------------------------------------------------------------\n",
      "Step 5840\n",
      "learning_rate: 0.00230611\n",
      "Training loss: 0.14917 , Training acc:  0.954651\n",
      "Test loss: 0.261967 , Test acc:  0.905748\n",
      "--------------------------------------------------------------------------------\n",
      "Step 5860\n",
      "learning_rate: 0.00228305\n",
      "Training loss: 0.182435 , Training acc:  0.939958\n",
      "Test loss: 0.309045 , Test acc:  0.890533\n",
      "--------------------------------------------------------------------------------\n",
      "Step 5880\n",
      "learning_rate: 0.00228305\n",
      "Training loss: 0.160964 , Training acc:  0.95296\n",
      "Test loss: 0.269783 , Test acc:  0.904903\n",
      "--------------------------------------------------------------------------------\n",
      "Step 5900\n",
      "learning_rate: 0.00228305\n",
      "Training loss: 0.161115 , Training acc:  0.954968\n",
      "Test loss: 0.275175 , Test acc:  0.904903\n",
      "--------------------------------------------------------------------------------\n",
      "Step 5920\n",
      "learning_rate: 0.00228305\n",
      "Training loss: 0.139902 , Training acc:  0.962368\n",
      "Test loss: 0.258121 , Test acc:  0.910397\n",
      "--------------------------------------------------------------------------------\n",
      "Step 5940\n",
      "learning_rate: 0.00226022\n",
      "Training loss: 0.134319 , Training acc:  0.957611\n",
      "Test loss: 0.260902 , Test acc:  0.903635\n",
      "--------------------------------------------------------------------------------\n",
      "Step 5960\n",
      "learning_rate: 0.00226022\n",
      "Training loss: 0.146913 , Training acc:  0.953488\n",
      "Test loss: 0.27861 , Test acc:  0.903635\n",
      "--------------------------------------------------------------------------------\n",
      "Step 5980\n",
      "learning_rate: 0.00226022\n",
      "Training loss: 0.157536 , Training acc:  0.948097\n",
      "Test loss: 0.286467 , Test acc:  0.899408\n",
      "--------------------------------------------------------------------------------\n",
      "Step 6000\n",
      "learning_rate: 0.00223762\n",
      "Training loss: 0.141853 , Training acc:  0.952326\n",
      "Test loss: 0.271383 , Test acc:  0.901944\n",
      "--------------------------------------------------------------------------------\n",
      "Step 6020\n",
      "learning_rate: 0.00223762\n",
      "Training loss: 0.139455 , Training acc:  0.954757\n",
      "Test loss: 0.264837 , Test acc:  0.906593\n",
      "--------------------------------------------------------------------------------\n",
      "Step 6040\n",
      "learning_rate: 0.00223762\n",
      "Training loss: 0.129169 , Training acc:  0.959302\n",
      "Test loss: 0.249986 , Test acc:  0.908707\n",
      "--------------------------------------------------------------------------------\n",
      "Step 6060\n",
      "learning_rate: 0.00223762\n",
      "Training loss: 0.138157 , Training acc:  0.955497\n",
      "Test loss: 0.263554 , Test acc:  0.903635\n",
      "--------------------------------------------------------------------------------\n",
      "Step 6080\n",
      "learning_rate: 0.00221524\n",
      "Training loss: 0.14063 , Training acc:  0.955391\n",
      "Test loss: 0.262309 , Test acc:  0.90448\n",
      "--------------------------------------------------------------------------------\n",
      "Step 6100\n",
      "learning_rate: 0.00221524\n",
      "Training loss: 0.137176 , Training acc:  0.955391\n",
      "Test loss: 0.260529 , Test acc:  0.903212\n",
      "--------------------------------------------------------------------------------\n",
      "Step 6120\n",
      "learning_rate: 0.00221524\n",
      "Training loss: 0.130458 , Training acc:  0.960254\n",
      "Test loss: 0.255456 , Test acc:  0.908707\n",
      "--------------------------------------------------------------------------------\n",
      "Step 6140\n",
      "learning_rate: 0.00221524\n",
      "Training loss: 0.140863 , Training acc:  0.95444\n",
      "Test loss: 0.265395 , Test acc:  0.905748\n",
      "--------------------------------------------------------------------------------\n",
      "Step 6160\n",
      "learning_rate: 0.00219309\n",
      "Training loss: 0.164259 , Training acc:  0.945032\n",
      "Test loss: 0.290057 , Test acc:  0.901944\n",
      "--------------------------------------------------------------------------------\n",
      "Step 6180\n",
      "learning_rate: 0.00219309\n",
      "Training loss: 0.15019 , Training acc:  0.954334\n",
      "Test loss: 0.270953 , Test acc:  0.899408\n",
      "--------------------------------------------------------------------------------\n",
      "Step 6200\n",
      "learning_rate: 0.00219309\n",
      "Training loss: 0.135757 , Training acc:  0.960359\n",
      "Test loss: 0.259372 , Test acc:  0.900676\n",
      "--------------------------------------------------------------------------------\n",
      "Step 6220\n",
      "learning_rate: 0.00219309\n",
      "Training loss: 0.160408 , Training acc:  0.951797\n",
      "Test loss: 0.275462 , Test acc:  0.901522\n",
      "--------------------------------------------------------------------------------\n",
      "Step 6240\n",
      "learning_rate: 0.00217116\n",
      "Training loss: 0.133868 , Training acc:  0.961099\n",
      "Test loss: 0.257721 , Test acc:  0.905325\n",
      "--------------------------------------------------------------------------------\n",
      "Step 6260\n",
      "learning_rate: 0.00217116\n",
      "Training loss: 0.133768 , Training acc:  0.959514\n",
      "Test loss: 0.257106 , Test acc:  0.909129\n",
      "--------------------------------------------------------------------------------\n",
      "Step 6280\n",
      "learning_rate: 0.00217116\n",
      "Training loss: 0.130022 , Training acc:  0.959408\n",
      "Test loss: 0.26162 , Test acc:  0.906593\n",
      "--------------------------------------------------------------------------------\n",
      "Step 6300\n",
      "learning_rate: 0.00214945\n",
      "Training loss: 0.127132 , Training acc:  0.961839\n",
      "Test loss: 0.254169 , Test acc:  0.911243\n",
      "--------------------------------------------------------------------------------\n",
      "Step 6320\n",
      "learning_rate: 0.00214945\n",
      "Training loss: 0.13042 , Training acc:  0.963531\n",
      "Test loss: 0.254325 , Test acc:  0.913779\n",
      "--------------------------------------------------------------------------------\n",
      "Step 6340\n",
      "learning_rate: 0.00214945\n",
      "Training loss: 0.126184 , Training acc:  0.961416\n",
      "Test loss: 0.242917 , Test acc:  0.915469\n",
      "--------------------------------------------------------------------------------\n",
      "Step 6360\n",
      "learning_rate: 0.00214945\n",
      "Training loss: 0.122604 , Training acc:  0.964482\n",
      "Test loss: 0.244644 , Test acc:  0.912088\n",
      "--------------------------------------------------------------------------------\n",
      "Step 6380\n",
      "learning_rate: 0.00212795\n",
      "Training loss: 0.131823 , Training acc:  0.962156\n",
      "Test loss: 0.260956 , Test acc:  0.906593\n",
      "--------------------------------------------------------------------------------\n",
      "Step 6400\n",
      "learning_rate: 0.00212795\n",
      "Training loss: 0.110708 , Training acc:  0.966068\n",
      "Test loss: 0.235505 , Test acc:  0.908707\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 6420\n",
      "learning_rate: 0.00212795\n",
      "Training loss: 0.157355 , Training acc:  0.946723\n",
      "Test loss: 0.301446 , Test acc:  0.893914\n",
      "--------------------------------------------------------------------------------\n",
      "Step 6440\n",
      "learning_rate: 0.00212795\n",
      "Training loss: 0.116289 , Training acc:  0.961945\n",
      "Test loss: 0.253496 , Test acc:  0.907016\n",
      "--------------------------------------------------------------------------------\n",
      "Step 6460\n",
      "learning_rate: 0.00210667\n",
      "Training loss: 0.119412 , Training acc:  0.960994\n",
      "Test loss: 0.248434 , Test acc:  0.909975\n",
      "--------------------------------------------------------------------------------\n",
      "Step 6480\n",
      "learning_rate: 0.00210667\n",
      "Training loss: 0.128828 , Training acc:  0.962791\n",
      "Test loss: 0.261666 , Test acc:  0.901944\n",
      "--------------------------------------------------------------------------------\n",
      "Step 6500\n",
      "learning_rate: 0.00210667\n",
      "Training loss: 0.117036 , Training acc:  0.965011\n",
      "Test loss: 0.245197 , Test acc:  0.907861\n",
      "--------------------------------------------------------------------------------\n",
      "Step 6520\n",
      "learning_rate: 0.00210667\n",
      "Training loss: 0.126412 , Training acc:  0.961945\n",
      "Test loss: 0.250434 , Test acc:  0.911665\n",
      "--------------------------------------------------------------------------------\n",
      "Step 6540\n",
      "learning_rate: 0.00208561\n",
      "Training loss: 0.137652 , Training acc:  0.956765\n",
      "Test loss: 0.272459 , Test acc:  0.902367\n",
      "--------------------------------------------------------------------------------\n",
      "Step 6560\n",
      "learning_rate: 0.00208561\n",
      "Training loss: 0.133148 , Training acc:  0.955708\n",
      "Test loss: 0.258506 , Test acc:  0.91082\n",
      "--------------------------------------------------------------------------------\n",
      "Step 6580\n",
      "learning_rate: 0.00208561\n",
      "Training loss: 0.119357 , Training acc:  0.962474\n",
      "Test loss: 0.253955 , Test acc:  0.904903\n",
      "--------------------------------------------------------------------------------\n",
      "Step 6600\n",
      "learning_rate: 0.00206475\n",
      "Training loss: 0.146618 , Training acc:  0.95222\n",
      "Test loss: 0.270889 , Test acc:  0.904903\n",
      "--------------------------------------------------------------------------------\n",
      "Step 6620\n",
      "learning_rate: 0.00206475\n",
      "Training loss: 0.129147 , Training acc:  0.959091\n",
      "Test loss: 0.261024 , Test acc:  0.906593\n",
      "--------------------------------------------------------------------------------\n",
      "Step 6640\n",
      "learning_rate: 0.00206475\n",
      "Training loss: 0.151698 , Training acc:  0.954123\n",
      "Test loss: 0.277419 , Test acc:  0.903635\n",
      "--------------------------------------------------------------------------------\n",
      "Step 6660\n",
      "learning_rate: 0.00206475\n",
      "Training loss: 0.138887 , Training acc:  0.959514\n",
      "Test loss: 0.260363 , Test acc:  0.904058\n",
      "--------------------------------------------------------------------------------\n",
      "Step 6680\n",
      "learning_rate: 0.0020441\n",
      "Training loss: 0.125506 , Training acc:  0.961522\n",
      "Test loss: 0.253052 , Test acc:  0.912511\n",
      "--------------------------------------------------------------------------------\n",
      "Step 6700\n",
      "learning_rate: 0.0020441\n",
      "Training loss: 0.121492 , Training acc:  0.962896\n",
      "Test loss: 0.244664 , Test acc:  0.915892\n",
      "--------------------------------------------------------------------------------\n",
      "Step 6720\n",
      "learning_rate: 0.0020441\n",
      "Training loss: 0.148366 , Training acc:  0.953066\n",
      "Test loss: 0.279839 , Test acc:  0.903212\n",
      "--------------------------------------------------------------------------------\n",
      "Step 6740\n",
      "learning_rate: 0.0020441\n",
      "Training loss: 0.120313 , Training acc:  0.965539\n",
      "Test loss: 0.248269 , Test acc:  0.908707\n",
      "--------------------------------------------------------------------------------\n",
      "Step 6760\n",
      "learning_rate: 0.00202366\n",
      "Training loss: 0.136674 , Training acc:  0.957822\n",
      "Test loss: 0.267317 , Test acc:  0.903635\n",
      "--------------------------------------------------------------------------------\n",
      "Step 6780\n",
      "learning_rate: 0.00202366\n",
      "Training loss: 0.136847 , Training acc:  0.959514\n",
      "Test loss: 0.268902 , Test acc:  0.905748\n",
      "--------------------------------------------------------------------------------\n",
      "Step 6800\n",
      "learning_rate: 0.00202366\n",
      "Training loss: 0.12773 , Training acc:  0.962262\n",
      "Test loss: 0.268087 , Test acc:  0.901099\n",
      "--------------------------------------------------------------------------------\n",
      "Step 6820\n",
      "learning_rate: 0.00202366\n",
      "Training loss: 0.142004 , Training acc:  0.956977\n",
      "Test loss: 0.26767 , Test acc:  0.907016\n",
      "--------------------------------------------------------------------------------\n",
      "Step 6840\n",
      "learning_rate: 0.00200342\n",
      "Training loss: 0.133145 , Training acc:  0.957294\n",
      "Test loss: 0.264412 , Test acc:  0.907016\n",
      "--------------------------------------------------------------------------------\n",
      "Step 6860\n",
      "learning_rate: 0.00200342\n",
      "Training loss: 0.132249 , Training acc:  0.957822\n",
      "Test loss: 0.26328 , Test acc:  0.905325\n",
      "--------------------------------------------------------------------------------\n",
      "Step 6880\n",
      "learning_rate: 0.00200342\n",
      "Training loss: 0.128659 , Training acc:  0.962579\n",
      "Test loss: 0.261985 , Test acc:  0.907016\n",
      "--------------------------------------------------------------------------------\n",
      "Step 6900\n",
      "learning_rate: 0.00198339\n",
      "Training loss: 0.122712 , Training acc:  0.962685\n",
      "Test loss: 0.270397 , Test acc:  0.904058\n",
      "--------------------------------------------------------------------------------\n",
      "Step 6920\n",
      "learning_rate: 0.00198339\n",
      "Training loss: 0.105813 , Training acc:  0.968288\n",
      "Test loss: 0.246601 , Test acc:  0.907861\n",
      "--------------------------------------------------------------------------------\n",
      "Step 6940\n",
      "learning_rate: 0.00198339\n",
      "Training loss: 0.118588 , Training acc:  0.961628\n",
      "Test loss: 0.26274 , Test acc:  0.905748\n",
      "--------------------------------------------------------------------------------\n",
      "Step 6960\n",
      "learning_rate: 0.00198339\n",
      "Training loss: 0.147095 , Training acc:  0.951268\n",
      "Test loss: 0.28483 , Test acc:  0.895604\n",
      "--------------------------------------------------------------------------------\n",
      "Step 6980\n",
      "learning_rate: 0.00196356\n",
      "Training loss: 0.124888 , Training acc:  0.962051\n",
      "Test loss: 0.260598 , Test acc:  0.908707\n",
      "--------------------------------------------------------------------------------\n",
      "Step 7000\n",
      "learning_rate: 0.00196356\n",
      "Training loss: 0.113141 , Training acc:  0.966068\n",
      "Test loss: 0.245107 , Test acc:  0.912088\n",
      "--------------------------------------------------------------------------------\n",
      "Step 7020\n",
      "learning_rate: 0.00196356\n",
      "Training loss: 0.116397 , Training acc:  0.966385\n",
      "Test loss: 0.248538 , Test acc:  0.909975\n",
      "--------------------------------------------------------------------------------\n",
      "Step 7040\n",
      "learning_rate: 0.00196356\n",
      "Training loss: 0.113944 , Training acc:  0.965328\n",
      "Test loss: 0.244179 , Test acc:  0.909129\n",
      "--------------------------------------------------------------------------------\n",
      "Step 7060\n",
      "learning_rate: 0.00194392\n",
      "Training loss: 0.117951 , Training acc:  0.966913\n",
      "Test loss: 0.244297 , Test acc:  0.911665\n",
      "--------------------------------------------------------------------------------\n",
      "Step 7080\n",
      "learning_rate: 0.00194392\n",
      "Training loss: 0.122138 , Training acc:  0.965328\n",
      "Test loss: 0.246728 , Test acc:  0.913356\n",
      "--------------------------------------------------------------------------------\n",
      "Step 7100\n",
      "learning_rate: 0.00194392\n",
      "Training loss: 0.123083 , Training acc:  0.963848\n",
      "Test loss: 0.245034 , Test acc:  0.912088\n",
      "--------------------------------------------------------------------------------\n",
      "Step 7120\n",
      "learning_rate: 0.00194392\n",
      "Training loss: 0.127679 , Training acc:  0.963425\n",
      "Test loss: 0.25756 , Test acc:  0.90279\n",
      "--------------------------------------------------------------------------------\n",
      "Step 7140\n",
      "learning_rate: 0.00192448\n",
      "Training loss: 0.111062 , Training acc:  0.968499\n",
      "Test loss: 0.235837 , Test acc:  0.916737\n",
      "--------------------------------------------------------------------------------\n",
      "Step 7160\n",
      "learning_rate: 0.00192448\n",
      "Training loss: 0.126057 , Training acc:  0.960148\n",
      "Test loss: 0.255217 , Test acc:  0.912511\n",
      "--------------------------------------------------------------------------------\n",
      "Step 7180\n",
      "learning_rate: 0.00192448\n",
      "Training loss: 0.108643 , Training acc:  0.968076\n",
      "Test loss: 0.242054 , Test acc:  0.913779\n",
      "--------------------------------------------------------------------------------\n",
      "Step 7200\n",
      "learning_rate: 0.00190524\n",
      "Training loss: 0.116453 , Training acc:  0.966068\n",
      "Test loss: 0.244439 , Test acc:  0.913779\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 7220\n",
      "learning_rate: 0.00190524\n",
      "Training loss: 0.114756 , Training acc:  0.965433\n",
      "Test loss: 0.25142 , Test acc:  0.911665\n",
      "--------------------------------------------------------------------------------\n",
      "Step 7240\n",
      "learning_rate: 0.00190524\n",
      "Training loss: 0.0973236 , Training acc:  0.972939\n",
      "Test loss: 0.231798 , Test acc:  0.916314\n",
      "--------------------------------------------------------------------------------\n",
      "Step 7260\n",
      "learning_rate: 0.00190524\n",
      "Training loss: 0.101064 , Training acc:  0.971142\n",
      "Test loss: 0.238367 , Test acc:  0.915892\n",
      "--------------------------------------------------------------------------------\n",
      "Step 7280\n",
      "learning_rate: 0.00188618\n",
      "Training loss: 0.0986043 , Training acc:  0.971036\n",
      "Test loss: 0.238419 , Test acc:  0.91716\n",
      "--------------------------------------------------------------------------------\n",
      "Step 7300\n",
      "learning_rate: 0.00188618\n",
      "Training loss: 0.108511 , Training acc:  0.966808\n",
      "Test loss: 0.244976 , Test acc:  0.909975\n",
      "--------------------------------------------------------------------------------\n",
      "Step 7320\n",
      "learning_rate: 0.00188618\n",
      "Training loss: 0.104511 , Training acc:  0.96797\n",
      "Test loss: 0.239417 , Test acc:  0.913779\n",
      "--------------------------------------------------------------------------------\n",
      "Step 7340\n",
      "learning_rate: 0.00188618\n",
      "Training loss: 0.124736 , Training acc:  0.958562\n",
      "Test loss: 0.256498 , Test acc:  0.905325\n",
      "--------------------------------------------------------------------------------\n",
      "Step 7360\n",
      "learning_rate: 0.00186732\n",
      "Training loss: 0.104879 , Training acc:  0.967865\n",
      "Test loss: 0.239861 , Test acc:  0.91716\n",
      "--------------------------------------------------------------------------------\n",
      "Step 7380\n",
      "learning_rate: 0.00186732\n",
      "Training loss: 0.114077 , Training acc:  0.964905\n",
      "Test loss: 0.252096 , Test acc:  0.912088\n",
      "--------------------------------------------------------------------------------\n",
      "Step 7400\n",
      "learning_rate: 0.00186732\n",
      "Training loss: 0.127113 , Training acc:  0.962474\n",
      "Test loss: 0.26252 , Test acc:  0.904058\n",
      "--------------------------------------------------------------------------------\n",
      "Step 7420\n",
      "learning_rate: 0.00186732\n",
      "Training loss: 0.117654 , Training acc:  0.966279\n",
      "Test loss: 0.244766 , Test acc:  0.911243\n",
      "--------------------------------------------------------------------------------\n",
      "Step 7440\n",
      "learning_rate: 0.00184865\n",
      "Training loss: 0.13507 , Training acc:  0.960042\n",
      "Test loss: 0.271709 , Test acc:  0.900676\n",
      "--------------------------------------------------------------------------------\n",
      "Step 7460\n",
      "learning_rate: 0.00184865\n",
      "Training loss: 0.107919 , Training acc:  0.971247\n",
      "Test loss: 0.238639 , Test acc:  0.916314\n",
      "--------------------------------------------------------------------------------\n",
      "Step 7480\n",
      "learning_rate: 0.00184865\n",
      "Training loss: 0.114402 , Training acc:  0.968076\n",
      "Test loss: 0.241852 , Test acc:  0.916314\n",
      "--------------------------------------------------------------------------------\n",
      "Step 7500\n",
      "learning_rate: 0.00183016\n",
      "Training loss: 0.106391 , Training acc:  0.970613\n",
      "Test loss: 0.240572 , Test acc:  0.914201\n",
      "--------------------------------------------------------------------------------\n",
      "Step 7520\n",
      "learning_rate: 0.00183016\n",
      "Training loss: 0.11713 , Training acc:  0.966596\n",
      "Test loss: 0.246292 , Test acc:  0.911665\n",
      "--------------------------------------------------------------------------------\n",
      "Step 7540\n",
      "learning_rate: 0.00183016\n",
      "Training loss: 0.102959 , Training acc:  0.97019\n",
      "Test loss: 0.237654 , Test acc:  0.912511\n",
      "--------------------------------------------------------------------------------\n",
      "Step 7560\n",
      "learning_rate: 0.00183016\n",
      "Training loss: 0.0939612 , Training acc:  0.973679\n",
      "Test loss: 0.228197 , Test acc:  0.913779\n",
      "--------------------------------------------------------------------------------\n",
      "Step 7580\n",
      "learning_rate: 0.00181186\n",
      "Training loss: 0.127489 , Training acc:  0.960994\n",
      "Test loss: 0.267331 , Test acc:  0.903212\n",
      "--------------------------------------------------------------------------------\n",
      "Step 7600\n",
      "learning_rate: 0.00181186\n",
      "Training loss: 0.105192 , Training acc:  0.969767\n",
      "Test loss: 0.23871 , Test acc:  0.912511\n",
      "--------------------------------------------------------------------------------\n",
      "Step 7620\n",
      "learning_rate: 0.00181186\n",
      "Training loss: 0.115202 , Training acc:  0.965539\n",
      "Test loss: 0.242531 , Test acc:  0.91082\n",
      "--------------------------------------------------------------------------------\n",
      "Step 7640\n",
      "learning_rate: 0.00181186\n",
      "Training loss: 0.113657 , Training acc:  0.967759\n",
      "Test loss: 0.236235 , Test acc:  0.915469\n",
      "--------------------------------------------------------------------------------\n",
      "Step 7660\n",
      "learning_rate: 0.00179374\n",
      "Training loss: 0.109302 , Training acc:  0.966808\n",
      "Test loss: 0.239906 , Test acc:  0.913779\n",
      "--------------------------------------------------------------------------------\n",
      "Step 7680\n",
      "learning_rate: 0.00179374\n",
      "Training loss: 0.118848 , Training acc:  0.964799\n",
      "Test loss: 0.256818 , Test acc:  0.909129\n",
      "--------------------------------------------------------------------------------\n",
      "Step 7700\n",
      "learning_rate: 0.00179374\n",
      "Training loss: 0.0999592 , Training acc:  0.971459\n",
      "Test loss: 0.238922 , Test acc:  0.915892\n",
      "--------------------------------------------------------------------------------\n",
      "Step 7720\n",
      "learning_rate: 0.00179374\n",
      "Training loss: 0.0972482 , Training acc:  0.973256\n",
      "Test loss: 0.233265 , Test acc:  0.916314\n",
      "--------------------------------------------------------------------------------\n",
      "Step 7740\n",
      "learning_rate: 0.00177581\n",
      "Training loss: 0.101085 , Training acc:  0.970085\n",
      "Test loss: 0.240417 , Test acc:  0.911665\n",
      "--------------------------------------------------------------------------------\n",
      "Step 7760\n",
      "learning_rate: 0.00177581\n",
      "Training loss: 0.0944498 , Training acc:  0.971776\n",
      "Test loss: 0.237323 , Test acc:  0.912933\n",
      "--------------------------------------------------------------------------------\n",
      "Step 7780\n",
      "learning_rate: 0.00177581\n",
      "Training loss: 0.0936845 , Training acc:  0.970825\n",
      "Test loss: 0.237898 , Test acc:  0.914201\n",
      "--------------------------------------------------------------------------------\n",
      "Step 7800\n",
      "learning_rate: 0.00175805\n",
      "Training loss: 0.0988475 , Training acc:  0.968499\n",
      "Test loss: 0.244217 , Test acc:  0.909975\n",
      "--------------------------------------------------------------------------------\n",
      "Step 7820\n",
      "learning_rate: 0.00175805\n",
      "Training loss: 0.113443 , Training acc:  0.966279\n",
      "Test loss: 0.251824 , Test acc:  0.910397\n",
      "--------------------------------------------------------------------------------\n",
      "Step 7840\n",
      "learning_rate: 0.00175805\n",
      "Training loss: 0.106493 , Training acc:  0.969662\n",
      "Test loss: 0.241831 , Test acc:  0.913356\n",
      "--------------------------------------------------------------------------------\n",
      "Step 7860\n",
      "learning_rate: 0.00175805\n",
      "Training loss: 0.117717 , Training acc:  0.962896\n",
      "Test loss: 0.261915 , Test acc:  0.904058\n",
      "--------------------------------------------------------------------------------\n",
      "Step 7880\n",
      "learning_rate: 0.00174047\n",
      "Training loss: 0.0982997 , Training acc:  0.970296\n",
      "Test loss: 0.244985 , Test acc:  0.913779\n",
      "--------------------------------------------------------------------------------\n",
      "Step 7900\n",
      "learning_rate: 0.00174047\n",
      "Training loss: 0.103425 , Training acc:  0.96945\n",
      "Test loss: 0.253042 , Test acc:  0.908707\n",
      "--------------------------------------------------------------------------------\n",
      "Step 7920\n",
      "learning_rate: 0.00174047\n",
      "Training loss: 0.112714 , Training acc:  0.966385\n",
      "Test loss: 0.263336 , Test acc:  0.90448\n",
      "--------------------------------------------------------------------------------\n",
      "Step 7940\n",
      "learning_rate: 0.00174047\n",
      "Training loss: 0.0874702 , Training acc:  0.974101\n",
      "Test loss: 0.23289 , Test acc:  0.909975\n",
      "--------------------------------------------------------------------------------\n",
      "Step 7960\n",
      "learning_rate: 0.00172306\n",
      "Training loss: 0.0920051 , Training acc:  0.97389\n",
      "Test loss: 0.236662 , Test acc:  0.916314\n",
      "--------------------------------------------------------------------------------\n",
      "Step 7980\n",
      "learning_rate: 0.00172306\n",
      "Training loss: 0.0862832 , Training acc:  0.976321\n",
      "Test loss: 0.227546 , Test acc:  0.915469\n",
      "--------------------------------------------------------------------------------\n",
      "Step 8000\n",
      "learning_rate: 0.00172306\n",
      "Training loss: 0.0993444 , Training acc:  0.972199\n",
      "Test loss: 0.239387 , Test acc:  0.920541\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 8020\n",
      "learning_rate: 0.00172306\n",
      "Training loss: 0.0940504 , Training acc:  0.97389\n",
      "Test loss: 0.232209 , Test acc:  0.919273\n",
      "--------------------------------------------------------------------------------\n",
      "Step 8040\n",
      "learning_rate: 0.00170583\n",
      "Training loss: 0.103316 , Training acc:  0.972304\n",
      "Test loss: 0.240501 , Test acc:  0.915469\n",
      "--------------------------------------------------------------------------------\n",
      "Step 8060\n",
      "learning_rate: 0.00170583\n",
      "Training loss: 0.0972338 , Training acc:  0.975053\n",
      "Test loss: 0.237087 , Test acc:  0.91716\n",
      "--------------------------------------------------------------------------------\n",
      "Step 8080\n",
      "learning_rate: 0.00170583\n",
      "Training loss: 0.097185 , Training acc:  0.974101\n",
      "Test loss: 0.240397 , Test acc:  0.91716\n",
      "--------------------------------------------------------------------------------\n",
      "Step 8100\n",
      "learning_rate: 0.00168877\n",
      "Training loss: 0.0871191 , Training acc:  0.974841\n",
      "Test loss: 0.231404 , Test acc:  0.914201\n",
      "--------------------------------------------------------------------------------\n",
      "Step 8120\n",
      "learning_rate: 0.00168877\n",
      "Training loss: 0.0858105 , Training acc:  0.975159\n",
      "Test loss: 0.231931 , Test acc:  0.915469\n",
      "--------------------------------------------------------------------------------\n",
      "Step 8140\n",
      "learning_rate: 0.00168877\n",
      "Training loss: 0.106519 , Training acc:  0.96871\n",
      "Test loss: 0.252135 , Test acc:  0.912511\n",
      "--------------------------------------------------------------------------------\n",
      "Step 8160\n",
      "learning_rate: 0.00168877\n",
      "Training loss: 0.0995029 , Training acc:  0.97537\n",
      "Test loss: 0.241213 , Test acc:  0.913779\n",
      "--------------------------------------------------------------------------------\n",
      "Step 8180\n",
      "learning_rate: 0.00167189\n",
      "Training loss: 0.0991048 , Training acc:  0.974101\n",
      "Test loss: 0.242327 , Test acc:  0.916737\n",
      "--------------------------------------------------------------------------------\n",
      "Step 8200\n",
      "learning_rate: 0.00167189\n",
      "Training loss: 0.0941821 , Training acc:  0.976321\n",
      "Test loss: 0.236232 , Test acc:  0.915892\n",
      "--------------------------------------------------------------------------------\n",
      "Step 8220\n",
      "learning_rate: 0.00167189\n",
      "Training loss: 0.0928604 , Training acc:  0.975687\n",
      "Test loss: 0.241001 , Test acc:  0.917582\n",
      "--------------------------------------------------------------------------------\n",
      "Step 8240\n",
      "learning_rate: 0.00167189\n",
      "Training loss: 0.0971746 , Training acc:  0.975476\n",
      "Test loss: 0.240122 , Test acc:  0.916314\n",
      "--------------------------------------------------------------------------------\n",
      "Step 8260\n",
      "learning_rate: 0.00165517\n",
      "Training loss: 0.0951353 , Training acc:  0.976744\n",
      "Test loss: 0.242746 , Test acc:  0.915892\n",
      "--------------------------------------------------------------------------------\n",
      "Step 8280\n",
      "learning_rate: 0.00165517\n",
      "Training loss: 0.0904423 , Training acc:  0.976321\n",
      "Test loss: 0.24416 , Test acc:  0.910397\n",
      "--------------------------------------------------------------------------------\n",
      "Step 8300\n",
      "learning_rate: 0.00165517\n",
      "Training loss: 0.100636 , Training acc:  0.972304\n",
      "Test loss: 0.25968 , Test acc:  0.910397\n",
      "--------------------------------------------------------------------------------\n",
      "Step 8320\n",
      "learning_rate: 0.00165517\n",
      "Training loss: 0.100284 , Training acc:  0.96871\n",
      "Test loss: 0.255875 , Test acc:  0.906593\n",
      "--------------------------------------------------------------------------------\n",
      "Step 8340\n",
      "learning_rate: 0.00163862\n",
      "Training loss: 0.0868946 , Training acc:  0.976321\n",
      "Test loss: 0.231597 , Test acc:  0.918428\n",
      "--------------------------------------------------------------------------------\n",
      "Step 8360\n",
      "learning_rate: 0.00163862\n",
      "Training loss: 0.0933473 , Training acc:  0.974313\n",
      "Test loss: 0.241828 , Test acc:  0.912511\n",
      "--------------------------------------------------------------------------------\n",
      "Step 8380\n",
      "learning_rate: 0.00163862\n",
      "Training loss: 0.0979761 , Training acc:  0.973784\n",
      "Test loss: 0.249565 , Test acc:  0.908707\n",
      "--------------------------------------------------------------------------------\n",
      "Step 8400\n",
      "learning_rate: 0.00162223\n",
      "Training loss: 0.0786329 , Training acc:  0.979915\n",
      "Test loss: 0.226 , Test acc:  0.91716\n",
      "--------------------------------------------------------------------------------\n",
      "Step 8420\n",
      "learning_rate: 0.00162223\n",
      "Training loss: 0.0775617 , Training acc:  0.980444\n",
      "Test loss: 0.226759 , Test acc:  0.918005\n",
      "--------------------------------------------------------------------------------\n",
      "Step 8440\n",
      "learning_rate: 0.00162223\n",
      "Training loss: 0.0825979 , Training acc:  0.978858\n",
      "Test loss: 0.233349 , Test acc:  0.913779\n",
      "--------------------------------------------------------------------------------\n",
      "Step 8460\n",
      "learning_rate: 0.00162223\n",
      "Training loss: 0.0812786 , Training acc:  0.978541\n",
      "Test loss: 0.232652 , Test acc:  0.912933\n",
      "--------------------------------------------------------------------------------\n",
      "Step 8480\n",
      "learning_rate: 0.00160601\n",
      "Training loss: 0.0877488 , Training acc:  0.974947\n",
      "Test loss: 0.24157 , Test acc:  0.912088\n",
      "--------------------------------------------------------------------------------\n",
      "Step 8500\n",
      "learning_rate: 0.00160601\n",
      "Training loss: 0.0899892 , Training acc:  0.973044\n",
      "Test loss: 0.244737 , Test acc:  0.909552\n",
      "--------------------------------------------------------------------------------\n",
      "Step 8520\n",
      "learning_rate: 0.00160601\n",
      "Training loss: 0.0973433 , Training acc:  0.973362\n",
      "Test loss: 0.255426 , Test acc:  0.913779\n",
      "--------------------------------------------------------------------------------\n",
      "Step 8540\n",
      "learning_rate: 0.00160601\n",
      "Training loss: 0.0891087 , Training acc:  0.97685\n",
      "Test loss: 0.237938 , Test acc:  0.913779\n",
      "--------------------------------------------------------------------------------\n",
      "Step 8560\n",
      "learning_rate: 0.00158995\n",
      "Training loss: 0.0762086 , Training acc:  0.980867\n",
      "Test loss: 0.223219 , Test acc:  0.919273\n",
      "--------------------------------------------------------------------------------\n",
      "Step 8580\n",
      "learning_rate: 0.00158995\n",
      "Training loss: 0.07994 , Training acc:  0.97981\n",
      "Test loss: 0.226847 , Test acc:  0.915892\n",
      "--------------------------------------------------------------------------------\n",
      "Step 8600\n",
      "learning_rate: 0.00158995\n",
      "Training loss: 0.0832164 , Training acc:  0.978118\n",
      "Test loss: 0.232984 , Test acc:  0.914624\n",
      "--------------------------------------------------------------------------------\n",
      "Step 8620\n",
      "learning_rate: 0.00158995\n",
      "Training loss: 0.0862156 , Training acc:  0.976427\n",
      "Test loss: 0.236688 , Test acc:  0.912933\n",
      "--------------------------------------------------------------------------------\n",
      "Step 8640\n",
      "learning_rate: 0.00157405\n",
      "Training loss: 0.0776555 , Training acc:  0.979915\n",
      "Test loss: 0.225542 , Test acc:  0.917582\n",
      "--------------------------------------------------------------------------------\n",
      "Step 8660\n",
      "learning_rate: 0.00157405\n",
      "Training loss: 0.0714607 , Training acc:  0.980973\n",
      "Test loss: 0.223401 , Test acc:  0.915469\n",
      "--------------------------------------------------------------------------------\n",
      "Step 8680\n",
      "learning_rate: 0.00157405\n",
      "Training loss: 0.070735 , Training acc:  0.980973\n",
      "Test loss: 0.225458 , Test acc:  0.916314\n",
      "--------------------------------------------------------------------------------\n",
      "Step 8700\n",
      "learning_rate: 0.00155831\n",
      "Training loss: 0.0724481 , Training acc:  0.980655\n",
      "Test loss: 0.223712 , Test acc:  0.919696\n",
      "--------------------------------------------------------------------------------\n",
      "Step 8720\n",
      "learning_rate: 0.00155831\n",
      "Training loss: 0.0812314 , Training acc:  0.978118\n",
      "Test loss: 0.236835 , Test acc:  0.915469\n",
      "--------------------------------------------------------------------------------\n",
      "Step 8740\n",
      "learning_rate: 0.00155831\n",
      "Training loss: 0.0927208 , Training acc:  0.972939\n",
      "Test loss: 0.251216 , Test acc:  0.909975\n",
      "--------------------------------------------------------------------------------\n",
      "Step 8760\n",
      "learning_rate: 0.00155831\n",
      "Training loss: 0.0803472 , Training acc:  0.976638\n",
      "Test loss: 0.228213 , Test acc:  0.91716\n",
      "--------------------------------------------------------------------------------\n",
      "Step 8780\n",
      "learning_rate: 0.00154272\n",
      "Training loss: 0.072098 , Training acc:  0.982347\n",
      "Test loss: 0.217344 , Test acc:  0.920964\n",
      "--------------------------------------------------------------------------------\n",
      "Step 8800\n",
      "learning_rate: 0.00154272\n",
      "Training loss: 0.0929502 , Training acc:  0.974207\n",
      "Test loss: 0.244464 , Test acc:  0.906593\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 8820\n",
      "learning_rate: 0.00154272\n",
      "Training loss: 0.0842464 , Training acc:  0.978013\n",
      "Test loss: 0.236726 , Test acc:  0.915892\n",
      "--------------------------------------------------------------------------------\n",
      "Step 8840\n",
      "learning_rate: 0.00154272\n",
      "Training loss: 0.0791956 , Training acc:  0.979387\n",
      "Test loss: 0.230789 , Test acc:  0.914624\n",
      "--------------------------------------------------------------------------------\n",
      "Step 8860\n",
      "learning_rate: 0.0015273\n",
      "Training loss: 0.0766295 , Training acc:  0.98055\n",
      "Test loss: 0.227139 , Test acc:  0.915892\n",
      "--------------------------------------------------------------------------------\n",
      "Step 8880\n",
      "learning_rate: 0.0015273\n",
      "Training loss: 0.0848611 , Training acc:  0.97833\n",
      "Test loss: 0.236381 , Test acc:  0.913356\n",
      "--------------------------------------------------------------------------------\n",
      "Step 8900\n",
      "learning_rate: 0.0015273\n",
      "Training loss: 0.0832425 , Training acc:  0.978647\n",
      "Test loss: 0.237336 , Test acc:  0.912088\n",
      "--------------------------------------------------------------------------------\n",
      "Step 8920\n",
      "learning_rate: 0.0015273\n",
      "Training loss: 0.0726885 , Training acc:  0.980761\n",
      "Test loss: 0.227909 , Test acc:  0.910397\n",
      "--------------------------------------------------------------------------------\n",
      "Step 8940\n",
      "learning_rate: 0.00151202\n",
      "Training loss: 0.0807492 , Training acc:  0.976744\n",
      "Test loss: 0.236497 , Test acc:  0.912933\n",
      "--------------------------------------------------------------------------------\n",
      "Step 8960\n",
      "learning_rate: 0.00151202\n",
      "Training loss: 0.0800272 , Training acc:  0.977484\n",
      "Test loss: 0.230793 , Test acc:  0.91716\n",
      "--------------------------------------------------------------------------------\n",
      "Step 8980\n",
      "learning_rate: 0.00151202\n",
      "Training loss: 0.0853267 , Training acc:  0.973679\n",
      "Test loss: 0.239889 , Test acc:  0.907439\n",
      "--------------------------------------------------------------------------------\n",
      "Step 9000\n",
      "learning_rate: 0.0014969\n",
      "Training loss: 0.0813102 , Training acc:  0.97685\n",
      "Test loss: 0.237652 , Test acc:  0.911243\n",
      "--------------------------------------------------------------------------------\n",
      "Step 9020\n",
      "learning_rate: 0.0014969\n",
      "Training loss: 0.0822666 , Training acc:  0.978647\n",
      "Test loss: 0.233966 , Test acc:  0.911243\n",
      "--------------------------------------------------------------------------------\n",
      "Step 9040\n",
      "learning_rate: 0.0014969\n",
      "Training loss: 0.0731758 , Training acc:  0.98351\n",
      "Test loss: 0.224776 , Test acc:  0.918428\n",
      "--------------------------------------------------------------------------------\n",
      "Step 9060\n",
      "learning_rate: 0.0014969\n",
      "Training loss: 0.0866589 , Training acc:  0.976321\n",
      "Test loss: 0.244318 , Test acc:  0.911665\n",
      "--------------------------------------------------------------------------------\n",
      "Step 9080\n",
      "learning_rate: 0.00148193\n",
      "Training loss: 0.0905731 , Training acc:  0.974947\n",
      "Test loss: 0.246565 , Test acc:  0.911665\n",
      "--------------------------------------------------------------------------------\n",
      "Step 9100\n",
      "learning_rate: 0.00148193\n",
      "Training loss: 0.0813694 , Training acc:  0.978753\n",
      "Test loss: 0.227606 , Test acc:  0.920541\n",
      "--------------------------------------------------------------------------------\n",
      "Step 9120\n",
      "learning_rate: 0.00148193\n",
      "Training loss: 0.0854578 , Training acc:  0.977801\n",
      "Test loss: 0.237573 , Test acc:  0.91716\n",
      "--------------------------------------------------------------------------------\n",
      "Step 9140\n",
      "learning_rate: 0.00148193\n",
      "Training loss: 0.0711186 , Training acc:  0.98277\n",
      "Test loss: 0.218353 , Test acc:  0.916314\n",
      "--------------------------------------------------------------------------------\n",
      "Step 9160\n",
      "learning_rate: 0.00146712\n",
      "Training loss: 0.0770935 , Training acc:  0.978964\n",
      "Test loss: 0.226847 , Test acc:  0.921809\n",
      "--------------------------------------------------------------------------------\n",
      "Step 9180\n",
      "learning_rate: 0.00146712\n",
      "Training loss: 0.0728825 , Training acc:  0.980127\n",
      "Test loss: 0.226169 , Test acc:  0.91716\n",
      "--------------------------------------------------------------------------------\n",
      "Step 9200\n",
      "learning_rate: 0.00146712\n",
      "Training loss: 0.0786591 , Training acc:  0.977484\n",
      "Test loss: 0.228995 , Test acc:  0.914624\n",
      "--------------------------------------------------------------------------------\n",
      "Step 9220\n",
      "learning_rate: 0.00146712\n",
      "Training loss: 0.0721617 , Training acc:  0.980973\n",
      "Test loss: 0.227666 , Test acc:  0.921386\n",
      "--------------------------------------------------------------------------------\n",
      "Step 9240\n",
      "learning_rate: 0.00145244\n",
      "Training loss: 0.0753521 , Training acc:  0.978964\n",
      "Test loss: 0.234809 , Test acc:  0.911243\n",
      "--------------------------------------------------------------------------------\n",
      "Step 9260\n",
      "learning_rate: 0.00145244\n",
      "Training loss: 0.0752032 , Training acc:  0.979175\n",
      "Test loss: 0.228817 , Test acc:  0.923922\n",
      "--------------------------------------------------------------------------------\n",
      "Step 9280\n",
      "learning_rate: 0.00145244\n",
      "Training loss: 0.0697905 , Training acc:  0.98277\n",
      "Test loss: 0.226392 , Test acc:  0.918428\n",
      "--------------------------------------------------------------------------------\n",
      "Step 9300\n",
      "learning_rate: 0.00143792\n",
      "Training loss: 0.0665888 , Training acc:  0.982241\n",
      "Test loss: 0.226994 , Test acc:  0.91885\n",
      "--------------------------------------------------------------------------------\n",
      "Step 9320\n",
      "learning_rate: 0.00143792\n",
      "Training loss: 0.0674023 , Training acc:  0.982135\n",
      "Test loss: 0.229413 , Test acc:  0.91716\n",
      "--------------------------------------------------------------------------------\n",
      "Step 9340\n",
      "learning_rate: 0.00143792\n",
      "Training loss: 0.0789186 , Training acc:  0.976744\n",
      "Test loss: 0.237518 , Test acc:  0.913779\n",
      "--------------------------------------------------------------------------------\n",
      "Step 9360\n",
      "learning_rate: 0.00143792\n",
      "Training loss: 0.0820879 , Training acc:  0.97759\n",
      "Test loss: 0.228842 , Test acc:  0.91885\n",
      "--------------------------------------------------------------------------------\n",
      "Step 9380\n",
      "learning_rate: 0.00142354\n",
      "Training loss: 0.0764981 , Training acc:  0.979704\n",
      "Test loss: 0.224411 , Test acc:  0.91885\n",
      "--------------------------------------------------------------------------------\n",
      "Step 9400\n",
      "learning_rate: 0.00142354\n",
      "Training loss: 0.0718333 , Training acc:  0.981607\n",
      "Test loss: 0.226584 , Test acc:  0.913356\n",
      "--------------------------------------------------------------------------------\n",
      "Step 9420\n",
      "learning_rate: 0.00142354\n",
      "Training loss: 0.0772554 , Training acc:  0.97759\n",
      "Test loss: 0.23337 , Test acc:  0.913779\n",
      "--------------------------------------------------------------------------------\n",
      "Step 9440\n",
      "learning_rate: 0.00142354\n",
      "Training loss: 0.0734842 , Training acc:  0.978647\n",
      "Test loss: 0.227719 , Test acc:  0.91885\n",
      "--------------------------------------------------------------------------------\n",
      "Step 9460\n",
      "learning_rate: 0.00140931\n",
      "Training loss: 0.0691746 , Training acc:  0.981184\n",
      "Test loss: 0.226088 , Test acc:  0.921386\n",
      "--------------------------------------------------------------------------------\n",
      "Step 9480\n",
      "learning_rate: 0.00140931\n",
      "Training loss: 0.0664171 , Training acc:  0.982875\n",
      "Test loss: 0.222042 , Test acc:  0.924345\n",
      "--------------------------------------------------------------------------------\n",
      "Step 9500\n",
      "learning_rate: 0.00140931\n",
      "Training loss: 0.0678744 , Training acc:  0.982558\n",
      "Test loss: 0.224112 , Test acc:  0.920118\n",
      "--------------------------------------------------------------------------------\n",
      "Step 9520\n",
      "learning_rate: 0.00140931\n",
      "Training loss: 0.0683559 , Training acc:  0.982452\n",
      "Test loss: 0.222637 , Test acc:  0.919696\n",
      "--------------------------------------------------------------------------------\n",
      "Step 9540\n",
      "learning_rate: 0.00139521\n",
      "Training loss: 0.0658186 , Training acc:  0.981924\n",
      "Test loss: 0.224934 , Test acc:  0.919273\n",
      "--------------------------------------------------------------------------------\n",
      "Step 9560\n",
      "learning_rate: 0.00139521\n",
      "Training loss: 0.0682922 , Training acc:  0.981607\n",
      "Test loss: 0.227952 , Test acc:  0.920541\n",
      "--------------------------------------------------------------------------------\n",
      "Step 9580\n",
      "learning_rate: 0.00139521\n",
      "Training loss: 0.0717341 , Training acc:  0.981395\n",
      "Test loss: 0.230865 , Test acc:  0.916314\n",
      "--------------------------------------------------------------------------------\n",
      "Step 9600\n",
      "learning_rate: 0.00138126\n",
      "Training loss: 0.0678498 , Training acc:  0.983192\n",
      "Test loss: 0.218975 , Test acc:  0.919273\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 9620\n",
      "learning_rate: 0.00138126\n",
      "Training loss: 0.075377 , Training acc:  0.979598\n",
      "Test loss: 0.233511 , Test acc:  0.914201\n",
      "--------------------------------------------------------------------------------\n",
      "Step 9640\n",
      "learning_rate: 0.00138126\n",
      "Training loss: 0.0654789 , Training acc:  0.984778\n",
      "Test loss: 0.219912 , Test acc:  0.923077\n",
      "--------------------------------------------------------------------------------\n",
      "Step 9660\n",
      "learning_rate: 0.00138126\n",
      "Training loss: 0.0658214 , Training acc:  0.985095\n",
      "Test loss: 0.221545 , Test acc:  0.918428\n",
      "--------------------------------------------------------------------------------\n",
      "Step 9680\n",
      "learning_rate: 0.00136745\n",
      "Training loss: 0.0708021 , Training acc:  0.981078\n",
      "Test loss: 0.230476 , Test acc:  0.916737\n",
      "--------------------------------------------------------------------------------\n",
      "Step 9700\n",
      "learning_rate: 0.00136745\n",
      "Training loss: 0.0676826 , Training acc:  0.982241\n",
      "Test loss: 0.230532 , Test acc:  0.916314\n",
      "--------------------------------------------------------------------------------\n",
      "Step 9720\n",
      "learning_rate: 0.00136745\n",
      "Training loss: 0.0628309 , Training acc:  0.984038\n",
      "Test loss: 0.22258 , Test acc:  0.918428\n",
      "--------------------------------------------------------------------------------\n",
      "Step 9740\n",
      "learning_rate: 0.00136745\n",
      "Training loss: 0.068362 , Training acc:  0.98203\n",
      "Test loss: 0.233947 , Test acc:  0.916314\n",
      "--------------------------------------------------------------------------------\n",
      "Step 9760\n",
      "learning_rate: 0.00135377\n",
      "Training loss: 0.064762 , Training acc:  0.983087\n",
      "Test loss: 0.226386 , Test acc:  0.919273\n",
      "--------------------------------------------------------------------------------\n",
      "Step 9780\n",
      "learning_rate: 0.00135377\n",
      "Training loss: 0.0713963 , Training acc:  0.982452\n",
      "Test loss: 0.228905 , Test acc:  0.920541\n",
      "--------------------------------------------------------------------------------\n",
      "Step 9800\n",
      "learning_rate: 0.00135377\n",
      "Training loss: 0.0684367 , Training acc:  0.985729\n",
      "Test loss: 0.225388 , Test acc:  0.920541\n",
      "--------------------------------------------------------------------------------\n",
      "Step 9820\n",
      "learning_rate: 0.00135377\n",
      "Training loss: 0.0640748 , Training acc:  0.985729\n",
      "Test loss: 0.2227 , Test acc:  0.917582\n",
      "--------------------------------------------------------------------------------\n",
      "Step 9840\n",
      "learning_rate: 0.00134024\n",
      "Training loss: 0.0786502 , Training acc:  0.979387\n",
      "Test loss: 0.236549 , Test acc:  0.918005\n",
      "--------------------------------------------------------------------------------\n",
      "Step 9860\n",
      "learning_rate: 0.00134024\n",
      "Training loss: 0.0819377 , Training acc:  0.977696\n",
      "Test loss: 0.23984 , Test acc:  0.912511\n",
      "--------------------------------------------------------------------------------\n",
      "Step 9880\n",
      "learning_rate: 0.00134024\n",
      "Training loss: 0.0781469 , Training acc:  0.980127\n",
      "Test loss: 0.231403 , Test acc:  0.918005\n",
      "--------------------------------------------------------------------------------\n",
      "Step 9900\n",
      "learning_rate: 0.00132683\n",
      "Training loss: 0.0681442 , Training acc:  0.984989\n",
      "Test loss: 0.223816 , Test acc:  0.919696\n",
      "--------------------------------------------------------------------------------\n",
      "Step 9920\n",
      "learning_rate: 0.00132683\n",
      "Training loss: 0.0702754 , Training acc:  0.983192\n",
      "Test loss: 0.228088 , Test acc:  0.920541\n",
      "--------------------------------------------------------------------------------\n",
      "Step 9940\n",
      "learning_rate: 0.00132683\n",
      "Training loss: 0.0716256 , Training acc:  0.981078\n",
      "Test loss: 0.234404 , Test acc:  0.915047\n",
      "--------------------------------------------------------------------------------\n",
      "Step 9960\n",
      "learning_rate: 0.00132683\n",
      "Training loss: 0.0641869 , Training acc:  0.983087\n",
      "Test loss: 0.230195 , Test acc:  0.916737\n",
      "--------------------------------------------------------------------------------\n",
      "Step 9980\n",
      "learning_rate: 0.00131356\n",
      "Training loss: 0.0682753 , Training acc:  0.983932\n",
      "Test loss: 0.233628 , Test acc:  0.91716\n",
      "--------------------------------------------------------------------------------\n",
      "Step 10000\n",
      "learning_rate: 0.00131356\n",
      "Training loss: 0.0640488 , Training acc:  0.983298\n",
      "Test loss: 0.229501 , Test acc:  0.918428\n",
      "--------------------------------------------------------------------------------\n",
      "Step 10020\n",
      "learning_rate: 0.00131356\n",
      "Training loss: 0.0632856 , Training acc:  0.983615\n",
      "Test loss: 0.232059 , Test acc:  0.920964\n",
      "--------------------------------------------------------------------------------\n",
      "Step 10040\n",
      "learning_rate: 0.00131356\n",
      "Training loss: 0.0653117 , Training acc:  0.983615\n",
      "Test loss: 0.229996 , Test acc:  0.917582\n",
      "--------------------------------------------------------------------------------\n",
      "Step 10060\n",
      "learning_rate: 0.00130043\n",
      "Training loss: 0.059936 , Training acc:  0.986998\n",
      "Test loss: 0.223043 , Test acc:  0.91885\n",
      "--------------------------------------------------------------------------------\n",
      "Step 10080\n",
      "learning_rate: 0.00130043\n",
      "Training loss: 0.0719668 , Training acc:  0.980973\n",
      "Test loss: 0.241414 , Test acc:  0.91716\n",
      "--------------------------------------------------------------------------------\n",
      "Step 10100\n",
      "learning_rate: 0.00130043\n",
      "Training loss: 0.059066 , Training acc:  0.986892\n",
      "Test loss: 0.22245 , Test acc:  0.923922\n",
      "--------------------------------------------------------------------------------\n",
      "Step 10120\n",
      "learning_rate: 0.00130043\n",
      "Training loss: 0.0661144 , Training acc:  0.984884\n",
      "Test loss: 0.232709 , Test acc:  0.921386\n",
      "--------------------------------------------------------------------------------\n",
      "Step 10140\n",
      "learning_rate: 0.00128742\n",
      "Training loss: 0.0643334 , Training acc:  0.984778\n",
      "Test loss: 0.232314 , Test acc:  0.918428\n",
      "--------------------------------------------------------------------------------\n",
      "Step 10160\n",
      "learning_rate: 0.00128742\n",
      "Training loss: 0.0639414 , Training acc:  0.983721\n",
      "Test loss: 0.224005 , Test acc:  0.922654\n",
      "--------------------------------------------------------------------------------\n",
      "Step 10180\n",
      "learning_rate: 0.00128742\n",
      "Training loss: 0.0662736 , Training acc:  0.984249\n",
      "Test loss: 0.222316 , Test acc:  0.920118\n",
      "--------------------------------------------------------------------------------\n",
      "Step 10200\n",
      "learning_rate: 0.00127455\n",
      "Training loss: 0.0699688 , Training acc:  0.984355\n",
      "Test loss: 0.225067 , Test acc:  0.920118\n",
      "--------------------------------------------------------------------------------\n",
      "Step 10220\n",
      "learning_rate: 0.00127455\n",
      "Training loss: 0.0656513 , Training acc:  0.983932\n",
      "Test loss: 0.22039 , Test acc:  0.916737\n",
      "--------------------------------------------------------------------------------\n",
      "Step 10240\n",
      "learning_rate: 0.00127455\n",
      "Training loss: 0.0627929 , Training acc:  0.984778\n",
      "Test loss: 0.21786 , Test acc:  0.920118\n",
      "--------------------------------------------------------------------------------\n",
      "Step 10260\n",
      "learning_rate: 0.00127455\n",
      "Training loss: 0.0727181 , Training acc:  0.982135\n",
      "Test loss: 0.225242 , Test acc:  0.919273\n",
      "--------------------------------------------------------------------------------\n",
      "Step 10280\n",
      "learning_rate: 0.0012618\n",
      "Training loss: 0.0702995 , Training acc:  0.983192\n",
      "Test loss: 0.217654 , Test acc:  0.921809\n",
      "--------------------------------------------------------------------------------\n",
      "Step 10300\n",
      "learning_rate: 0.0012618\n",
      "Training loss: 0.0680353 , Training acc:  0.981712\n",
      "Test loss: 0.222035 , Test acc:  0.91716\n",
      "--------------------------------------------------------------------------------\n",
      "Step 10320\n",
      "learning_rate: 0.0012618\n",
      "Training loss: 0.0712688 , Training acc:  0.982241\n",
      "Test loss: 0.230132 , Test acc:  0.917582\n",
      "--------------------------------------------------------------------------------\n",
      "Step 10340\n",
      "learning_rate: 0.0012618\n",
      "Training loss: 0.062125 , Training acc:  0.986364\n",
      "Test loss: 0.214247 , Test acc:  0.921386\n",
      "--------------------------------------------------------------------------------\n",
      "Step 10360\n",
      "learning_rate: 0.00124919\n",
      "Training loss: 0.0656141 , Training acc:  0.984989\n",
      "Test loss: 0.220299 , Test acc:  0.916737\n",
      "--------------------------------------------------------------------------------\n",
      "Step 10380\n",
      "learning_rate: 0.00124919\n",
      "Training loss: 0.0658485 , Training acc:  0.985412\n",
      "Test loss: 0.217286 , Test acc:  0.921386\n",
      "--------------------------------------------------------------------------------\n",
      "Step 10400\n",
      "learning_rate: 0.00124919\n",
      "Training loss: 0.0650297 , Training acc:  0.984567\n",
      "Test loss: 0.218498 , Test acc:  0.924345\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 10420\n",
      "learning_rate: 0.00124919\n",
      "Training loss: 0.0608904 , Training acc:  0.986786\n",
      "Test loss: 0.21521 , Test acc:  0.9235\n",
      "--------------------------------------------------------------------------------\n",
      "Step 10440\n",
      "learning_rate: 0.00123669\n",
      "Training loss: 0.0802054 , Training acc:  0.978541\n",
      "Test loss: 0.240139 , Test acc:  0.91716\n",
      "--------------------------------------------------------------------------------\n",
      "Step 10460\n",
      "learning_rate: 0.00123669\n",
      "Training loss: 0.0635391 , Training acc:  0.983721\n",
      "Test loss: 0.222375 , Test acc:  0.920964\n",
      "--------------------------------------------------------------------------------\n",
      "Step 10480\n",
      "learning_rate: 0.00123669\n",
      "Training loss: 0.0586366 , Training acc:  0.986152\n",
      "Test loss: 0.216387 , Test acc:  0.922232\n",
      "--------------------------------------------------------------------------------\n",
      "Step 10500\n",
      "learning_rate: 0.00122433\n",
      "Training loss: 0.0650791 , Training acc:  0.983615\n",
      "Test loss: 0.227551 , Test acc:  0.921809\n",
      "--------------------------------------------------------------------------------\n",
      "Step 10520\n",
      "learning_rate: 0.00122433\n",
      "Training loss: 0.0653333 , Training acc:  0.982241\n",
      "Test loss: 0.226983 , Test acc:  0.921386\n",
      "--------------------------------------------------------------------------------\n",
      "Step 10540\n",
      "learning_rate: 0.00122433\n",
      "Training loss: 0.0698887 , Training acc:  0.983298\n",
      "Test loss: 0.231709 , Test acc:  0.921386\n",
      "--------------------------------------------------------------------------------\n",
      "Step 10560\n",
      "learning_rate: 0.00122433\n",
      "Training loss: 0.0643177 , Training acc:  0.983827\n",
      "Test loss: 0.222928 , Test acc:  0.920541\n",
      "--------------------------------------------------------------------------------\n",
      "Step 10580\n",
      "learning_rate: 0.00121208\n",
      "Training loss: 0.0610452 , Training acc:  0.987315\n",
      "Test loss: 0.216962 , Test acc:  0.918428\n",
      "--------------------------------------------------------------------------------\n",
      "Step 10600\n",
      "learning_rate: 0.00121208\n",
      "Training loss: 0.0615459 , Training acc:  0.988161\n",
      "Test loss: 0.215119 , Test acc:  0.924345\n",
      "--------------------------------------------------------------------------------\n",
      "Step 10620\n",
      "learning_rate: 0.00121208\n",
      "Training loss: 0.0598279 , Training acc:  0.986998\n",
      "Test loss: 0.220115 , Test acc:  0.920118\n",
      "--------------------------------------------------------------------------------\n",
      "Step 10640\n",
      "learning_rate: 0.00121208\n",
      "Training loss: 0.0600789 , Training acc:  0.985941\n",
      "Test loss: 0.227655 , Test acc:  0.918428\n",
      "--------------------------------------------------------------------------------\n",
      "Step 10660\n",
      "learning_rate: 0.00119996\n",
      "Training loss: 0.0650787 , Training acc:  0.985941\n",
      "Test loss: 0.233601 , Test acc:  0.919696\n",
      "--------------------------------------------------------------------------------\n",
      "Step 10680\n",
      "learning_rate: 0.00119996\n",
      "Training loss: 0.063302 , Training acc:  0.985729\n",
      "Test loss: 0.231418 , Test acc:  0.921809\n",
      "--------------------------------------------------------------------------------\n",
      "Step 10700\n",
      "learning_rate: 0.00119996\n",
      "Training loss: 0.0670461 , Training acc:  0.982558\n",
      "Test loss: 0.237689 , Test acc:  0.916314\n",
      "--------------------------------------------------------------------------------\n",
      "Step 10720\n",
      "learning_rate: 0.00119996\n",
      "Training loss: 0.0662111 , Training acc:  0.981395\n",
      "Test loss: 0.247979 , Test acc:  0.911665\n",
      "--------------------------------------------------------------------------------\n",
      "Step 10740\n",
      "learning_rate: 0.00118796\n",
      "Training loss: 0.058633 , Training acc:  0.986046\n",
      "Test loss: 0.227798 , Test acc:  0.919696\n",
      "--------------------------------------------------------------------------------\n",
      "Step 10760\n",
      "learning_rate: 0.00118796\n",
      "Training loss: 0.0620912 , Training acc:  0.983721\n",
      "Test loss: 0.237179 , Test acc:  0.915892\n",
      "--------------------------------------------------------------------------------\n",
      "Step 10780\n",
      "learning_rate: 0.00118796\n",
      "Training loss: 0.0616676 , Training acc:  0.985095\n",
      "Test loss: 0.235556 , Test acc:  0.916737\n",
      "--------------------------------------------------------------------------------\n",
      "Step 10800\n",
      "learning_rate: 0.00117608\n",
      "Training loss: 0.0620936 , Training acc:  0.985201\n",
      "Test loss: 0.229366 , Test acc:  0.91716\n",
      "--------------------------------------------------------------------------------\n",
      "Step 10820\n",
      "learning_rate: 0.00117608\n",
      "Training loss: 0.0617739 , Training acc:  0.984884\n",
      "Test loss: 0.224172 , Test acc:  0.919273\n",
      "--------------------------------------------------------------------------------\n",
      "Step 10840\n",
      "learning_rate: 0.00117608\n",
      "Training loss: 0.0689064 , Training acc:  0.984461\n",
      "Test loss: 0.227882 , Test acc:  0.919273\n",
      "--------------------------------------------------------------------------------\n",
      "Step 10860\n",
      "learning_rate: 0.00117608\n",
      "Training loss: 0.06238 , Training acc:  0.985835\n",
      "Test loss: 0.222249 , Test acc:  0.915892\n",
      "--------------------------------------------------------------------------------\n",
      "Step 10880\n",
      "learning_rate: 0.00116432\n",
      "Training loss: 0.0642756 , Training acc:  0.984355\n",
      "Test loss: 0.221132 , Test acc:  0.921809\n",
      "--------------------------------------------------------------------------------\n",
      "Step 10900\n",
      "learning_rate: 0.00116432\n",
      "Training loss: 0.0734342 , Training acc:  0.980655\n",
      "Test loss: 0.239872 , Test acc:  0.911665\n",
      "--------------------------------------------------------------------------------\n",
      "Step 10920\n",
      "learning_rate: 0.00116432\n",
      "Training loss: 0.0572493 , Training acc:  0.987421\n",
      "Test loss: 0.220041 , Test acc:  0.918005\n",
      "--------------------------------------------------------------------------------\n",
      "Step 10940\n",
      "learning_rate: 0.00116432\n",
      "Training loss: 0.0560172 , Training acc:  0.987526\n",
      "Test loss: 0.216181 , Test acc:  0.919696\n",
      "--------------------------------------------------------------------------------\n",
      "Step 10960\n",
      "learning_rate: 0.00115268\n",
      "Training loss: 0.0551657 , Training acc:  0.987421\n",
      "Test loss: 0.2129 , Test acc:  0.918005\n",
      "--------------------------------------------------------------------------------\n",
      "Step 10980\n",
      "learning_rate: 0.00115268\n",
      "Training loss: 0.0562088 , Training acc:  0.987738\n",
      "Test loss: 0.216524 , Test acc:  0.91885\n",
      "--------------------------------------------------------------------------------\n",
      "Step 11000\n",
      "learning_rate: 0.00115268\n",
      "Training loss: 0.0635832 , Training acc:  0.983615\n",
      "Test loss: 0.231387 , Test acc:  0.913779\n",
      "--------------------------------------------------------------------------------\n",
      "Step 11020\n",
      "learning_rate: 0.00115268\n",
      "Training loss: 0.0589026 , Training acc:  0.985624\n",
      "Test loss: 0.219538 , Test acc:  0.91885\n",
      "--------------------------------------------------------------------------------\n",
      "Step 11040\n",
      "learning_rate: 0.00114115\n",
      "Training loss: 0.0559488 , Training acc:  0.986786\n",
      "Test loss: 0.212904 , Test acc:  0.9235\n",
      "--------------------------------------------------------------------------------\n",
      "Step 11060\n",
      "learning_rate: 0.00114115\n",
      "Training loss: 0.0578057 , Training acc:  0.986575\n",
      "Test loss: 0.215769 , Test acc:  0.924768\n",
      "--------------------------------------------------------------------------------\n",
      "Step 11080\n",
      "learning_rate: 0.00114115\n",
      "Training loss: 0.0573123 , Training acc:  0.986786\n",
      "Test loss: 0.222409 , Test acc:  0.921386\n",
      "--------------------------------------------------------------------------------\n",
      "Step 11100\n",
      "learning_rate: 0.00112974\n",
      "Training loss: 0.0593104 , Training acc:  0.984884\n",
      "Test loss: 0.220983 , Test acc:  0.920118\n",
      "--------------------------------------------------------------------------------\n",
      "Step 11120\n",
      "learning_rate: 0.00112974\n",
      "Training loss: 0.0678371 , Training acc:  0.983827\n",
      "Test loss: 0.226737 , Test acc:  0.920541\n",
      "--------------------------------------------------------------------------------\n",
      "Step 11140\n",
      "learning_rate: 0.00112974\n",
      "Training loss: 0.0582462 , Training acc:  0.986258\n",
      "Test loss: 0.219693 , Test acc:  0.92519\n",
      "--------------------------------------------------------------------------------\n",
      "Step 11160\n",
      "learning_rate: 0.00112974\n",
      "Training loss: 0.0655274 , Training acc:  0.983615\n",
      "Test loss: 0.233543 , Test acc:  0.923077\n",
      "--------------------------------------------------------------------------------\n",
      "Step 11180\n",
      "learning_rate: 0.00111844\n",
      "Training loss: 0.0566716 , Training acc:  0.986681\n",
      "Test loss: 0.222019 , Test acc:  0.923077\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 11200\n",
      "learning_rate: 0.00111844\n",
      "Training loss: 0.0547472 , Training acc:  0.987738\n",
      "Test loss: 0.219146 , Test acc:  0.928149\n",
      "--------------------------------------------------------------------------------\n",
      "Step 11220\n",
      "learning_rate: 0.00111844\n",
      "Training loss: 0.0497111 , Training acc:  0.988689\n",
      "Test loss: 0.218854 , Test acc:  0.927303\n",
      "--------------------------------------------------------------------------------\n",
      "Step 11240\n",
      "learning_rate: 0.00111844\n",
      "Training loss: 0.0549991 , Training acc:  0.986364\n",
      "Test loss: 0.22531 , Test acc:  0.921809\n",
      "--------------------------------------------------------------------------------\n",
      "Step 11260\n",
      "learning_rate: 0.00110726\n",
      "Training loss: 0.0510401 , Training acc:  0.987844\n",
      "Test loss: 0.21802 , Test acc:  0.923922\n",
      "--------------------------------------------------------------------------------\n",
      "Step 11280\n",
      "learning_rate: 0.00110726\n",
      "Training loss: 0.0517553 , Training acc:  0.986786\n",
      "Test loss: 0.227158 , Test acc:  0.922654\n",
      "--------------------------------------------------------------------------------\n",
      "Step 11300\n",
      "learning_rate: 0.00110726\n",
      "Training loss: 0.0524895 , Training acc:  0.987844\n",
      "Test loss: 0.220946 , Test acc:  0.92519\n",
      "--------------------------------------------------------------------------------\n",
      "Step 11320\n",
      "learning_rate: 0.00110726\n",
      "Training loss: 0.0523456 , Training acc:  0.987844\n",
      "Test loss: 0.214703 , Test acc:  0.927303\n",
      "--------------------------------------------------------------------------------\n",
      "Step 11340\n",
      "learning_rate: 0.00109619\n",
      "Training loss: 0.0554415 , Training acc:  0.988055\n",
      "Test loss: 0.214867 , Test acc:  0.925613\n",
      "--------------------------------------------------------------------------------\n",
      "Step 11360\n",
      "learning_rate: 0.00109619\n",
      "Training loss: 0.058807 , Training acc:  0.985941\n",
      "Test loss: 0.216354 , Test acc:  0.928571\n",
      "--------------------------------------------------------------------------------\n",
      "Step 11380\n",
      "learning_rate: 0.00109619\n",
      "Training loss: 0.0605385 , Training acc:  0.985624\n",
      "Test loss: 0.214984 , Test acc:  0.927726\n",
      "--------------------------------------------------------------------------------\n",
      "Step 11400\n",
      "learning_rate: 0.00108523\n",
      "Training loss: 0.0626413 , Training acc:  0.985307\n",
      "Test loss: 0.217632 , Test acc:  0.926881\n",
      "--------------------------------------------------------------------------------\n",
      "Step 11420\n",
      "learning_rate: 0.00108523\n",
      "Training loss: 0.0593541 , Training acc:  0.986575\n",
      "Test loss: 0.215481 , Test acc:  0.923077\n",
      "--------------------------------------------------------------------------------\n",
      "Step 11440\n",
      "learning_rate: 0.00108523\n",
      "Training loss: 0.0560543 , Training acc:  0.986998\n",
      "Test loss: 0.214492 , Test acc:  0.927303\n",
      "--------------------------------------------------------------------------------\n",
      "Step 11460\n",
      "learning_rate: 0.00108523\n",
      "Training loss: 0.0604891 , Training acc:  0.986046\n",
      "Test loss: 0.225518 , Test acc:  0.9235\n",
      "--------------------------------------------------------------------------------\n",
      "Step 11480\n",
      "learning_rate: 0.00107437\n",
      "Training loss: 0.0541544 , Training acc:  0.989429\n",
      "Test loss: 0.219213 , Test acc:  0.926458\n",
      "--------------------------------------------------------------------------------\n",
      "Step 11500\n",
      "learning_rate: 0.00107437\n",
      "Training loss: 0.0551047 , Training acc:  0.988795\n",
      "Test loss: 0.215533 , Test acc:  0.92519\n",
      "--------------------------------------------------------------------------------\n",
      "Step 11520\n",
      "learning_rate: 0.00107437\n",
      "Training loss: 0.0521272 , Training acc:  0.986998\n",
      "Test loss: 0.210893 , Test acc:  0.924345\n",
      "--------------------------------------------------------------------------------\n",
      "Step 11540\n",
      "learning_rate: 0.00107437\n",
      "Training loss: 0.0578778 , Training acc:  0.986469\n",
      "Test loss: 0.214624 , Test acc:  0.925613\n",
      "--------------------------------------------------------------------------------\n",
      "Step 11560\n",
      "learning_rate: 0.00106363\n",
      "Training loss: 0.0583357 , Training acc:  0.988266\n",
      "Test loss: 0.217865 , Test acc:  0.926458\n",
      "--------------------------------------------------------------------------------\n",
      "Step 11580\n",
      "learning_rate: 0.00106363\n",
      "Training loss: 0.0525523 , Training acc:  0.987844\n",
      "Test loss: 0.214966 , Test acc:  0.925613\n",
      "--------------------------------------------------------------------------------\n",
      "Step 11600\n",
      "learning_rate: 0.00106363\n",
      "Training loss: 0.053366 , Training acc:  0.988372\n",
      "Test loss: 0.215347 , Test acc:  0.924345\n",
      "--------------------------------------------------------------------------------\n",
      "Step 11620\n",
      "learning_rate: 0.00106363\n",
      "Training loss: 0.0567077 , Training acc:  0.988055\n",
      "Test loss: 0.212777 , Test acc:  0.927303\n",
      "--------------------------------------------------------------------------------\n",
      "Step 11640\n",
      "learning_rate: 0.00105299\n",
      "Training loss: 0.0619642 , Training acc:  0.985412\n",
      "Test loss: 0.224865 , Test acc:  0.919273\n",
      "--------------------------------------------------------------------------------\n",
      "Step 11660\n",
      "learning_rate: 0.00105299\n",
      "Training loss: 0.0577251 , Training acc:  0.986046\n",
      "Test loss: 0.221373 , Test acc:  0.923922\n",
      "--------------------------------------------------------------------------------\n",
      "Step 11680\n",
      "learning_rate: 0.00105299\n",
      "Training loss: 0.0535486 , Training acc:  0.986681\n",
      "Test loss: 0.219678 , Test acc:  0.919273\n",
      "--------------------------------------------------------------------------------\n",
      "Step 11700\n",
      "learning_rate: 0.00104246\n",
      "Training loss: 0.0516928 , Training acc:  0.987738\n",
      "Test loss: 0.212596 , Test acc:  0.927303\n",
      "--------------------------------------------------------------------------------\n",
      "Step 11720\n",
      "learning_rate: 0.00104246\n",
      "Training loss: 0.0490438 , Training acc:  0.991015\n",
      "Test loss: 0.209733 , Test acc:  0.924768\n",
      "--------------------------------------------------------------------------------\n",
      "Step 11740\n",
      "learning_rate: 0.00104246\n",
      "Training loss: 0.0489748 , Training acc:  0.989641\n",
      "Test loss: 0.213312 , Test acc:  0.926458\n",
      "--------------------------------------------------------------------------------\n",
      "Step 11760\n",
      "learning_rate: 0.00104246\n",
      "Training loss: 0.0491978 , Training acc:  0.989218\n",
      "Test loss: 0.21467 , Test acc:  0.926036\n",
      "--------------------------------------------------------------------------------\n",
      "Step 11780\n",
      "learning_rate: 0.00103204\n",
      "Training loss: 0.0523895 , Training acc:  0.988372\n",
      "Test loss: 0.216589 , Test acc:  0.927726\n",
      "--------------------------------------------------------------------------------\n",
      "Step 11800\n",
      "learning_rate: 0.00103204\n",
      "Training loss: 0.0603816 , Training acc:  0.985412\n",
      "Test loss: 0.221453 , Test acc:  0.920964\n",
      "--------------------------------------------------------------------------------\n",
      "Step 11820\n",
      "learning_rate: 0.00103204\n",
      "Training loss: 0.06447 , Training acc:  0.984989\n",
      "Test loss: 0.22041 , Test acc:  0.920118\n",
      "--------------------------------------------------------------------------------\n",
      "Step 11840\n",
      "learning_rate: 0.00103204\n",
      "Training loss: 0.0546706 , Training acc:  0.989323\n",
      "Test loss: 0.21439 , Test acc:  0.920118\n",
      "--------------------------------------------------------------------------------\n",
      "Optimization Finished!\n",
      "Training Accuracy: 0.989323\n",
      "Test Accuracy: 0.920118\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "RUN_NAME = 'tf_on_gpu_train_test_split'\n",
    "writer_train = tf.summary.FileWriter('./log/' + RUN_NAME + '/train', graph=sess.graph)\n",
    "writer_test = tf.summary.FileWriter('./log/' + RUN_NAME + '/test', graph=sess.graph)\n",
    "\n",
    "steps = 0\n",
    "# Keep training until reach max iterations\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    indices = np.arange(len(y_train))\n",
    "    np.random.shuffle(indices)\n",
    "    X_train, y_train =  X_train[indices], y_train[indices]\n",
    "\n",
    "    for start, end in feed_next_batch(len(X_train), batch_size=batch_size):\n",
    "        # Run optimization op (backprop)\n",
    "        batch_x, batch_y = X_train[start:end], y_train[start:end]\n",
    "        sess.run(optimizer, feed_dict={x: batch_x, y: batch_y, keep_prob: dropout})\n",
    "        \n",
    "        steps += 1\n",
    "        \n",
    "        if steps % 20 == 0:\n",
    "\n",
    "            # Calculate batch loss and accuracy\n",
    "            train_loss, train_acc, train_lr, summary_train = sess.run([loss, accuracy, learning_rate, summary], \n",
    "                                                   feed_dict={x: X_train, y: y_train, keep_prob: 1.0})\n",
    "            writer_train.add_summary(summary_train, steps)\n",
    "\n",
    "            print('Step %d' % (steps))\n",
    "            print('learning_rate:', train_lr)\n",
    "            print (\"Training loss:\", train_loss, ', Training acc: ', train_acc)\n",
    "\n",
    "            val_loss, val_acc, summary_test = sess.run([loss, accuracy, summary], feed_dict={x: X_test, \n",
    "                                                                        y: y_test,\n",
    "                                                                       keep_prob: 1.0})\n",
    "            writer_test.add_summary(summary_test, steps)\n",
    "            print (\"Test loss:\", val_loss, ', Test acc: ', val_acc)\n",
    "            print('-' * 80)\n",
    "\n",
    "print (\"Optimization Finished!\")\n",
    "\n",
    "# Calculate accuracy for all test samples\n",
    "print (\"Training Accuracy:\", \\\n",
    "    sess.run(accuracy, feed_dict={x: X_train,\n",
    "                                  y: y_train,\n",
    "                                 keep_prob: 1.0}))\n",
    "print (\"Test Accuracy:\", \\\n",
    "    sess.run(accuracy, feed_dict={x: X_test,\n",
    "                                  y: y_test,\n",
    "                                 keep_prob: 1.0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fcffa9d7c18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sess.close()\n",
    "\n",
    "arr5 = np.arange(0, 3600)\n",
    "arr5 = 0.0075 * 0.99 ** (arr5/75)\n",
    "plt.plot(arr5, '--'),\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
