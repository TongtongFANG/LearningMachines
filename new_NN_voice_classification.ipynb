{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import librosa\n",
    "from librosa import display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from matplotlib.pyplot import specgram\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "plt.rcParams['font.serif'] = 'Ubuntu'\n",
    "plt.rcParams['font.monospace'] = 'Ubuntu Mono'\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.rcParams['axes.labelsize'] = 11\n",
    "plt.rcParams['axes.labelweight'] = 'bold'\n",
    "plt.rcParams['axes.titlesize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 10\n",
    "plt.rcParams['ytick.labelsize'] = 10\n",
    "plt.rcParams['legend.fontsize'] = 11\n",
    "plt.rcParams['figure.titlesize'] = 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "features = np.loadtxt('nn_simple_features.csv', delimiter=',')\n",
    "labels = np.array(np.loadtxt('nn_simple_labels.csv', delimiter=','), dtype=np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "X_all = features\n",
    "y_all = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "\n",
    "X_not_test, X_test, y_not_rest, y_test = train_test_split(\n",
    "    X_all, y_all, stratify=y_all, train_size=.85, random_state=round(time.time()))\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_not_test, y_not_rest, stratify=y_not_rest, train_size=.9, random_state=round(time.time()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9046, 1280)\n",
      "(9046, 5)\n",
      "(1006, 1280)\n",
      "(1006, 5)\n",
      "(1774, 1280)\n",
      "(1774, 5)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_val.shape)\n",
    "print(y_val.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## Imports\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# print(K.image_data_format())\n",
    "\n",
    "# X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
    "# X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
    "# X_val = X_val.reshape(X_val.shape[0], img_rows, img_cols, 1)\n",
    "# input_shape = (img_rows, img_cols, 1)\n",
    "# print(X_train.shape)\n",
    "# print(y_train.shape)\n",
    "# print(X_val.shape)\n",
    "# print(y_val.shape)\n",
    "# print(X_test.shape)\n",
    "# print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "# learning_rate = 0.005\n",
    "\n",
    "global_step = tf.Variable(0, trainable=False)\n",
    "starter_learning_rate = 0.005\n",
    "learning_rate = tf.train.exponential_decay(starter_learning_rate, global_step,\n",
    "                                           50, 0.99, staircase=True)\n",
    "\n",
    "training_iters = 4000\n",
    "batch_size = 100\n",
    "test_step = 40\n",
    "\n",
    "# Network Parameters\n",
    "n_input = 40 * 32\n",
    "n_classes = 5\n",
    "dropout = .8 # Dropout, probability to keep units\n",
    "\n",
    "# 1. Define Variables and Placeholders\n",
    "x = tf.placeholder(tf.float32, [None, n_input])\n",
    "y = tf.placeholder(tf.float32, [None, n_classes])\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32) #dropout (keep probability)\n",
    "\n",
    "def build_model(x, dropout, activation):\n",
    "    \n",
    "    x = tf.reshape(x, shape=[-1, 40, 32, 1])\n",
    "    \n",
    "    conv1 = tf.layers.conv2d(x, 4, 5, activation=activation)\n",
    "    conv1 = tf.layers.batch_normalization(conv1)\n",
    "    conv1 = tf.layers.max_pooling2d(conv1, 2, 2)\n",
    "    conv1 = tf.nn.dropout(conv1, dropout)\n",
    "    \n",
    "    conv2 = tf.layers.conv2d(conv1, 8, 3, activation=activation)\n",
    "    conv2 = tf.layers.batch_normalization(conv2)\n",
    "    conv2 = tf.layers.max_pooling2d(conv2, 2, 2)\n",
    "    conv2 = tf.nn.dropout(conv2, dropout)\n",
    "    \n",
    "    fc1 = tf.contrib.layers.flatten(conv2)\n",
    "\n",
    "    fc1 = tf.layers.dense(fc1, 128, activation=activation)\n",
    "    fc1 = tf.layers.batch_normalization(fc1)\n",
    "    fc1 = tf.nn.dropout(fc1, dropout)\n",
    "\n",
    "    fc2 = tf.layers.dense(fc1, 64, activation=activation)\n",
    "    fc2 = tf.layers.batch_normalization(fc2)\n",
    "    fc2 = tf.nn.dropout(fc2, dropout)\n",
    "    \n",
    "    out = tf.layers.dense(fc2, n_classes)\n",
    "\n",
    "    return out\n",
    "\n",
    "predictions = build_model(x, keep_prob, activation=tf.nn.relu)\n",
    "# 3. Define the loss function  \n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=predictions, labels=y))\n",
    "# 4. Define the accuracy \n",
    "correct_pred = tf.equal(tf.argmax(predictions, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# 5. Define an optimizer\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost, global_step=global_step)\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate: 0.005\n",
      "Batch 40, Training Loss= 1.598171, Train Accuracy= 0.26631\n",
      "Validation loss: 1.60151 , Validation acc:  0.261431\n",
      "--------------------------------------------------------------------------------\n",
      "learning_rate: 0.00495\n",
      "Batch 80, Training Loss= 1.528448, Train Accuracy= 0.31793\n",
      "Validation loss: 1.53208 , Validation acc:  0.316103\n",
      "--------------------------------------------------------------------------------\n",
      "learning_rate: 0.0049005\n",
      "Batch 120, Training Loss= 1.441624, Train Accuracy= 0.38017\n",
      "Validation loss: 1.45431 , Validation acc:  0.371769\n",
      "--------------------------------------------------------------------------------\n",
      "learning_rate: 0.00485149\n",
      "Batch 160, Training Loss= 1.361797, Train Accuracy= 0.44075\n",
      "Validation loss: 1.39179 , Validation acc:  0.43837\n",
      "--------------------------------------------------------------------------------\n",
      "learning_rate: 0.00480298\n",
      "Batch 200, Training Loss= 1.259116, Train Accuracy= 0.51437\n",
      "Validation loss: 1.28202 , Validation acc:  0.50994\n",
      "--------------------------------------------------------------------------------\n",
      "learning_rate: 0.00480298\n",
      "Batch 240, Training Loss= 1.188660, Train Accuracy= 0.53991\n",
      "Validation loss: 1.22515 , Validation acc:  0.528827\n",
      "--------------------------------------------------------------------------------\n",
      "learning_rate: 0.00475495\n",
      "Batch 280, Training Loss= 0.970214, Train Accuracy= 0.65675\n",
      "Validation loss: 1.00151 , Validation acc:  0.641153\n",
      "--------------------------------------------------------------------------------\n",
      "learning_rate: 0.0047074\n",
      "Batch 320, Training Loss= 0.943437, Train Accuracy= 0.66328\n",
      "Validation loss: 0.988849 , Validation acc:  0.627237\n",
      "--------------------------------------------------------------------------------\n",
      "learning_rate: 0.00466033\n",
      "Batch 360, Training Loss= 0.801029, Train Accuracy= 0.72817\n",
      "Validation loss: 0.851039 , Validation acc:  0.695825\n",
      "--------------------------------------------------------------------------------\n",
      "learning_rate: 0.00461372\n",
      "Batch 400, Training Loss= 0.750026, Train Accuracy= 0.74176\n",
      "Validation loss: 0.82009 , Validation acc:  0.705765\n",
      "--------------------------------------------------------------------------------\n",
      "learning_rate: 0.00461372\n",
      "Batch 440, Training Loss= 0.659310, Train Accuracy= 0.78355\n",
      "Validation loss: 0.71245 , Validation acc:  0.764414\n",
      "--------------------------------------------------------------------------------\n",
      "learning_rate: 0.00456759\n",
      "Batch 480, Training Loss= 0.599787, Train Accuracy= 0.79505\n",
      "Validation loss: 0.654799 , Validation acc:  0.777336\n",
      "--------------------------------------------------------------------------------\n",
      "learning_rate: 0.00452191\n",
      "Batch 520, Training Loss= 0.616693, Train Accuracy= 0.78797\n",
      "Validation loss: 0.675698 , Validation acc:  0.775348\n",
      "--------------------------------------------------------------------------------\n",
      "learning_rate: 0.00447669\n",
      "Batch 560, Training Loss= 0.597473, Train Accuracy= 0.80964\n",
      "Validation loss: 0.633447 , Validation acc:  0.797217\n",
      "--------------------------------------------------------------------------------\n",
      "learning_rate: 0.00443192\n",
      "Batch 600, Training Loss= 0.521972, Train Accuracy= 0.82954\n",
      "Validation loss: 0.58227 , Validation acc:  0.806163\n",
      "--------------------------------------------------------------------------------\n",
      "learning_rate: 0.00443192\n",
      "Batch 640, Training Loss= 0.500208, Train Accuracy= 0.83938\n",
      "Validation loss: 0.561087 , Validation acc:  0.812127\n",
      "--------------------------------------------------------------------------------\n",
      "learning_rate: 0.00438761\n",
      "Batch 680, Training Loss= 0.517912, Train Accuracy= 0.83197\n",
      "Validation loss: 0.574642 , Validation acc:  0.812127\n",
      "--------------------------------------------------------------------------------\n",
      "learning_rate: 0.00434373\n",
      "Batch 720, Training Loss= 0.449861, Train Accuracy= 0.84966\n",
      "Validation loss: 0.500169 , Validation acc:  0.843936\n",
      "--------------------------------------------------------------------------------\n",
      "learning_rate: 0.00430029\n",
      "Batch 760, Training Loss= 0.465575, Train Accuracy= 0.84424\n",
      "Validation loss: 0.512337 , Validation acc:  0.832008\n",
      "--------------------------------------------------------------------------------\n",
      "learning_rate: 0.00425729\n",
      "Batch 800, Training Loss= 0.441053, Train Accuracy= 0.84479\n",
      "Validation loss: 0.50409 , Validation acc:  0.823062\n",
      "--------------------------------------------------------------------------------\n",
      "learning_rate: 0.00425729\n",
      "Batch 840, Training Loss= 0.428350, Train Accuracy= 0.86524\n",
      "Validation loss: 0.488486 , Validation acc:  0.841948\n",
      "--------------------------------------------------------------------------------\n",
      "learning_rate: 0.00421472\n",
      "Batch 880, Training Loss= 0.408653, Train Accuracy= 0.86602\n",
      "Validation loss: 0.474735 , Validation acc:  0.84493\n",
      "--------------------------------------------------------------------------------\n",
      "learning_rate: 0.00417257\n",
      "Batch 920, Training Loss= 0.362049, Train Accuracy= 0.88437\n",
      "Validation loss: 0.452423 , Validation acc:  0.840954\n",
      "--------------------------------------------------------------------------------\n",
      "learning_rate: 0.00413084\n",
      "Batch 960, Training Loss= 0.328369, Train Accuracy= 0.88990\n",
      "Validation loss: 0.418451 , Validation acc:  0.849901\n",
      "--------------------------------------------------------------------------------\n",
      "learning_rate: 0.00408954\n",
      "Batch 1000, Training Loss= 0.359627, Train Accuracy= 0.88636\n",
      "Validation loss: 0.449045 , Validation acc:  0.861829\n",
      "--------------------------------------------------------------------------------\n",
      "learning_rate: 0.00408954\n",
      "Batch 1040, Training Loss= 0.298343, Train Accuracy= 0.90648\n",
      "Validation loss: 0.374791 , Validation acc:  0.880716\n",
      "--------------------------------------------------------------------------------\n",
      "learning_rate: 0.00404864\n",
      "Batch 1080, Training Loss= 0.324884, Train Accuracy= 0.89907\n",
      "Validation loss: 0.415632 , Validation acc:  0.854871\n",
      "--------------------------------------------------------------------------------\n",
      "learning_rate: 0.00400815\n",
      "Batch 1120, Training Loss= 0.287921, Train Accuracy= 0.90670\n",
      "Validation loss: 0.365994 , Validation acc:  0.867793\n",
      "--------------------------------------------------------------------------------\n",
      "learning_rate: 0.00396807\n",
      "Batch 1160, Training Loss= 0.265483, Train Accuracy= 0.91344\n",
      "Validation loss: 0.356098 , Validation acc:  0.877734\n",
      "--------------------------------------------------------------------------------\n",
      "learning_rate: 0.00392839\n",
      "Batch 1200, Training Loss= 0.260431, Train Accuracy= 0.91289\n",
      "Validation loss: 0.356696 , Validation acc:  0.872763\n",
      "--------------------------------------------------------------------------------\n",
      "learning_rate: 0.00392839\n",
      "Batch 1240, Training Loss= 0.241321, Train Accuracy= 0.92118\n",
      "Validation loss: 0.350221 , Validation acc:  0.870775\n",
      "--------------------------------------------------------------------------------\n",
      "learning_rate: 0.00388911\n",
      "Batch 1280, Training Loss= 0.249274, Train Accuracy= 0.92207\n",
      "Validation loss: 0.363097 , Validation acc:  0.879722\n",
      "--------------------------------------------------------------------------------\n",
      "learning_rate: 0.00385022\n",
      "Batch 1320, Training Loss= 0.239128, Train Accuracy= 0.92350\n",
      "Validation loss: 0.36697 , Validation acc:  0.873757\n",
      "--------------------------------------------------------------------------------\n",
      "learning_rate: 0.00381171\n",
      "Batch 1360, Training Loss= 0.232667, Train Accuracy= 0.92881\n",
      "Validation loss: 0.352455 , Validation acc:  0.879722\n",
      "--------------------------------------------------------------------------------\n",
      "learning_rate: 0.0037736\n",
      "Batch 1400, Training Loss= 0.232159, Train Accuracy= 0.92538\n",
      "Validation loss: 0.341396 , Validation acc:  0.878728\n",
      "--------------------------------------------------------------------------------\n",
      "learning_rate: 0.0037736\n",
      "Batch 1440, Training Loss= 0.213597, Train Accuracy= 0.93445\n",
      "Validation loss: 0.333217 , Validation acc:  0.87674\n",
      "--------------------------------------------------------------------------------\n",
      "learning_rate: 0.00373586\n",
      "Batch 1480, Training Loss= 0.198004, Train Accuracy= 0.93909\n",
      "Validation loss: 0.328672 , Validation acc:  0.889662\n",
      "--------------------------------------------------------------------------------\n",
      "learning_rate: 0.0036985\n",
      "Batch 1520, Training Loss= 0.179809, Train Accuracy= 0.94506\n",
      "Validation loss: 0.324444 , Validation acc:  0.892644\n",
      "--------------------------------------------------------------------------------\n",
      "learning_rate: 0.00366152\n",
      "Batch 1560, Training Loss= 0.184010, Train Accuracy= 0.94473\n",
      "Validation loss: 0.319523 , Validation acc:  0.888668\n",
      "--------------------------------------------------------------------------------\n",
      "learning_rate: 0.0036249\n",
      "Batch 1600, Training Loss= 0.195104, Train Accuracy= 0.93633\n",
      "Validation loss: 0.340918 , Validation acc:  0.878728\n",
      "--------------------------------------------------------------------------------\n",
      "learning_rate: 0.0036249\n",
      "Batch 1640, Training Loss= 0.182769, Train Accuracy= 0.94462\n",
      "Validation loss: 0.340599 , Validation acc:  0.878728\n",
      "--------------------------------------------------------------------------------\n",
      "learning_rate: 0.00358865\n",
      "Batch 1680, Training Loss= 0.166762, Train Accuracy= 0.95247\n",
      "Validation loss: 0.304744 , Validation acc:  0.898608\n",
      "--------------------------------------------------------------------------------\n",
      "learning_rate: 0.00355277\n",
      "Batch 1720, Training Loss= 0.165413, Train Accuracy= 0.95224\n",
      "Validation loss: 0.308852 , Validation acc:  0.898608\n",
      "--------------------------------------------------------------------------------\n",
      "learning_rate: 0.00351724\n",
      "Batch 1760, Training Loss= 0.155525, Train Accuracy= 0.95700\n",
      "Validation loss: 0.298164 , Validation acc:  0.903579\n",
      "--------------------------------------------------------------------------------\n",
      "learning_rate: 0.00348207\n",
      "Batch 1800, Training Loss= 0.161194, Train Accuracy= 0.95003\n",
      "Validation loss: 0.31579 , Validation acc:  0.88668\n",
      "--------------------------------------------------------------------------------\n",
      "learning_rate: 0.00348207\n",
      "Batch 1840, Training Loss= 0.147688, Train Accuracy= 0.95567\n",
      "Validation loss: 0.294255 , Validation acc:  0.895626\n",
      "--------------------------------------------------------------------------------\n",
      "learning_rate: 0.00344725\n",
      "Batch 1880, Training Loss= 0.153469, Train Accuracy= 0.95744\n",
      "Validation loss: 0.302519 , Validation acc:  0.890656\n",
      "--------------------------------------------------------------------------------\n",
      "learning_rate: 0.00341277\n",
      "Batch 1920, Training Loss= 0.150984, Train Accuracy= 0.95689\n",
      "Validation loss: 0.30897 , Validation acc:  0.894632\n",
      "--------------------------------------------------------------------------------\n",
      "learning_rate: 0.00337865\n",
      "Batch 1960, Training Loss= 0.156373, Train Accuracy= 0.95114\n",
      "Validation loss: 0.312139 , Validation acc:  0.887674\n",
      "--------------------------------------------------------------------------------\n",
      "learning_rate: 0.00334486\n",
      "Batch 2000, Training Loss= 0.144422, Train Accuracy= 0.95821\n",
      "Validation loss: 0.296011 , Validation acc:  0.899602\n",
      "--------------------------------------------------------------------------------\n",
      "learning_rate: 0.00334486\n",
      "Batch 2040, Training Loss= 0.136249, Train Accuracy= 0.96319\n",
      "Validation loss: 0.278047 , Validation acc:  0.904573\n",
      "--------------------------------------------------------------------------------\n",
      "learning_rate: 0.00331141\n",
      "Batch 2080, Training Loss= 0.134754, Train Accuracy= 0.96440\n",
      "Validation loss: 0.286995 , Validation acc:  0.90159\n",
      "--------------------------------------------------------------------------------\n",
      "learning_rate: 0.0032783\n",
      "Batch 2120, Training Loss= 0.122526, Train Accuracy= 0.96595\n",
      "Validation loss: 0.290534 , Validation acc:  0.895626\n",
      "--------------------------------------------------------------------------------\n",
      "learning_rate: 0.00324551\n",
      "Batch 2160, Training Loss= 0.118897, Train Accuracy= 0.96529\n",
      "Validation loss: 0.284727 , Validation acc:  0.907555\n",
      "--------------------------------------------------------------------------------\n",
      "learning_rate: 0.00321306\n",
      "Batch 2200, Training Loss= 0.120102, Train Accuracy= 0.96518\n",
      "Validation loss: 0.279049 , Validation acc:  0.90159\n",
      "--------------------------------------------------------------------------------\n",
      "learning_rate: 0.00321306\n",
      "Batch 2240, Training Loss= 0.114380, Train Accuracy= 0.96783\n",
      "Validation loss: 0.28781 , Validation acc:  0.895626\n",
      "--------------------------------------------------------------------------------\n",
      "learning_rate: 0.00318093\n",
      "Batch 2280, Training Loss= 0.114366, Train Accuracy= 0.97037\n",
      "Validation loss: 0.289907 , Validation acc:  0.906561\n",
      "--------------------------------------------------------------------------------\n",
      "learning_rate: 0.00314912\n",
      "Batch 2320, Training Loss= 0.148775, Train Accuracy= 0.95556\n",
      "Validation loss: 0.321191 , Validation acc:  0.883698\n",
      "--------------------------------------------------------------------------------\n",
      "learning_rate: 0.00311763\n",
      "Batch 2360, Training Loss= 0.110388, Train Accuracy= 0.97048\n",
      "Validation loss: 0.281326 , Validation acc:  0.90159\n",
      "--------------------------------------------------------------------------------\n",
      "learning_rate: 0.00308645\n",
      "Batch 2400, Training Loss= 0.108281, Train Accuracy= 0.97048\n",
      "Validation loss: 0.289734 , Validation acc:  0.89662\n",
      "--------------------------------------------------------------------------------\n",
      "learning_rate: 0.00308645\n",
      "Batch 2440, Training Loss= 0.112919, Train Accuracy= 0.96960\n",
      "Validation loss: 0.305651 , Validation acc:  0.889662\n",
      "--------------------------------------------------------------------------------\n",
      "learning_rate: 0.00305559\n",
      "Batch 2480, Training Loss= 0.099052, Train Accuracy= 0.97623\n",
      "Validation loss: 0.271937 , Validation acc:  0.908549\n",
      "--------------------------------------------------------------------------------\n",
      "learning_rate: 0.00302503\n",
      "Batch 2520, Training Loss= 0.096161, Train Accuracy= 0.97800\n",
      "Validation loss: 0.274093 , Validation acc:  0.907555\n",
      "--------------------------------------------------------------------------------\n",
      "learning_rate: 0.00299478\n",
      "Batch 2560, Training Loss= 0.100303, Train Accuracy= 0.97292\n",
      "Validation loss: 0.306769 , Validation acc:  0.894632\n",
      "--------------------------------------------------------------------------------\n",
      "learning_rate: 0.00296483\n",
      "Batch 2600, Training Loss= 0.089786, Train Accuracy= 0.97944\n",
      "Validation loss: 0.288156 , Validation acc:  0.908549\n",
      "--------------------------------------------------------------------------------\n",
      "learning_rate: 0.00296483\n",
      "Batch 2640, Training Loss= 0.091546, Train Accuracy= 0.97745\n",
      "Validation loss: 0.2913 , Validation acc:  0.898608\n",
      "--------------------------------------------------------------------------------\n",
      "learning_rate: 0.00293519\n",
      "Batch 2680, Training Loss= 0.084464, Train Accuracy= 0.98054\n",
      "Validation loss: 0.291128 , Validation acc:  0.906561\n",
      "--------------------------------------------------------------------------------\n",
      "learning_rate: 0.00290583\n",
      "Batch 2720, Training Loss= 0.091135, Train Accuracy= 0.97778\n",
      "Validation loss: 0.305564 , Validation acc:  0.89165\n",
      "--------------------------------------------------------------------------------\n",
      "learning_rate: 0.00287678\n",
      "Batch 2760, Training Loss= 0.084355, Train Accuracy= 0.97999\n",
      "Validation loss: 0.282762 , Validation acc:  0.905567\n",
      "--------------------------------------------------------------------------------\n",
      "learning_rate: 0.00284801\n",
      "Batch 2800, Training Loss= 0.081839, Train Accuracy= 0.98076\n",
      "Validation loss: 0.282778 , Validation acc:  0.902584\n",
      "--------------------------------------------------------------------------------\n",
      "learning_rate: 0.00284801\n",
      "Batch 2840, Training Loss= 0.080537, Train Accuracy= 0.97889\n",
      "Validation loss: 0.300667 , Validation acc:  0.909543\n",
      "--------------------------------------------------------------------------------\n",
      "learning_rate: 0.00281953\n",
      "Batch 2880, Training Loss= 0.079856, Train Accuracy= 0.98010\n",
      "Validation loss: 0.292996 , Validation acc:  0.900596\n",
      "--------------------------------------------------------------------------------\n",
      "learning_rate: 0.00279133\n",
      "Batch 2920, Training Loss= 0.104029, Train Accuracy= 0.97104\n",
      "Validation loss: 0.323227 , Validation acc:  0.884692\n",
      "--------------------------------------------------------------------------------\n",
      "learning_rate: 0.00276342\n",
      "Batch 2960, Training Loss= 0.083963, Train Accuracy= 0.97778\n",
      "Validation loss: 0.286291 , Validation acc:  0.910537\n",
      "--------------------------------------------------------------------------------\n",
      "learning_rate: 0.00273578\n",
      "Batch 3000, Training Loss= 0.074655, Train Accuracy= 0.98242\n",
      "Validation loss: 0.305197 , Validation acc:  0.899602\n",
      "--------------------------------------------------------------------------------\n",
      "learning_rate: 0.00273578\n",
      "Batch 3040, Training Loss= 0.075298, Train Accuracy= 0.98309\n",
      "Validation loss: 0.284755 , Validation acc:  0.909543\n",
      "--------------------------------------------------------------------------------\n",
      "learning_rate: 0.00270843\n",
      "Batch 3080, Training Loss= 0.073502, Train Accuracy= 0.98375\n",
      "Validation loss: 0.286612 , Validation acc:  0.910537\n",
      "--------------------------------------------------------------------------------\n",
      "learning_rate: 0.00268134\n",
      "Batch 3120, Training Loss= 0.070188, Train Accuracy= 0.98463\n",
      "Validation loss: 0.293227 , Validation acc:  0.898608\n",
      "--------------------------------------------------------------------------------\n",
      "learning_rate: 0.00265453\n",
      "Batch 3160, Training Loss= 0.065586, Train Accuracy= 0.98508\n",
      "Validation loss: 0.28728 , Validation acc:  0.904573\n",
      "--------------------------------------------------------------------------------\n",
      "learning_rate: 0.00262798\n",
      "Batch 3200, Training Loss= 0.062264, Train Accuracy= 0.98508\n",
      "Validation loss: 0.299777 , Validation acc:  0.895626\n",
      "--------------------------------------------------------------------------------\n",
      "learning_rate: 0.00262798\n",
      "Batch 3240, Training Loss= 0.073964, Train Accuracy= 0.98253\n",
      "Validation loss: 0.309127 , Validation acc:  0.902584\n",
      "--------------------------------------------------------------------------------\n",
      "learning_rate: 0.0026017\n",
      "Batch 3280, Training Loss= 0.059662, Train Accuracy= 0.98773\n",
      "Validation loss: 0.280944 , Validation acc:  0.907555\n",
      "--------------------------------------------------------------------------------\n",
      "learning_rate: 0.00257569\n",
      "Batch 3320, Training Loss= 0.063265, Train Accuracy= 0.98607\n",
      "Validation loss: 0.294872 , Validation acc:  0.898608\n",
      "--------------------------------------------------------------------------------\n",
      "learning_rate: 0.00254993\n",
      "Batch 3360, Training Loss= 0.061090, Train Accuracy= 0.98883\n",
      "Validation loss: 0.278717 , Validation acc:  0.903579\n",
      "--------------------------------------------------------------------------------\n",
      "learning_rate: 0.00252443\n",
      "Batch 3400, Training Loss= 0.058583, Train Accuracy= 0.98662\n",
      "Validation loss: 0.280414 , Validation acc:  0.89662\n",
      "--------------------------------------------------------------------------------\n",
      "learning_rate: 0.00252443\n",
      "Batch 3440, Training Loss= 0.055820, Train Accuracy= 0.98773\n",
      "Validation loss: 0.286377 , Validation acc:  0.90159\n",
      "--------------------------------------------------------------------------------\n",
      "learning_rate: 0.00249919\n",
      "Batch 3480, Training Loss= 0.053801, Train Accuracy= 0.98729\n",
      "Validation loss: 0.303214 , Validation acc:  0.902584\n",
      "--------------------------------------------------------------------------------\n",
      "learning_rate: 0.00247419\n",
      "Batch 3520, Training Loss= 0.051579, Train Accuracy= 0.98939\n",
      "Validation loss: 0.305295 , Validation acc:  0.904573\n",
      "--------------------------------------------------------------------------------\n",
      "learning_rate: 0.00244945\n",
      "Batch 3560, Training Loss= 0.058570, Train Accuracy= 0.98784\n",
      "Validation loss: 0.290743 , Validation acc:  0.902584\n",
      "--------------------------------------------------------------------------------\n",
      "learning_rate: 0.00242496\n",
      "Batch 3600, Training Loss= 0.050698, Train Accuracy= 0.99049\n",
      "Validation loss: 0.294783 , Validation acc:  0.904573\n",
      "--------------------------------------------------------------------------------\n",
      "learning_rate: 0.00242496\n",
      "Batch 3640, Training Loss= 0.048895, Train Accuracy= 0.98861\n",
      "Validation loss: 0.287002 , Validation acc:  0.904573\n",
      "--------------------------------------------------------------------------------\n",
      "learning_rate: 0.00240071\n",
      "Batch 3680, Training Loss= 0.049274, Train Accuracy= 0.99027\n",
      "Validation loss: 0.288399 , Validation acc:  0.905567\n",
      "--------------------------------------------------------------------------------\n",
      "learning_rate: 0.0023767\n",
      "Batch 3720, Training Loss= 0.058596, Train Accuracy= 0.98596\n",
      "Validation loss: 0.299162 , Validation acc:  0.906561\n",
      "--------------------------------------------------------------------------------\n",
      "learning_rate: 0.00235293\n",
      "Batch 3760, Training Loss= 0.050713, Train Accuracy= 0.98872\n",
      "Validation loss: 0.309285 , Validation acc:  0.905567\n",
      "--------------------------------------------------------------------------------\n",
      "learning_rate: 0.00232941\n",
      "Batch 3800, Training Loss= 0.046498, Train Accuracy= 0.99127\n",
      "Validation loss: 0.297461 , Validation acc:  0.900596\n",
      "--------------------------------------------------------------------------------\n",
      "learning_rate: 0.00232941\n",
      "Batch 3840, Training Loss= 0.052761, Train Accuracy= 0.98895\n",
      "Validation loss: 0.29529 , Validation acc:  0.903579\n",
      "--------------------------------------------------------------------------------\n",
      "learning_rate: 0.00230611\n",
      "Batch 3880, Training Loss= 0.048168, Train Accuracy= 0.99182\n",
      "Validation loss: 0.296544 , Validation acc:  0.904573\n",
      "--------------------------------------------------------------------------------\n",
      "learning_rate: 0.00228305\n",
      "Batch 3920, Training Loss= 0.047311, Train Accuracy= 0.98972\n",
      "Validation loss: 0.308635 , Validation acc:  0.898608\n",
      "--------------------------------------------------------------------------------\n",
      "learning_rate: 0.00226022\n",
      "Batch 3960, Training Loss= 0.047041, Train Accuracy= 0.99038\n",
      "Validation loss: 0.293725 , Validation acc:  0.911531\n",
      "--------------------------------------------------------------------------------\n",
      "learning_rate: 0.00223762\n",
      "Batch 4000, Training Loss= 0.044203, Train Accuracy= 0.99127\n",
      "Validation loss: 0.301551 , Validation acc:  0.900596\n",
      "--------------------------------------------------------------------------------\n",
      "Optimization Finished!\n",
      "Training Accuracy: 0.992704\n",
      "Test Accuracy: 0.9177\n"
     ]
    }
   ],
   "source": [
    "train_accuracy = []\n",
    "train_cost = []\n",
    "val_accuracy = []\n",
    "val_cost = []\n",
    "\n",
    "def feed_next_batch(train_size, batch_size=64):\n",
    "    \n",
    "    start = 0\n",
    "    while start < train_size:\n",
    "        yield start, start + batch_size\n",
    "        start += batch_size\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    step = 1\n",
    "    # Keep training until reach max iterations\n",
    "    while step < training_iters:\n",
    "        \n",
    "        indices = np.arange(len(y_train))\n",
    "        np.random.shuffle(indices)\n",
    "        X_train, y_train =  X_train[indices], y_train[indices]\n",
    "        \n",
    "        for start, end in feed_next_batch(len(X_train), batch_size=batch_size):\n",
    "            # Run optimization op (backprop)\n",
    "            \n",
    "            batch_x, batch_y = X_train[start:end], y_train[start:end]\n",
    "            \n",
    "            sess.run(optimizer, feed_dict={x: batch_x, y: batch_y, keep_prob: dropout})\n",
    "            if step % test_step == 0:\n",
    "                # Calculate batch loss and accuracy\n",
    "                train_loss, train_acc = sess.run([cost, accuracy], feed_dict={x: X_train, \n",
    "                                                                              y: y_train,\n",
    "                                                                              keep_prob: 1.0})\n",
    "\n",
    "                if type(learning_rate) is not float:\n",
    "                    print('learning_rate:', sess.run(learning_rate))\n",
    "\n",
    "                train_cost.append(train_loss)\n",
    "                train_accuracy.append(train_acc)\n",
    "\n",
    "                print (\"Batch \" + str(step) + \", Training Loss= \" + \\\n",
    "                      \"{:.6f}\".format(train_loss) + \", Train Accuracy= \" + \\\n",
    "                      \"{:.5f}\".format(train_acc))\n",
    "\n",
    "                val_loss, val_acc = sess.run([cost, accuracy], feed_dict={x: X_val, \n",
    "                                                                            y: y_val,\n",
    "                                                                           keep_prob: 1.0})\n",
    "                val_cost.append(val_loss)\n",
    "                val_accuracy.append(val_acc)\n",
    "                print (\"Validation loss:\", val_loss, ', Validation acc: ', val_acc)\n",
    "                print('-' * 80)\n",
    "\n",
    "            step += 1\n",
    "            \n",
    "    print (\"Optimization Finished!\")\n",
    "\n",
    "    # Calculate accuracy for all test samples\n",
    "    print (\"Training Accuracy:\", \\\n",
    "        sess.run(accuracy, feed_dict={x: X_train,\n",
    "                                      y: y_train,\n",
    "                                     keep_prob: 1.0}))\n",
    "    print (\"Test Accuracy:\", \\\n",
    "        sess.run(accuracy, feed_dict={x: X_test,\n",
    "                                      y: y_test,\n",
    "                                     keep_prob: 1.0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
